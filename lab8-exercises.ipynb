{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8 - Neural Networks\n",
    "\n",
    "In this lab you'll use *neural networks* to classify images using both [scikit-learn](https://scikit-learn.org) and [PyTorch](https://pytorch.org/). PyTorch 1.9 or later is assumed to be installed. The goal is for you to see:\n",
    "1. that logistic regression is a special case of neural networks; and\n",
    "2. how to express the same type of network in both scikit-learn and in PyTorch, both shallow (logistic regression) and deep (several layers).\n",
    "\n",
    "**Run the code cell below** to import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.preprocessing     # For StandardScaler\n",
    "import sklearn.linear_model      # For LogisticRegression\n",
    "import sklearn.neural_network    # For MLPClassifier\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)  # Annoying\n",
    "np.set_printoptions(precision=3, suppress=True)  # Print as 0.001 instead of 9.876e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 1. Digit classification with neural networks in scikit-learn\n",
    "\n",
    "Exercise 1.1&ndash;1.8 ask you to load and train a model on the classic MNIST data set. It's so classic it has its [own Wikipedia page](https://en.wikipedia.org/wiki/MNIST_database)! The MNIST data set contains 60,000 training examples and 10,000 test examples. Each example comprises a 784-dimensional feature vector $\\mathbf{x}_i$ representing 28x28 grayscale image of a hand-written digit (784 = 28x28) with a label $y_i \\in \\{0, \\ldots, 9\\}$.\n",
    "\n",
    "Since there are 60,000 training cases, the matrix of training features $\\mathbf{X}$ is provided in as a 60000x784 matrix of pixel intensities. Value $X_{i,j} \\in \\{0, \\ldots, 255\\}$ represents the intensity (0=black, 255=white) of pixel number $j$ in training image $i$. Each 784-dimensional feature vector $\\mathbf{x}_i$ can be reshaped into a 28x28 image as depicted below.\n",
    "\n",
    "![image](img/mnist_data_layout.png)\n",
    "\n",
    "**Run the code cell below** to define a function that will be useful for plotting matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_grid(V):\n",
    "    \"\"\"\n",
    "    Given an array V containing stacked matrices, plots them in a grid layout.\n",
    "    V should have shape (K,M,N) where V[k] is a matrix of shape (M,N).\n",
    "    \"\"\"\n",
    "    assert V.ndim == 3, \"Expected V to have 3 dimensions, not %d\" % V.ndim\n",
    "    k, m, n = V.shape\n",
    "    ncol = 8                                     # At most 8 columns\n",
    "    nrow = min(4, (k + ncol - 1) // ncol)        # At most 4 rows\n",
    "    V = V[:nrow*ncol]                            # Focus on just the matrices we'll actually plot\n",
    "    figsize = (2*ncol, max(1, 2*nrow*(m/n)))     # Guess a good figure shape based on ncol, nrow\n",
    "    fig, axes = plt.subplots(nrow, ncol, sharex=True, sharey=True, figsize=figsize)\n",
    "    vmin, vmax = np.percentile(V, [0.1, 99.9])   # Show the main range of values, between 0.1%-99.9%\n",
    "    for v, ax in zip(V, axes.flat):\n",
    "        img = ax.matshow(v, vmin=vmin, vmax=vmax, cmap=plt.get_cmap('gray'))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    fig.colorbar(img, cax=fig.add_axes([0.92, 0.25, 0.01, .5]))   # Add a colorbar on the right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1 &ndash; Load MNIST and plot some digits\n",
    "\n",
    "The MNIST training data has been provided to you in a file called `mnist_train.npz`. The file is located in the same directory as this Jupyter Notebook.  A `npz` file is an efficient way to store multiple Numpy arrays in a file. Use Numpy's **[load](https://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html)** function to open an `npz` file. When the file is opened, you can think of the file as being a Python dictionary where you can ask for an array by its name (its 'key'). The example below shows how to open the file and list the keys:\n",
    "\n",
    "```python\n",
    ">>> with np.load(\"mnist_train.npz\") as data:\n",
    "...    print(list(data.keys()))\n",
    "\n",
    "['X', 'y']\n",
    "```\n",
    "(The reason we open the file using a *with*-statement is because once the *with*-statement is complete the file (\"file descriptor\") is automatically closed, rather than Python trying to keep the file open. This isn't important for the lab *per se*, closing files when you're done with them is just good programming practice!)\n",
    "\n",
    "\n",
    "**Write a few lines of code** to load the training data from `mnist_train.npz` and create two global vaiables *X_trn* and *y_trn* to refer to the data you loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here. Aim for 3 lines.\n",
    "with np.load(\"mnist_train.npz\") as mnist:\n",
    "    X_trn = mnist['X']\n",
    "    y_trn = mnist['y']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect the data** by printing information about the arrays.\n",
    "1. Print the shape and dtype of both your *X_trn* and *y_trn* arrays.\n",
    "2. Print the first five training samples from *X_trn* and *y_trn* arrays.\n",
    "\n",
    "Since your *X_trn* array is big, and because most of the first/last pixels in each image are 0 (black), to see any patterns in the features try printing a slice of values taken from the \"middle\" of each image. For example, pixels 400:415 are roughly from the middle row of each image (similar to blue rectangle in the diagram earlier), so try printing a slice of just those pixels. You should see `[  0   0   0   0   0  81 240 253 253 119  25   0   0   0   0]` printed for the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  60000 \ty shape:  5\n",
      "X_train data type:  uint8 \ty_train data type:  int32\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0] 5\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  51 159 253 159  50   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84 252\n",
      " 253 122   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
      "  47  79 255 168   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0\n",
      "   0   0   0   0 253 252 165   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  57 252 252  63   0   0   0\n",
      "   0   0   0   0   0   0 253 252 195   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255 253\n",
      " 196   0   0   0   0   0   0   0   0   0   0   0  76 246 252 112   0   0\n",
      "   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0   0   0\n",
      "   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7 135\n",
      " 253 186  12   0   0   0   0   0   0   0   0   0   0   0  85 252 223   0\n",
      "   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
      " 252 173   0   0   0   0   0   0   0   0   0   0   0   0   0   0  86 253\n",
      " 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253\n",
      " 223 167  56   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  28 199 252 252 253 252 252 233\n",
      " 145   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0] 0\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  67 232\n",
      "  39   0   0   0   0   0   0   0   0   0  62  81   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0 120 180  39   0   0   0   0   0   0   0\n",
      "   0   0 126 163   0   0   0   0   0   0   0   0   0   0   0   0   0   2\n",
      " 153 210  40   0   0   0   0   0   0   0   0   0 220 163   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  27 254 162   0   0   0   0   0   0\n",
      "   0   0   0   0 222 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 183 254 125   0   0   0   0   0   0   0   0   0  46 245 163   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0 198 254  56   0   0   0   0\n",
      "   0   0   0   0   0 120 254 163   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23 231 254  29   0   0   0   0   0   0   0   0   0 159 254 120\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 163 254 216  16   0   0\n",
      "   0   0   0   0   0   0   0 159 254  67   0   0   0   0   0   0   0   0\n",
      "   0  14  86 178 248 254  91   0   0   0   0   0   0   0   0   0   0 159\n",
      " 254  85   0   0   0  47  49 116 144 150 241 243 234 179 241 252  40   0\n",
      "   0   0   0   0   0   0   0   0   0 150 253 237 207 207 207 253 254 250\n",
      " 240 198 143  91  28   5 233 250   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0 119 177 177 177 177 177  98  56   0   0   0   0   0 102 254 220\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 169 254 137   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
      " 254  57   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 169 254  57   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 169 255  94   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0 169 254  96   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 169 254 153   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 169 255 153   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  96 254 153   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0] 4\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 124 253 255  63\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  96 244 251 253  62   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 127 251 251\n",
      " 253  62   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  68 236 251 211  31   8   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  60 228 251\n",
      " 251  94   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 155 253 253 189   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  20 253\n",
      " 251 235  66   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  32 205 253 251 126   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 104\n",
      " 251 253 184  15   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 240 251 193  23   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  32\n",
      " 253 253 253 159   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 151 251 251 251  39   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  48 221 251 251 172   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 234 251 251 196  12   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0 253 251 251  89   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0 159 255 253 253  31   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  48 228 253 247 140   8   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  64 251 253 220   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  64 251 253 220   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  24 193 253 220\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0] 1\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  55 148 210 253 253 113  87 148\n",
      "  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  87 232 252 253 189 210 252 252 253 168   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   4  57 242 252 190  65   5  12 182\n",
      " 252 253 116   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  96 252 252 183  14   0   0  92 252 252 225  21   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 132 253 252 146  14   0   0   0\n",
      " 215 252 252  79   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 126 253 247 176   9   0   0   8  78 245 253 129   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  16 232 252 176   0   0   0  36\n",
      " 201 252 252 169  11   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  22 252 252  30  22 119 197 241 253 252 251  77   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  16 231 252 253 252 252\n",
      " 252 226 227 252 231   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  55 235 253 217 138  42  24 192 252 143   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  62 255 253 109   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  71 253 252  21   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 253 252  21   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  71 253 252\n",
      "  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 106 253 252  21   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45\n",
      " 255 253  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 218 252  56   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  96 252 189  42   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  14 184 252 170  11   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  14 147 252  42   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0] 9\n"
     ]
    }
   ],
   "source": [
    "# Your code for printing shape and dtype here. Aim for 2 lines.\n",
    "print(\"X shape: \", X_trn.shape[0], \"\\ty shape: \", y_trn[0])\n",
    "print(\"X_train data type: \", X_trn.dtype, \"\\ty_train data type: \",y_trn.dtype)\n",
    "# Your code for printing sample values. Aim for 2 lines.\n",
    "for x,y in zip(X_trn[:5],y_trn[:5]):\n",
    "    print(x,y,end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot a few digits** to see what they look like. Use the *plot_matrix_grid* function defined earlier. To do this, you'll need to reshape the array referred to by your *X_trn* variable so that the plotting code knows the images have shape 28x28 rather than being just 784-dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 33 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here. Aim for 1-2 lines.\n",
    "# plot_matrix_grid()\n",
    "plot_matrix_grid(np.array([i.reshape(28,28) for i in X_trn[:40]]))\n",
    "# count=0\n",
    "# the loop is used to plot the 8 train variables after reshaping one by one\n",
    "# for index,value in enumerate(X_trn[:4]):plot_matrix_grid(np.array([X_trn[count].reshape(28,28),X_trn[count+1].reshape(28,28),X_trn[count+2].reshape(28,28),X_trn[count+3].reshape(28,28),X_trn[count+4].reshape(28,28),X_trn[count+5].reshape(28,28),X_trn[count+6].reshape(28,28),X_trn[count+7].reshape(28,28)]));count+=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the patterns you printed when inspecting the *X_trn* variable earlier, and make sure you see where they come from in the first five images plotted above.\n",
    "\n",
    "If you want to see more of the MNIST training digits, rather than just the first few, you can try plotting different \"slices\" of the *X_trn* variable, such as *X_trn[100:]* to start plotting at the 101st training example. (You still have to reshape the resulting array, of course.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, **load the MNIST test data** from the file `mnist_test.npz`, just like you did for the training data. Create global variables *X_tst* and *y_tst* to refer to the arrays that you loaded. These arrays will be used to evaluate test-time accuracy later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 3 lines.\n",
    "# loading the mnist test data and initialize the X and y values into X_tst and y_tst\n",
    "with np.load(\"mnist_test.npz\") as mnist:\n",
    "    X_tst = mnist['X']\n",
    "    y_tst = mnist['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Exericise 1.2 &ndash; Preprocess the MNIST data\n",
    "\n",
    "Certain models trained on MNIST work better when the features are normalized. Use scikit-learn to normalize the MNIST data using scaling, such as the *StandardScaler*. (You can just treat the pixels as independent features, nothing fancy.)\n",
    "\n",
    "**Write a few lines of code** to normalize both you *X_trn* and *X_tst* variables. You can just over-write those variables with the new (normalized) feature arrays, and discard the original unscaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 3-4 lines.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_trn=scaler.fit_transform(X_trn)\n",
    "X_tst=scaler.fit_transform(X_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the rescaled training digits** using the *plot_matrix_grid* function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 33 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here. Aim for 1-2 lines.\n",
    "# count=0\n",
    "# for index,value in enumerate(X_trn[:4]):plot_matrix_grid(np.array([X_trn[count].reshape(28,28),X_trn[count+1].reshape(28,28),X_trn[count+2].reshape(28,28),X_trn[count+3].reshape(28,28),X_trn[count+4].reshape(28,28),X_trn[count+5].reshape(28,28),X_trn[count+6].reshape(28,28),X_trn[count+7].reshape(28,28)]));count+=8\n",
    "plot_matrix_grid(np.array([i.reshape(28,28) for i in X_trn[:40]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the pixels in the center tend to be scaled down more than the pixels in the periphery. *Do you understand why?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Exericise 1.3 &ndash; Train multinomial logistic regression on MNIST\n",
    "\n",
    "Train a **[LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)** object to classify MNIST digits. Use *random_state*=0 and default settings otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here. Aim for 2-3 lines.\n",
    "# train the model with Logistic regression \n",
    "log=sklearn.linear_model.LogisticRegression(random_state=0)\n",
    "# fit the train data to a model\n",
    "log.fit(X_trn,y_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the **[score](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score)** method of the *LogisticRegression* object to compute the accuracy as a number in the range $[0.0, 1.0]$. Figure out how to convert that number (e.g., 0.934) into an error rate percentage (e.g., 6.6%).\n",
    "\n",
    "**Print the training _error rate_ and testing _error rate_** of your logistic regression model on the MNIST data set. Your output should be in the form:\n",
    "```\n",
    "X.XX% training error\n",
    "X.XX% testing error\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.65% training error\n",
      "7.68% testing error\n"
     ]
    }
   ],
   "source": [
    "# Your code here. Aim for 2-4 lines.\n",
    "# print the trainig error score and testing error score\n",
    "print(f\"{round((1-log.score(X_trn,y_trn))*100,2)}% training error\")\n",
    "print(f\"{round((1-log.score(X_tst,y_tst))*100,2)}% testing error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the testing error rate you see compare to some of the error rates mentioned on the [MNIST Wikipedia page](https://en.wikipedia.org/wiki/MNIST_database)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the predicted class probabities** of the **first five examples** in the training set. Use the *predict_proba* method of your *LogisticRegression* object. The first row of output should look something like:\n",
    "```\n",
    "[0.001 0.    0.    0.203 0.    0.796 0.    0.    0.    0.   ]\n",
    "```\n",
    "From the above probabilities we can see that the model thinks the first digit in the training set is *probably* digit \"5\" but *might also be* digit \"3\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.001 0.    0.    0.203 0.    0.796 0.    0.    0.    0.   ]\n",
      " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.002 0.001 0.013 0.949 0.    0.    0.035 0.    0.   ]\n",
      " [0.    0.991 0.006 0.    0.    0.    0.    0.    0.002 0.   ]\n",
      " [0.    0.    0.    0.    0.014 0.    0.    0.006 0.001 0.979]]\n"
     ]
    }
   ],
   "source": [
    "# Your code here. Aim for 1-2 lines.\n",
    "# using predict_proba function to print the first 5 X train values\n",
    "print(log.predict_proba(X_trn[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Exericise 1.4 &ndash; Visualize the weights of your logistic regression model\n",
    "\n",
    "The logisitic regression model you trained in Exercise 1.3 has a *coef_* attribute. This attribute is the array of weights $\\mathbf{W}$ seen in Lecture 4 (e.g. slide 28). For the MNIST data, this matrix has shape (10, 784), because there are 10 output classes and 784=28x28 pixels. Weight $W_{k,j}$ is the weight with which of pixel $j$ contributes to output class $k$.\n",
    "\n",
    "You are asked to visualize the weights using *plot_matrix_grid*. You may need to reshape the weight matrix to do this. The first two outputs, corresponding to predictin digit \"0\" and predicting digit \"1\" should look something like this:\n",
    "\n",
    "<img src=\"img/mnist_logistic_regression_weights.png\" width=180/>\n",
    "\n",
    "Notice how the pattern for \"0\" is has strong negative weights in the center: that's because if there are white pixels in the center, it's unlikely that the image represents digit \"0\"!\n",
    "\n",
    "<span style=\"color:red\">If your weight patterns appear **noisier** than above, try repeating Exercise 1.3 but weaken *LogisticRegression*'s L2 penalty by a factor of 100 from its default. Take note of any change in training/test accuracy, too.</span>\n",
    "\n",
    "**Write a few lines of code** to plot the weights and see what patterns they contain. You should see ten patterns. (Don't worry if the last few grid entries are just white boxes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 17 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here. Aim for 1-2 lines.\n",
    "# reshape the images data using comprehension method\n",
    "co=[i.reshape(28,28) for i in log.coef_]\n",
    "# passing the coeficient array values to plot function for ploting results \n",
    "plot_matrix_grid(np.array(co))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When an input image (of a hand-written digit) causes one of these patterns to have a large positive response (strong activation), then the corresponing class $\\{0, 1, 2, \\ldots, 9\\}$ will be given a high probability by the final softmax operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Exericise 1.5 &ndash; Train a neural network on MNIST with *zero* hidden layers\n",
    "\n",
    "Train a neural network on MNIST using the **[sklearn.neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)** class.\n",
    "\n",
    "A neural network has *many* more hyperparameters to configure. Configure your neural network as follows:\n",
    "* Ask for *no hidden layers*. You can do this by specifying an empty tuple `()` for the *hidden_layer_sizes* argument. This will create a neural network where the 784 input features are directly 'connected' to the 10 output predictions, which in this case corresponds to the multinomial logistic regression you did in Exercise 1.4.\n",
    "* Use the `sgd` solver. This means *stochastic gradient descent* that we saw in Lecture 1.\n",
    "* Use a batch size of 100. This means that at each step of SGD the gradient will be computed from only 100 of the 60,000 training cases. This is also callsed a \"mini-batch\". The SGD algorithm works by starting with the firs 100, then the next 100, and then it gets to the last 100 in the training set it starts from the beginning again.\n",
    "* Use *max_iter*=10. This causes the training to stop after SGD has passed over all 60,000 training cases exactly 10 times.\n",
    "* Use *learning_rate_init*=0.01, which determines the step size for SGD once it has computed a gradient.\n",
    "* Use *momentum*=0.9, which speeds up training.\n",
    "* Use *random_state*=0 for reproducibility\n",
    "* Use *verbose*=True to see progress printed out. Each time it prints \"Iteration X\" it means SGD has made another pass over all 60,000 training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 1-2 lines, plus whatever line wrapping you need for arguments!\n",
    "# train model via MLP classifier with 0 hidder layer and put the values as directed above \n",
    "NN=sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(),solver='sgd', batch_size=100, max_iter=10, learning_rate_init=0.01, momentum=0.9, random_state=0,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the training error rate and test error rate** of your neural network classifier, just like you did for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.40770306\n",
      "Iteration 2, loss = 0.30859873\n",
      "Iteration 3, loss = 0.29337169\n",
      "Iteration 4, loss = 0.28490254\n",
      "Iteration 5, loss = 0.27543585\n",
      "Iteration 6, loss = 0.26958339\n",
      "Iteration 7, loss = 0.26545986\n",
      "Iteration 8, loss = 0.26427636\n",
      "Iteration 9, loss = 0.26236903\n",
      "Iteration 10, loss = 0.25963997\n",
      "6.84% training error\n",
      "7.75% testing error\n"
     ]
    }
   ],
   "source": [
    "# Your code here. Aim for 2-4 lines.\n",
    "# fitting the values\n",
    "NN.fit(X_trn,y_trn)\n",
    "print(f\"{round((1-NN.score(X_trn,y_trn))*100,2)}% training error\")\n",
    "print(f\"{round((1-NN.score(X_tst,y_tst))*100,2)}% testing error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Exericise 1.6 &ndash; Visualize the weights of a neural network (no hidden layers)\n",
    "\n",
    "The *MLPClassifier* object has a *coefs_* attribute that works just like the *coef_* attribute that contained coefficient matrix $\\mathbf{W}$ of *LogisticRegression*, except that for a neural network there are two differences:\n",
    "1. *coefs_* is a *list* of coefficient matrices, so *coefs_[0]* is $\\mathbf{W}^{(1)}$, the coefficient matrix of the *first layer*. Since the neural network you trained in Exercise 1.5 has no hidden layers, this\n",
    "$\\mathbf{W}^{(1)}$ matrix holds the same weights as the $\\mathbf{W}$ matrix for LogisticRegression.\n",
    "2. The weight matrix for *MLPClassifier* has a different layout: it is 784x10 rather than 10x784. Do you now how to account for this?\n",
    "\n",
    "**Write a few lines of code** to repeat Exercise 1.4 but this time with the neural network weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 17 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here. Aim for 1-2 lines.\n",
    "# reshape the images and change layout from 784x10 to 10x784\n",
    "co=[i.reshape(28,28) for i in NN.coefs_[0].T]\n",
    "plot_matrix_grid(np.array(co))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your patterns look streaky then you may need to try transposing your weight matrix to account for the different layout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Exericise 1.7 &ndash; Train and visualize the weights of a neural network with 1 hidden layer\n",
    "\n",
    "Here you're asked to train a neural network like you did in Exercise 1.5, but this time **add a hidden layer with 16 'tanh' hidden units** to your neural network. Then you'll visualize the weights of this network.\n",
    "\n",
    "Read the documentation for **[MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)** to learn how to do specify a hidden layer. (*Note:* In Python if you want to create a *tuple* object with only one item in it, you can use *(item,)* with an extra comma, rather than *(item)*, which Python interprets to just be regular parentheses.) All the other hyperparameters can stay the same as Exercise 1.5.\n",
    "\n",
    "**Write a few lines of code** to train a new neural network, this time with 16 *tanh* hidden units. In other words, this will be a 784-16-10 neural network where the hidden layer uses *tanh* activations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 1-2 lines, plus whatever line wrapping you need for arguments!\n",
    "# same method use as in 1.8 but here change the hiider layer size and add activation parameter to MLP classifier\n",
    "NN=sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(16,), activation='tanh',solver='sgd', batch_size=100, max_iter=10, learning_rate_init=0.01, momentum=0.9, random_state=0,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the training error rate and test error rate** of your neural network classifier, just like you did for logistic regression. How does your error rate compare to multinomial logistic regression? (Exercises 1.3 and 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.47011299\n",
      "Iteration 2, loss = 0.26978585\n",
      "Iteration 3, loss = 0.23458535\n",
      "Iteration 4, loss = 0.21459244\n",
      "Iteration 5, loss = 0.19994936\n",
      "Iteration 6, loss = 0.19026849\n",
      "Iteration 7, loss = 0.18173445\n",
      "Iteration 8, loss = 0.17397831\n",
      "Iteration 9, loss = 0.16790016\n",
      "Iteration 10, loss = 0.16357402\n",
      "4.18% training error\n",
      "6.43% testing error\n"
     ]
    }
   ],
   "source": [
    "# Your code here. Aim for 2-4 lines.\n",
    "NN.fit(X_trn,y_trn)\n",
    "print(f\"{round((1-NN.score(X_trn,y_trn))*100,2)}% training error\")\n",
    "print(f\"{round((1-NN.score(X_tst,y_tst))*100,2)}% testing error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the first-layer weights $\\mathbf{W}^{(1)}$ of your neural network** using the *plot_matrix_grid* function, just in Exercise 1.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x72 with 33 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here. Aim for 1-2 lines.\n",
    "# reshape the coeficients with weights 1\n",
    "co=[[i] for i in NN.coefs_[0]]\n",
    "plot_matrix_grid(np.array(co))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are now 16 patterns, not 10, and they no longer seem to correspond to the digits $\\{0,1,\\ldots,9\\}$ in any particular order. *Do you understand why?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the second-layer weights $\\mathbf{W}^{(2)}$ of your neural network** using the *plot_matrix_grid* function. \n",
    "\n",
    "However, this time if you inspect the shape of the second weight matrix, *coefs_[1]*, you'll see that it has shape $(16, 10)$, and so it cannot be reshaped into a 28x28 pattern. In fact the second layer has only dimension: the \"hidden layer\" is just a vector of 16 values (the 16 tanh-transformed activations of the first-layer patterns). Each of the 10 output units has 16 weights contributing to it, rather than 784 weights like in Exercise 1.6.\n",
    "\n",
    "Figure out how to reshape the weight matrix so that when you call *plot_matrix_grid* you see a grid of 1x16 weight vectors, like the two examples below:\n",
    "![image](img/mnist_mlp_hidden_weights.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x72 with 17 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here. Aim for 1-2 lines.\n",
    "co=[[i] for i in NN.coefs_[1]]\n",
    "plot_matrix_grid(np.array(co))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Exericise 1.8 &ndash; Train a neural network with lots of hidden units\n",
    "\n",
    "Repeat Exercise 1.7 but with two hidden layers having **100 and 50 hidden units** respectively. This time use **_relu_ activations**. All other hyperparameters can stay the same.\n",
    "\n",
    "**Write a few lines of code** to train the model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 1-2 lines, plus whatever line wrapping you need for arguments!\n",
    "# train the model and change the hiddern layer size and activation parameter to relue\n",
    "NN=sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100,50,), activation='relu',solver='sgd', batch_size=100, max_iter=10, learning_rate_init=0.01, momentum=0.9, random_state=0,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the training and testing error rates** here. *How do they compare to earlier models?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.33306221\n",
      "Iteration 2, loss = 0.13727616\n",
      "Iteration 3, loss = 0.09523979\n",
      "Iteration 4, loss = 0.07193538\n",
      "Iteration 5, loss = 0.05528783\n",
      "Iteration 6, loss = 0.04298481\n",
      "Iteration 7, loss = 0.03308290\n",
      "Iteration 8, loss = 0.02760081\n",
      "Iteration 9, loss = 0.02298517\n",
      "Iteration 10, loss = 0.01933388\n",
      "0.22% training error\n",
      "2.72% testing error\n"
     ]
    }
   ],
   "source": [
    "# Your code here. Aim for 2-4 lines.\n",
    "NN.fit(X_trn,y_trn)\n",
    "print(f\"{round((1-NN.score(X_trn,y_trn))*100,2)}% training error\")\n",
    "print(f\"{round((1-NN.score(X_tst,y_tst))*100,2)}% testing error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the first-layer weights $\\mathbf{W}^{(1)}$ of your neural network** here. *Are the pattern detectors here qualitatively different than for earlier models?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x72 with 33 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here. Aim for 1-2 lines.\n",
    "co=[[i] for i in NN.coefs_[1]]\n",
    "plot_matrix_grid(np.array(co))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't bother plotting the 2nd and 3rd layer weights, they are high-dimensional and hard to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 2. Neural networks in PyTorch\n",
    "\n",
    "Exercise 2.1&ndash;2.3 ask you to train a simple neural network in **[PyTorch](https://pytorch.org/docs/stable/index.html)**. Here you'll use PyTorch to train an MNIST classifier using the same MNIST data that you already preprocess in Part 1. The goal is just to get you familiar with PyTorch basics and how they compare to scikit-learn.\n",
    "\n",
    "PyTorch is a deep learning framework like TensorFlow. PyTorch tends to be popular with deep learning researchers because it's very flexible for trying new ideas. TensorFlow is also flexible but is designed in such a way that it's more popular for companies trying to deploy high-performance models (in the cloud etc). Both can be used for research, of course! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Exericise 2.1 &ndash; Convert MNIST from Numpy arrays to PyTorch tensors\n",
    "\n",
    "PyTorch has its own Numpy-like array class, called *Tensor*. In order to train a PyTorch model, you must first convert the Numpy arrays. PyTorch understands Numpy arrays, so this is easy. The only tricky part is that, in order to be fast and not waste memory, PyTorch tends to be more picky about the *dtype* of the arrays you give it.\n",
    "\n",
    "**Write a few lines of code** to create four global variables: *X_trn_torch, y_trn_torch, X_tst_torch, y_tst_torch* that are PyTorch versions of your preprocessed MNIST training data from Part 1. The *X* tensors should have *dtype* float32, and the *y* tensors should have *dtype* int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 2-4 lines.\n",
    "# convert the numpy array to torch and assign to X_trn torch with dtype float32\n",
    "X_trn_torch = torch.from_numpy(X_trn).type(torch.FloatTensor)\n",
    "# convert the numpy array to torch and assign to y_trn torch with dtype int64\n",
    "y_trn_torch = torch.from_numpy(y_trn).type(torch.LongTensor)\n",
    "\n",
    "X_tst_torch = torch.from_numpy(X_tst).type(torch.FloatTensor)\n",
    "y_tst_torch = torch.from_numpy(y_tst).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to check your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "assert 'X_trn_torch' in globals(), \"You didn't declare a X_trn_torch variable!\"\n",
    "assert 'y_trn_torch' in globals(), \"You didn't declare a y_trn_torch variable!\"\n",
    "assert 'X_tst_torch' in globals(), \"You didn't declare a X_tst_torch variable!\"\n",
    "assert 'y_tst_torch' in globals(), \"You didn't declare a y_tst_torch variable!\"\n",
    "assert isinstance(X_trn_torch, torch.Tensor)\n",
    "assert isinstance(y_trn_torch, torch.Tensor)\n",
    "assert isinstance(X_tst_torch, torch.Tensor)\n",
    "assert isinstance(y_tst_torch, torch.Tensor)\n",
    "assert X_trn_torch.dtype == torch.float32\n",
    "assert y_trn_torch.dtype == torch.int64\n",
    "assert X_trn_torch.shape == (60000,784)\n",
    "assert y_trn_torch.shape == (60000,)\n",
    "assert X_tst_torch.dtype == torch.float32\n",
    "assert y_tst_torch.dtype == torch.int64\n",
    "assert X_tst_torch.shape == (10000,784)\n",
    "assert y_tst_torch.shape == (10000,)\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Exericise 2.2 &ndash; Train a PyTorch neural network *without* hidden layers\n",
    "\n",
    "This exercise only asks you to **run existing code** so that you learn how PyTorch works. The code in this cell defines a simple logistic model, and then you are asked to modify the code to add hidden layers to the network.\n",
    "\n",
    "Useful documentation for understanding the code that you see:\n",
    "* **[torch.nn](https://pytorch.org/docs/stable/nn.html)** (neural network)\n",
    "* **[torch.optim](https://pytorch.org/docs/stable/optim.html)** (optimizers such as SGD)\n",
    "\n",
    "Here are some comments to help you understand the \"starter code\" below:\n",
    "\n",
    "* A neural network is a sequence of non-linear transformations, so PyTorch provides a **[Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)** class that accepts a list of desired transformations.\n",
    "\n",
    "* In a standard neural network, the transformations are just linear, i.e. $\\mathbf{Wx}+\\mathbf{b}$, and in PyTorch this is implemented by a **[Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)** class where constructing one of these objects with *Linear(D, M)* tells the new object that it should be expecting an *D*-dimensional input and transform it into a *M*-dimensional output. To do this, the *Linear* object will create its own parameter matrix $\\mathbf{W} \\in \\mathbb{R}^{M\\times D}$ and bias vector $\\mathbf{b} \\in \\mathbb{R}^M$.\n",
    "\n",
    "* In PyTorch, the **[CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)** class conveniently combines applying a softmax and then computing the negative log likelihood, so you don't explicitly apply softmax while training. Once you have a *CrossEntropyLoss* object, you can call it with your predictions and targets (both vectors), and it will compute the negative log likelihood, which is just one number (a scalar).\n",
    " \n",
    "\n",
    "\n",
    "**Run the code cell below** to define a simple 784-10 neural network (i.e. logistic regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0) # Ensure model weights initialized with same random numbers\n",
    "\n",
    "# Create an object that holds a sequence of layers and activation functions\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28, 10),   # Applies Wx+b from 784 dimensions down to 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to define some objects and variables needed for training the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object that can compute \"negative log likelihood of a softmax\"\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Use stochastic gradient descent to train the model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Use 100 training samples at a time to compute the gradient.\n",
    "batch_size = 100\n",
    "\n",
    "# Make 10 passes over the training data, each time using batch_size samples to compute gradient\n",
    "num_epoch = 10\n",
    "next_epoch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to train the neural network using stochastic gradient descent (SGD). *Note that if you re-run this code cell multiple times it will \"continue\" training from the current parameters, and if you want to \"reset\" the model you need to re-run the earlier code cell that defined the model!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: loss on final training batch: 0.7097\n",
      "Epoch  2: loss on final training batch: 0.8752\n",
      "Epoch  3: loss on final training batch: 0.3313\n",
      "Epoch  4: loss on final training batch: 0.3312\n",
      "Epoch  5: loss on final training batch: 0.3239\n",
      "Epoch  6: loss on final training batch: 0.3168\n",
      "Epoch  7: loss on final training batch: 0.3128\n",
      "Epoch  8: loss on final training batch: 0.3074\n",
      "Epoch  9: loss on final training batch: 0.3044\n",
      "Epoch 10: loss on final training batch: 0.2990\n",
      "Epoch 10: loss on test set: 0.3182\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(next_epoch, next_epoch+num_epoch):\n",
    "    \n",
    "    # Make an entire pass (an 'epoch') over the training data in batch_size chunks\n",
    "    for i in range(0, len(X_trn), batch_size):        \n",
    "        X = X_trn_torch[i:i+batch_size]     # Slice out a mini-batch of features\n",
    "        y = y_trn_torch[i:i+batch_size]     # Slice out a mini-batch of targets\n",
    "\n",
    "        y_pred = model(X)                   # Make predictions (final-layer activations)\n",
    "        l = loss(y_pred, y)                 # Compute loss with respect to predictions\n",
    "        \n",
    "        model.zero_grad()                   # Reset all gradient accumulators to zero (PyTorch thing)\n",
    "        l.backward()                        # Compute gradient of loss wrt all parameters (backprop!)\n",
    "        optimizer.step()                    # Use the gradients to take a step with SGD.\n",
    "        \n",
    "    print(\"Epoch %2d: loss on final training batch: %.4f\" % (epoch, l.item()))\n",
    "    \n",
    "print(\"Epoch %2d: loss on test set: %.4f\" % (epoch, loss(model(X_tst_torch), y_tst_torch)))\n",
    "next_epoch = epoch+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to retrieve the PyTorch model's parameters, convert them back to Numpy, and plot them like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 17 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "W, b, *_ = model.parameters()\n",
    "W = W.detach().numpy()\n",
    "plot_matrix_grid(W.reshape(-1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Exericise 2.3 &ndash; Train a PyTorch neural network *with* hidden layers\n",
    "\n",
    "Using Exercise 2.2 as a starting point, write new code to **implement a 784-100-50-10 neural network** with **_relu_ activations** just like you did in Exercise 1.8, but now implemented with PyTorch.\n",
    "\n",
    "To do this, you will need to:\n",
    "1. Create a new *model* object that has more sequential steps to it, including the *Linear* and **[ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)** objects.\n",
    "2. Create a new *optimizer* object that knows about your new model's parameters.\n",
    "\n",
    "If you succeed, you should be able to get the training loss to go to zero, especially if you run the training loop code cell extra times (i.e. more than 10 epochs total). *But what happens with the test set loss, as you continue training?*\n",
    "\n",
    "We will do more PyTorch in the next lab, with convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your PyTorch to create the model and optimizer here. \n",
    "# create a model object to assign the shapes using Torch with Linear and ReLU objects \n",
    "\n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001 \n",
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = torch.nn.Linear(input_size, hidden_size) \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.l2 = torch.nn.Linear(hidden_size, num_classes)\n",
    "        self.l3 = torch.nn.Linear(num_classes, num_epochs)\n",
    "        self.l4 = torch.nn.Linear(num_epochs, batch_size)\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.l4(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer parameter \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step[1/60000], Loss: 4.6041\n",
      "Epoch [1/10], Step[101/60000], Loss: 4.6043\n",
      "Epoch [1/10], Step[201/60000], Loss: 4.6105\n",
      "Epoch [1/10], Step[301/60000], Loss: 4.5667\n",
      "Epoch [1/10], Step[401/60000], Loss: 4.5663\n",
      "Epoch [1/10], Step[501/60000], Loss: 4.5342\n",
      "Epoch [1/10], Step[601/60000], Loss: 4.5760\n",
      "Epoch [1/10], Step[701/60000], Loss: 4.5264\n",
      "Epoch [1/10], Step[801/60000], Loss: 4.5255\n",
      "Epoch [1/10], Step[901/60000], Loss: 4.4965\n",
      "Epoch [1/10], Step[1001/60000], Loss: 4.4496\n",
      "Epoch [1/10], Step[1101/60000], Loss: 4.4190\n",
      "Epoch [1/10], Step[1201/60000], Loss: 4.4321\n",
      "Epoch [1/10], Step[1301/60000], Loss: 4.4237\n",
      "Epoch [1/10], Step[1401/60000], Loss: 4.3486\n",
      "Epoch [1/10], Step[1501/60000], Loss: 4.3053\n",
      "Epoch [1/10], Step[1601/60000], Loss: 4.2564\n",
      "Epoch [1/10], Step[1701/60000], Loss: 4.2200\n",
      "Epoch [1/10], Step[1801/60000], Loss: 4.2083\n",
      "Epoch [1/10], Step[1901/60000], Loss: 4.1407\n",
      "Epoch [1/10], Step[2001/60000], Loss: 4.1543\n",
      "Epoch [1/10], Step[2101/60000], Loss: 4.0368\n",
      "Epoch [1/10], Step[2201/60000], Loss: 4.0808\n",
      "Epoch [1/10], Step[2301/60000], Loss: 3.9294\n",
      "Epoch [1/10], Step[2401/60000], Loss: 3.8301\n",
      "Epoch [1/10], Step[2501/60000], Loss: 3.7067\n",
      "Epoch [1/10], Step[2601/60000], Loss: 3.7410\n",
      "Epoch [1/10], Step[2701/60000], Loss: 3.5121\n",
      "Epoch [1/10], Step[2801/60000], Loss: 3.3923\n",
      "Epoch [1/10], Step[2901/60000], Loss: 3.3858\n",
      "Epoch [1/10], Step[3001/60000], Loss: 3.2655\n",
      "Epoch [1/10], Step[3101/60000], Loss: 3.1223\n",
      "Epoch [1/10], Step[3201/60000], Loss: 2.9846\n",
      "Epoch [1/10], Step[3301/60000], Loss: 2.7719\n",
      "Epoch [1/10], Step[3401/60000], Loss: 2.6812\n",
      "Epoch [1/10], Step[3501/60000], Loss: 2.5299\n",
      "Epoch [1/10], Step[3601/60000], Loss: 2.5448\n",
      "Epoch [1/10], Step[3701/60000], Loss: 2.1978\n",
      "Epoch [1/10], Step[3801/60000], Loss: 2.1895\n",
      "Epoch [1/10], Step[3901/60000], Loss: 2.0778\n",
      "Epoch [1/10], Step[4001/60000], Loss: 1.9972\n",
      "Epoch [1/10], Step[4101/60000], Loss: 2.0476\n",
      "Epoch [1/10], Step[4201/60000], Loss: 1.7182\n",
      "Epoch [1/10], Step[4301/60000], Loss: 1.7734\n",
      "Epoch [1/10], Step[4401/60000], Loss: 1.7196\n",
      "Epoch [1/10], Step[4501/60000], Loss: 1.5950\n",
      "Epoch [1/10], Step[4601/60000], Loss: 1.6531\n",
      "Epoch [1/10], Step[4701/60000], Loss: 1.5741\n",
      "Epoch [1/10], Step[4801/60000], Loss: 1.6092\n",
      "Epoch [1/10], Step[4901/60000], Loss: 1.4730\n",
      "Epoch [1/10], Step[5001/60000], Loss: 1.4378\n",
      "Epoch [1/10], Step[5101/60000], Loss: 1.4810\n",
      "Epoch [1/10], Step[5201/60000], Loss: 1.3163\n",
      "Epoch [1/10], Step[5301/60000], Loss: 1.3210\n",
      "Epoch [1/10], Step[5401/60000], Loss: 1.3206\n",
      "Epoch [1/10], Step[5501/60000], Loss: 1.1925\n",
      "Epoch [1/10], Step[5601/60000], Loss: 1.2789\n",
      "Epoch [1/10], Step[5701/60000], Loss: 1.2545\n",
      "Epoch [1/10], Step[5801/60000], Loss: 1.1838\n",
      "Epoch [1/10], Step[5901/60000], Loss: 1.1379\n",
      "Epoch [1/10], Step[6001/60000], Loss: 1.0900\n",
      "Epoch [1/10], Step[6101/60000], Loss: 1.0069\n",
      "Epoch [1/10], Step[6201/60000], Loss: 1.1319\n",
      "Epoch [1/10], Step[6301/60000], Loss: 0.9743\n",
      "Epoch [1/10], Step[6401/60000], Loss: 1.1036\n",
      "Epoch [1/10], Step[6501/60000], Loss: 0.8420\n",
      "Epoch [1/10], Step[6601/60000], Loss: 0.8809\n",
      "Epoch [1/10], Step[6701/60000], Loss: 0.9497\n",
      "Epoch [1/10], Step[6801/60000], Loss: 1.1367\n",
      "Epoch [1/10], Step[6901/60000], Loss: 0.9195\n",
      "Epoch [1/10], Step[7001/60000], Loss: 0.9680\n",
      "Epoch [1/10], Step[7101/60000], Loss: 0.9114\n",
      "Epoch [1/10], Step[7201/60000], Loss: 1.1582\n",
      "Epoch [1/10], Step[7301/60000], Loss: 0.9637\n",
      "Epoch [1/10], Step[7401/60000], Loss: 0.9189\n",
      "Epoch [1/10], Step[7501/60000], Loss: 0.8944\n",
      "Epoch [1/10], Step[7601/60000], Loss: 0.9182\n",
      "Epoch [1/10], Step[7701/60000], Loss: 0.8416\n",
      "Epoch [1/10], Step[7801/60000], Loss: 0.7743\n",
      "Epoch [1/10], Step[7901/60000], Loss: 0.9368\n",
      "Epoch [1/10], Step[8001/60000], Loss: 0.6919\n",
      "Epoch [1/10], Step[8101/60000], Loss: 0.7202\n",
      "Epoch [1/10], Step[8201/60000], Loss: 0.8748\n",
      "Epoch [1/10], Step[8301/60000], Loss: 0.7010\n",
      "Epoch [1/10], Step[8401/60000], Loss: 0.9640\n",
      "Epoch [1/10], Step[8501/60000], Loss: 0.5427\n",
      "Epoch [1/10], Step[8601/60000], Loss: 0.8360\n",
      "Epoch [1/10], Step[8701/60000], Loss: 0.9079\n",
      "Epoch [1/10], Step[8801/60000], Loss: 0.9263\n",
      "Epoch [1/10], Step[8901/60000], Loss: 0.6895\n",
      "Epoch [1/10], Step[9001/60000], Loss: 0.4735\n",
      "Epoch [1/10], Step[9101/60000], Loss: 0.5731\n",
      "Epoch [1/10], Step[9201/60000], Loss: 0.7379\n",
      "Epoch [1/10], Step[9301/60000], Loss: 0.8654\n",
      "Epoch [1/10], Step[9401/60000], Loss: 0.7435\n",
      "Epoch [1/10], Step[9501/60000], Loss: 1.0602\n",
      "Epoch [1/10], Step[9601/60000], Loss: 0.7807\n",
      "Epoch [1/10], Step[9701/60000], Loss: 0.7635\n",
      "Epoch [1/10], Step[9801/60000], Loss: 0.5058\n",
      "Epoch [1/10], Step[9901/60000], Loss: 0.5350\n",
      "Epoch [1/10], Step[10001/60000], Loss: 0.6873\n",
      "Epoch [1/10], Step[10101/60000], Loss: 0.5209\n",
      "Epoch [1/10], Step[10201/60000], Loss: 0.6823\n",
      "Epoch [1/10], Step[10301/60000], Loss: 0.4535\n",
      "Epoch [1/10], Step[10401/60000], Loss: 0.5139\n",
      "Epoch [1/10], Step[10501/60000], Loss: 0.4804\n",
      "Epoch [1/10], Step[10601/60000], Loss: 0.4778\n",
      "Epoch [1/10], Step[10701/60000], Loss: 0.7314\n",
      "Epoch [1/10], Step[10801/60000], Loss: 0.4448\n",
      "Epoch [1/10], Step[10901/60000], Loss: 0.4756\n",
      "Epoch [1/10], Step[11001/60000], Loss: 0.4207\n",
      "Epoch [1/10], Step[11101/60000], Loss: 0.4396\n",
      "Epoch [1/10], Step[11201/60000], Loss: 0.7426\n",
      "Epoch [1/10], Step[11301/60000], Loss: 0.4972\n",
      "Epoch [1/10], Step[11401/60000], Loss: 0.3627\n",
      "Epoch [1/10], Step[11501/60000], Loss: 0.7559\n",
      "Epoch [1/10], Step[11601/60000], Loss: 0.6078\n",
      "Epoch [1/10], Step[11701/60000], Loss: 0.6442\n",
      "Epoch [1/10], Step[11801/60000], Loss: 0.7683\n",
      "Epoch [1/10], Step[11901/60000], Loss: 0.4675\n",
      "Epoch [1/10], Step[12001/60000], Loss: 0.5396\n",
      "Epoch [1/10], Step[12101/60000], Loss: 0.4370\n",
      "Epoch [1/10], Step[12201/60000], Loss: 0.5132\n",
      "Epoch [1/10], Step[12301/60000], Loss: 0.5528\n",
      "Epoch [1/10], Step[12401/60000], Loss: 0.5692\n",
      "Epoch [1/10], Step[12501/60000], Loss: 0.7648\n",
      "Epoch [1/10], Step[12601/60000], Loss: 0.8651\n",
      "Epoch [1/10], Step[12701/60000], Loss: 0.4846\n",
      "Epoch [1/10], Step[12801/60000], Loss: 0.5162\n",
      "Epoch [1/10], Step[12901/60000], Loss: 0.8087\n",
      "Epoch [1/10], Step[13001/60000], Loss: 0.9347\n",
      "Epoch [1/10], Step[13101/60000], Loss: 0.6092\n",
      "Epoch [1/10], Step[13201/60000], Loss: 0.4538\n",
      "Epoch [1/10], Step[13301/60000], Loss: 0.4753\n",
      "Epoch [1/10], Step[13401/60000], Loss: 0.3587\n",
      "Epoch [1/10], Step[13501/60000], Loss: 0.3959\n",
      "Epoch [1/10], Step[13601/60000], Loss: 0.6014\n",
      "Epoch [1/10], Step[13701/60000], Loss: 0.5313\n",
      "Epoch [1/10], Step[13801/60000], Loss: 0.4441\n",
      "Epoch [1/10], Step[13901/60000], Loss: 0.7548\n",
      "Epoch [1/10], Step[14001/60000], Loss: 0.4051\n",
      "Epoch [1/10], Step[14101/60000], Loss: 0.4560\n",
      "Epoch [1/10], Step[14201/60000], Loss: 0.4445\n",
      "Epoch [1/10], Step[14301/60000], Loss: 0.5777\n",
      "Epoch [1/10], Step[14401/60000], Loss: 0.3714\n",
      "Epoch [1/10], Step[14501/60000], Loss: 0.5762\n",
      "Epoch [1/10], Step[14601/60000], Loss: 0.8218\n",
      "Epoch [1/10], Step[14701/60000], Loss: 0.8492\n",
      "Epoch [1/10], Step[14801/60000], Loss: 0.5232\n",
      "Epoch [1/10], Step[14901/60000], Loss: 0.3503\n",
      "Epoch [1/10], Step[15001/60000], Loss: 0.3764\n",
      "Epoch [1/10], Step[15101/60000], Loss: 0.6292\n",
      "Epoch [1/10], Step[15201/60000], Loss: 0.4954\n",
      "Epoch [1/10], Step[15301/60000], Loss: 0.3134\n",
      "Epoch [1/10], Step[15401/60000], Loss: 0.4541\n",
      "Epoch [1/10], Step[15501/60000], Loss: 0.5200\n",
      "Epoch [1/10], Step[15601/60000], Loss: 0.3189\n",
      "Epoch [1/10], Step[15701/60000], Loss: 0.5367\n",
      "Epoch [1/10], Step[15801/60000], Loss: 0.4734\n",
      "Epoch [1/10], Step[15901/60000], Loss: 0.5249\n",
      "Epoch [1/10], Step[16001/60000], Loss: 0.4862\n",
      "Epoch [1/10], Step[16101/60000], Loss: 0.4148\n",
      "Epoch [1/10], Step[16201/60000], Loss: 0.2440\n",
      "Epoch [1/10], Step[16301/60000], Loss: 0.3408\n",
      "Epoch [1/10], Step[16401/60000], Loss: 0.3119\n",
      "Epoch [1/10], Step[16501/60000], Loss: 0.4616\n",
      "Epoch [1/10], Step[16601/60000], Loss: 0.4964\n",
      "Epoch [1/10], Step[16701/60000], Loss: 0.4417\n",
      "Epoch [1/10], Step[16801/60000], Loss: 0.4250\n",
      "Epoch [1/10], Step[16901/60000], Loss: 0.3995\n",
      "Epoch [1/10], Step[17001/60000], Loss: 0.8611\n",
      "Epoch [1/10], Step[17101/60000], Loss: 0.3968\n",
      "Epoch [1/10], Step[17201/60000], Loss: 0.3728\n",
      "Epoch [1/10], Step[17301/60000], Loss: 0.4694\n",
      "Epoch [1/10], Step[17401/60000], Loss: 0.4909\n",
      "Epoch [1/10], Step[17501/60000], Loss: 0.5925\n",
      "Epoch [1/10], Step[17601/60000], Loss: 0.4947\n",
      "Epoch [1/10], Step[17701/60000], Loss: 0.4427\n",
      "Epoch [1/10], Step[17801/60000], Loss: 0.4726\n",
      "Epoch [1/10], Step[17901/60000], Loss: 0.2741\n",
      "Epoch [1/10], Step[18001/60000], Loss: 0.2796\n",
      "Epoch [1/10], Step[18101/60000], Loss: 0.2294\n",
      "Epoch [1/10], Step[18201/60000], Loss: 0.2199\n",
      "Epoch [1/10], Step[18301/60000], Loss: 0.3139\n",
      "Epoch [1/10], Step[18401/60000], Loss: 0.3703\n",
      "Epoch [1/10], Step[18501/60000], Loss: 0.3358\n",
      "Epoch [1/10], Step[18601/60000], Loss: 0.3995\n",
      "Epoch [1/10], Step[18701/60000], Loss: 0.5035\n",
      "Epoch [1/10], Step[18801/60000], Loss: 0.2528\n",
      "Epoch [1/10], Step[18901/60000], Loss: 0.3434\n",
      "Epoch [1/10], Step[19001/60000], Loss: 0.4177\n",
      "Epoch [1/10], Step[19101/60000], Loss: 0.3674\n",
      "Epoch [1/10], Step[19201/60000], Loss: 0.2738\n",
      "Epoch [1/10], Step[19301/60000], Loss: 0.3854\n",
      "Epoch [1/10], Step[19401/60000], Loss: 0.1954\n",
      "Epoch [1/10], Step[19501/60000], Loss: 0.4295\n",
      "Epoch [1/10], Step[19601/60000], Loss: 0.1199\n",
      "Epoch [1/10], Step[19701/60000], Loss: 0.2117\n",
      "Epoch [1/10], Step[19801/60000], Loss: 0.3668\n",
      "Epoch [1/10], Step[19901/60000], Loss: 0.3588\n",
      "Epoch [1/10], Step[20001/60000], Loss: 0.5929\n",
      "Epoch [1/10], Step[20101/60000], Loss: 0.5141\n",
      "Epoch [1/10], Step[20201/60000], Loss: 0.3108\n",
      "Epoch [1/10], Step[20301/60000], Loss: 0.2631\n",
      "Epoch [1/10], Step[20401/60000], Loss: 0.1770\n",
      "Epoch [1/10], Step[20501/60000], Loss: 0.2950\n",
      "Epoch [1/10], Step[20601/60000], Loss: 0.4029\n",
      "Epoch [1/10], Step[20701/60000], Loss: 0.4677\n",
      "Epoch [1/10], Step[20801/60000], Loss: 0.4421\n",
      "Epoch [1/10], Step[20901/60000], Loss: 0.5775\n",
      "Epoch [1/10], Step[21001/60000], Loss: 0.4563\n",
      "Epoch [1/10], Step[21101/60000], Loss: 0.3067\n",
      "Epoch [1/10], Step[21201/60000], Loss: 0.2273\n",
      "Epoch [1/10], Step[21301/60000], Loss: 0.4847\n",
      "Epoch [1/10], Step[21401/60000], Loss: 0.3790\n",
      "Epoch [1/10], Step[21501/60000], Loss: 0.3459\n",
      "Epoch [1/10], Step[21601/60000], Loss: 0.7327\n",
      "Epoch [1/10], Step[21701/60000], Loss: 0.2068\n",
      "Epoch [1/10], Step[21801/60000], Loss: 0.1377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step[21901/60000], Loss: 0.2868\n",
      "Epoch [1/10], Step[22001/60000], Loss: 0.1590\n",
      "Epoch [1/10], Step[22101/60000], Loss: 0.4308\n",
      "Epoch [1/10], Step[22201/60000], Loss: 0.3979\n",
      "Epoch [1/10], Step[22301/60000], Loss: 0.1566\n",
      "Epoch [1/10], Step[22401/60000], Loss: 0.4934\n",
      "Epoch [1/10], Step[22501/60000], Loss: 0.8327\n",
      "Epoch [1/10], Step[22601/60000], Loss: 0.3898\n",
      "Epoch [1/10], Step[22701/60000], Loss: 0.2677\n",
      "Epoch [1/10], Step[22801/60000], Loss: 0.1880\n",
      "Epoch [1/10], Step[22901/60000], Loss: 0.1596\n",
      "Epoch [1/10], Step[23001/60000], Loss: 0.3279\n",
      "Epoch [1/10], Step[23101/60000], Loss: 0.3876\n",
      "Epoch [1/10], Step[23201/60000], Loss: 0.1948\n",
      "Epoch [1/10], Step[23301/60000], Loss: 0.2003\n",
      "Epoch [1/10], Step[23401/60000], Loss: 0.2931\n",
      "Epoch [1/10], Step[23501/60000], Loss: 0.2582\n",
      "Epoch [1/10], Step[23601/60000], Loss: 0.3191\n",
      "Epoch [1/10], Step[23701/60000], Loss: 0.3440\n",
      "Epoch [1/10], Step[23801/60000], Loss: 0.3406\n",
      "Epoch [1/10], Step[23901/60000], Loss: 0.4240\n",
      "Epoch [1/10], Step[24001/60000], Loss: 0.2105\n",
      "Epoch [1/10], Step[24101/60000], Loss: 0.2311\n",
      "Epoch [1/10], Step[24201/60000], Loss: 0.4798\n",
      "Epoch [1/10], Step[24301/60000], Loss: 0.2176\n",
      "Epoch [1/10], Step[24401/60000], Loss: 0.2738\n",
      "Epoch [1/10], Step[24501/60000], Loss: 0.3130\n",
      "Epoch [1/10], Step[24601/60000], Loss: 0.2703\n",
      "Epoch [1/10], Step[24701/60000], Loss: 0.3529\n",
      "Epoch [1/10], Step[24801/60000], Loss: 0.2038\n",
      "Epoch [1/10], Step[24901/60000], Loss: 0.3542\n",
      "Epoch [1/10], Step[25001/60000], Loss: 0.2072\n",
      "Epoch [1/10], Step[25101/60000], Loss: 0.2530\n",
      "Epoch [1/10], Step[25201/60000], Loss: 0.2172\n",
      "Epoch [1/10], Step[25301/60000], Loss: 0.2647\n",
      "Epoch [1/10], Step[25401/60000], Loss: 0.1922\n",
      "Epoch [1/10], Step[25501/60000], Loss: 0.3545\n",
      "Epoch [1/10], Step[25601/60000], Loss: 0.4061\n",
      "Epoch [1/10], Step[25701/60000], Loss: 0.2752\n",
      "Epoch [1/10], Step[25801/60000], Loss: 0.3408\n",
      "Epoch [1/10], Step[25901/60000], Loss: 0.3026\n",
      "Epoch [1/10], Step[26001/60000], Loss: 0.1745\n",
      "Epoch [1/10], Step[26101/60000], Loss: 0.2147\n",
      "Epoch [1/10], Step[26201/60000], Loss: 0.2991\n",
      "Epoch [1/10], Step[26301/60000], Loss: 0.4528\n",
      "Epoch [1/10], Step[26401/60000], Loss: 0.3723\n",
      "Epoch [1/10], Step[26501/60000], Loss: 0.3713\n",
      "Epoch [1/10], Step[26601/60000], Loss: 0.4066\n",
      "Epoch [1/10], Step[26701/60000], Loss: 0.4242\n",
      "Epoch [1/10], Step[26801/60000], Loss: 0.3871\n",
      "Epoch [1/10], Step[26901/60000], Loss: 0.1638\n",
      "Epoch [1/10], Step[27001/60000], Loss: 0.1516\n",
      "Epoch [1/10], Step[27101/60000], Loss: 0.4428\n",
      "Epoch [1/10], Step[27201/60000], Loss: 0.2369\n",
      "Epoch [1/10], Step[27301/60000], Loss: 0.1966\n",
      "Epoch [1/10], Step[27401/60000], Loss: 0.2364\n",
      "Epoch [1/10], Step[27501/60000], Loss: 0.2537\n",
      "Epoch [1/10], Step[27601/60000], Loss: 0.3009\n",
      "Epoch [1/10], Step[27701/60000], Loss: 0.2779\n",
      "Epoch [1/10], Step[27801/60000], Loss: 0.2399\n",
      "Epoch [1/10], Step[27901/60000], Loss: 0.1658\n",
      "Epoch [1/10], Step[28001/60000], Loss: 0.1128\n",
      "Epoch [1/10], Step[28101/60000], Loss: 0.2252\n",
      "Epoch [1/10], Step[28201/60000], Loss: 0.2340\n",
      "Epoch [1/10], Step[28301/60000], Loss: 0.3620\n",
      "Epoch [1/10], Step[28401/60000], Loss: 0.1210\n",
      "Epoch [1/10], Step[28501/60000], Loss: 0.2724\n",
      "Epoch [1/10], Step[28601/60000], Loss: 0.6093\n",
      "Epoch [1/10], Step[28701/60000], Loss: 0.3555\n",
      "Epoch [1/10], Step[28801/60000], Loss: 0.2353\n",
      "Epoch [1/10], Step[28901/60000], Loss: 0.2264\n",
      "Epoch [1/10], Step[29001/60000], Loss: 0.4373\n",
      "Epoch [1/10], Step[29101/60000], Loss: 0.2848\n",
      "Epoch [1/10], Step[29201/60000], Loss: 0.3130\n",
      "Epoch [1/10], Step[29301/60000], Loss: 0.3574\n",
      "Epoch [1/10], Step[29401/60000], Loss: 0.2957\n",
      "Epoch [1/10], Step[29501/60000], Loss: 0.3079\n",
      "Epoch [1/10], Step[29601/60000], Loss: 0.2860\n",
      "Epoch [1/10], Step[29701/60000], Loss: 0.2949\n",
      "Epoch [1/10], Step[29801/60000], Loss: 0.3775\n",
      "Epoch [1/10], Step[29901/60000], Loss: 0.5446\n",
      "Epoch [1/10], Step[30001/60000], Loss: 0.3567\n",
      "Epoch [1/10], Step[30101/60000], Loss: 0.3762\n",
      "Epoch [1/10], Step[30201/60000], Loss: 0.1538\n",
      "Epoch [1/10], Step[30301/60000], Loss: 0.1827\n",
      "Epoch [1/10], Step[30401/60000], Loss: 0.2063\n",
      "Epoch [1/10], Step[30501/60000], Loss: 0.2948\n",
      "Epoch [1/10], Step[30601/60000], Loss: 0.3612\n",
      "Epoch [1/10], Step[30701/60000], Loss: 0.2082\n",
      "Epoch [1/10], Step[30801/60000], Loss: 0.5921\n",
      "Epoch [1/10], Step[30901/60000], Loss: 0.3946\n",
      "Epoch [1/10], Step[31001/60000], Loss: 0.2480\n",
      "Epoch [1/10], Step[31101/60000], Loss: 0.5926\n",
      "Epoch [1/10], Step[31201/60000], Loss: 0.3146\n",
      "Epoch [1/10], Step[31301/60000], Loss: 0.4543\n",
      "Epoch [1/10], Step[31401/60000], Loss: 0.2879\n",
      "Epoch [1/10], Step[31501/60000], Loss: 0.2408\n",
      "Epoch [1/10], Step[31601/60000], Loss: 0.5169\n",
      "Epoch [1/10], Step[31701/60000], Loss: 0.4397\n",
      "Epoch [1/10], Step[31801/60000], Loss: 0.2158\n",
      "Epoch [1/10], Step[31901/60000], Loss: 0.1609\n",
      "Epoch [1/10], Step[32001/60000], Loss: 0.6658\n",
      "Epoch [1/10], Step[32101/60000], Loss: 0.3387\n",
      "Epoch [1/10], Step[32201/60000], Loss: 0.3227\n",
      "Epoch [1/10], Step[32301/60000], Loss: 0.4910\n",
      "Epoch [1/10], Step[32401/60000], Loss: 0.3680\n",
      "Epoch [1/10], Step[32501/60000], Loss: 0.1875\n",
      "Epoch [1/10], Step[32601/60000], Loss: 0.1979\n",
      "Epoch [1/10], Step[32701/60000], Loss: 0.3220\n",
      "Epoch [1/10], Step[32801/60000], Loss: 0.2288\n",
      "Epoch [1/10], Step[32901/60000], Loss: 0.2042\n",
      "Epoch [1/10], Step[33001/60000], Loss: 0.2288\n",
      "Epoch [1/10], Step[33101/60000], Loss: 0.1714\n",
      "Epoch [1/10], Step[33201/60000], Loss: 0.2085\n",
      "Epoch [1/10], Step[33301/60000], Loss: 0.3328\n",
      "Epoch [1/10], Step[33401/60000], Loss: 0.2353\n",
      "Epoch [1/10], Step[33501/60000], Loss: 0.2919\n",
      "Epoch [1/10], Step[33601/60000], Loss: 0.1832\n",
      "Epoch [1/10], Step[33701/60000], Loss: 0.2464\n",
      "Epoch [1/10], Step[33801/60000], Loss: 0.0775\n",
      "Epoch [1/10], Step[33901/60000], Loss: 0.1157\n",
      "Epoch [1/10], Step[34001/60000], Loss: 0.2634\n",
      "Epoch [1/10], Step[34101/60000], Loss: 0.1598\n",
      "Epoch [1/10], Step[34201/60000], Loss: 0.0973\n",
      "Epoch [1/10], Step[34301/60000], Loss: 0.1563\n",
      "Epoch [1/10], Step[34401/60000], Loss: 0.3627\n",
      "Epoch [1/10], Step[34501/60000], Loss: 0.3331\n",
      "Epoch [1/10], Step[34601/60000], Loss: 0.2744\n",
      "Epoch [1/10], Step[34701/60000], Loss: 0.3406\n",
      "Epoch [1/10], Step[34801/60000], Loss: 0.3363\n",
      "Epoch [1/10], Step[34901/60000], Loss: 0.1974\n",
      "Epoch [1/10], Step[35001/60000], Loss: 0.1893\n",
      "Epoch [1/10], Step[35101/60000], Loss: 0.1822\n",
      "Epoch [1/10], Step[35201/60000], Loss: 0.2819\n",
      "Epoch [1/10], Step[35301/60000], Loss: 0.1723\n",
      "Epoch [1/10], Step[35401/60000], Loss: 0.3569\n",
      "Epoch [1/10], Step[35501/60000], Loss: 0.1105\n",
      "Epoch [1/10], Step[35601/60000], Loss: 0.2544\n",
      "Epoch [1/10], Step[35701/60000], Loss: 0.1084\n",
      "Epoch [1/10], Step[35801/60000], Loss: 0.1389\n",
      "Epoch [1/10], Step[35901/60000], Loss: 0.2163\n",
      "Epoch [1/10], Step[36001/60000], Loss: 0.3995\n",
      "Epoch [1/10], Step[36101/60000], Loss: 0.2152\n",
      "Epoch [1/10], Step[36201/60000], Loss: 0.1712\n",
      "Epoch [1/10], Step[36301/60000], Loss: 0.1361\n",
      "Epoch [1/10], Step[36401/60000], Loss: 0.3707\n",
      "Epoch [1/10], Step[36501/60000], Loss: 0.1692\n",
      "Epoch [1/10], Step[36601/60000], Loss: 0.0964\n",
      "Epoch [1/10], Step[36701/60000], Loss: 0.2332\n",
      "Epoch [1/10], Step[36801/60000], Loss: 0.2473\n",
      "Epoch [1/10], Step[36901/60000], Loss: 0.1723\n",
      "Epoch [1/10], Step[37001/60000], Loss: 0.2718\n",
      "Epoch [1/10], Step[37101/60000], Loss: 0.2806\n",
      "Epoch [1/10], Step[37201/60000], Loss: 0.4583\n",
      "Epoch [1/10], Step[37301/60000], Loss: 0.6843\n",
      "Epoch [1/10], Step[37401/60000], Loss: 0.7768\n",
      "Epoch [1/10], Step[37501/60000], Loss: 0.3866\n",
      "Epoch [1/10], Step[37601/60000], Loss: 0.1422\n",
      "Epoch [1/10], Step[37701/60000], Loss: 0.3716\n",
      "Epoch [1/10], Step[37801/60000], Loss: 0.5416\n",
      "Epoch [1/10], Step[37901/60000], Loss: 0.2540\n",
      "Epoch [1/10], Step[38001/60000], Loss: 0.2106\n",
      "Epoch [1/10], Step[38101/60000], Loss: 0.1372\n",
      "Epoch [1/10], Step[38201/60000], Loss: 0.2113\n",
      "Epoch [1/10], Step[38301/60000], Loss: 0.6672\n",
      "Epoch [1/10], Step[38401/60000], Loss: 0.0959\n",
      "Epoch [1/10], Step[38501/60000], Loss: 0.3600\n",
      "Epoch [1/10], Step[38601/60000], Loss: 0.4131\n",
      "Epoch [1/10], Step[38701/60000], Loss: 0.5887\n",
      "Epoch [1/10], Step[38801/60000], Loss: 0.1333\n",
      "Epoch [1/10], Step[38901/60000], Loss: 0.2305\n",
      "Epoch [1/10], Step[39001/60000], Loss: 0.1729\n",
      "Epoch [1/10], Step[39101/60000], Loss: 0.2536\n",
      "Epoch [1/10], Step[39201/60000], Loss: 0.1137\n",
      "Epoch [1/10], Step[39301/60000], Loss: 0.6204\n",
      "Epoch [1/10], Step[39401/60000], Loss: 0.4591\n",
      "Epoch [1/10], Step[39501/60000], Loss: 0.1279\n",
      "Epoch [1/10], Step[39601/60000], Loss: 0.3530\n",
      "Epoch [1/10], Step[39701/60000], Loss: 0.2186\n",
      "Epoch [1/10], Step[39801/60000], Loss: 0.2844\n",
      "Epoch [1/10], Step[39901/60000], Loss: 0.3062\n",
      "Epoch [1/10], Step[40001/60000], Loss: 0.1598\n",
      "Epoch [1/10], Step[40101/60000], Loss: 0.3033\n",
      "Epoch [1/10], Step[40201/60000], Loss: 0.2670\n",
      "Epoch [1/10], Step[40301/60000], Loss: 0.2849\n",
      "Epoch [1/10], Step[40401/60000], Loss: 0.1668\n",
      "Epoch [1/10], Step[40501/60000], Loss: 0.1774\n",
      "Epoch [1/10], Step[40601/60000], Loss: 0.2185\n",
      "Epoch [1/10], Step[40701/60000], Loss: 0.2059\n",
      "Epoch [1/10], Step[40801/60000], Loss: 0.1585\n",
      "Epoch [1/10], Step[40901/60000], Loss: 0.1650\n",
      "Epoch [1/10], Step[41001/60000], Loss: 0.2804\n",
      "Epoch [1/10], Step[41101/60000], Loss: 0.1864\n",
      "Epoch [1/10], Step[41201/60000], Loss: 0.3534\n",
      "Epoch [1/10], Step[41301/60000], Loss: 0.4264\n",
      "Epoch [1/10], Step[41401/60000], Loss: 0.6714\n",
      "Epoch [1/10], Step[41501/60000], Loss: 0.2331\n",
      "Epoch [1/10], Step[41601/60000], Loss: 0.1456\n",
      "Epoch [1/10], Step[41701/60000], Loss: 0.1840\n",
      "Epoch [1/10], Step[41801/60000], Loss: 0.1333\n",
      "Epoch [1/10], Step[41901/60000], Loss: 0.2462\n",
      "Epoch [1/10], Step[42001/60000], Loss: 0.2480\n",
      "Epoch [1/10], Step[42101/60000], Loss: 0.3088\n",
      "Epoch [1/10], Step[42201/60000], Loss: 0.2274\n",
      "Epoch [1/10], Step[42301/60000], Loss: 0.3557\n",
      "Epoch [1/10], Step[42401/60000], Loss: 0.3694\n",
      "Epoch [1/10], Step[42501/60000], Loss: 0.4553\n",
      "Epoch [1/10], Step[42601/60000], Loss: 0.1814\n",
      "Epoch [1/10], Step[42701/60000], Loss: 0.4379\n",
      "Epoch [1/10], Step[42801/60000], Loss: 0.3428\n",
      "Epoch [1/10], Step[42901/60000], Loss: 0.3363\n",
      "Epoch [1/10], Step[43001/60000], Loss: 0.2692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step[43101/60000], Loss: 0.3023\n",
      "Epoch [1/10], Step[43201/60000], Loss: 0.1660\n",
      "Epoch [1/10], Step[43301/60000], Loss: 0.1011\n",
      "Epoch [1/10], Step[43401/60000], Loss: 0.0919\n",
      "Epoch [1/10], Step[43501/60000], Loss: 0.7080\n",
      "Epoch [1/10], Step[43601/60000], Loss: 0.2383\n",
      "Epoch [1/10], Step[43701/60000], Loss: 0.3226\n",
      "Epoch [1/10], Step[43801/60000], Loss: 0.3952\n",
      "Epoch [1/10], Step[43901/60000], Loss: 0.2943\n",
      "Epoch [1/10], Step[44001/60000], Loss: 0.2206\n",
      "Epoch [1/10], Step[44101/60000], Loss: 0.4027\n",
      "Epoch [1/10], Step[44201/60000], Loss: 0.4152\n",
      "Epoch [1/10], Step[44301/60000], Loss: 0.3212\n",
      "Epoch [1/10], Step[44401/60000], Loss: 0.3640\n",
      "Epoch [1/10], Step[44501/60000], Loss: 0.1366\n",
      "Epoch [1/10], Step[44601/60000], Loss: 0.1080\n",
      "Epoch [1/10], Step[44701/60000], Loss: 0.3004\n",
      "Epoch [1/10], Step[44801/60000], Loss: 0.3847\n",
      "Epoch [1/10], Step[44901/60000], Loss: 0.3360\n",
      "Epoch [1/10], Step[45001/60000], Loss: 0.3487\n",
      "Epoch [1/10], Step[45101/60000], Loss: 0.7467\n",
      "Epoch [1/10], Step[45201/60000], Loss: 0.2183\n",
      "Epoch [1/10], Step[45301/60000], Loss: 0.1573\n",
      "Epoch [1/10], Step[45401/60000], Loss: 0.6026\n",
      "Epoch [1/10], Step[45501/60000], Loss: 0.2767\n",
      "Epoch [1/10], Step[45601/60000], Loss: 0.3300\n",
      "Epoch [1/10], Step[45701/60000], Loss: 0.2003\n",
      "Epoch [1/10], Step[45801/60000], Loss: 0.3458\n",
      "Epoch [1/10], Step[45901/60000], Loss: 0.3268\n",
      "Epoch [1/10], Step[46001/60000], Loss: 0.3163\n",
      "Epoch [1/10], Step[46101/60000], Loss: 0.3127\n",
      "Epoch [1/10], Step[46201/60000], Loss: 0.5323\n",
      "Epoch [1/10], Step[46301/60000], Loss: 0.2794\n",
      "Epoch [1/10], Step[46401/60000], Loss: 0.3216\n",
      "Epoch [1/10], Step[46501/60000], Loss: 0.1172\n",
      "Epoch [1/10], Step[46601/60000], Loss: 0.2517\n",
      "Epoch [1/10], Step[46701/60000], Loss: 0.9292\n",
      "Epoch [1/10], Step[46801/60000], Loss: 0.2401\n",
      "Epoch [1/10], Step[46901/60000], Loss: 0.1341\n",
      "Epoch [1/10], Step[47001/60000], Loss: 0.1994\n",
      "Epoch [1/10], Step[47101/60000], Loss: 0.1463\n",
      "Epoch [1/10], Step[47201/60000], Loss: 0.5266\n",
      "Epoch [1/10], Step[47301/60000], Loss: 0.2906\n",
      "Epoch [1/10], Step[47401/60000], Loss: 0.5961\n",
      "Epoch [1/10], Step[47501/60000], Loss: 0.2042\n",
      "Epoch [1/10], Step[47601/60000], Loss: 0.3090\n",
      "Epoch [1/10], Step[47701/60000], Loss: 0.4719\n",
      "Epoch [1/10], Step[47801/60000], Loss: 0.1531\n",
      "Epoch [1/10], Step[47901/60000], Loss: 0.4011\n",
      "Epoch [1/10], Step[48001/60000], Loss: 0.1604\n",
      "Epoch [1/10], Step[48101/60000], Loss: 0.1841\n",
      "Epoch [1/10], Step[48201/60000], Loss: 0.1278\n",
      "Epoch [1/10], Step[48301/60000], Loss: 0.3538\n",
      "Epoch [1/10], Step[48401/60000], Loss: 0.0836\n",
      "Epoch [1/10], Step[48501/60000], Loss: 1.0035\n",
      "Epoch [1/10], Step[48601/60000], Loss: 0.2066\n",
      "Epoch [1/10], Step[48701/60000], Loss: 0.1103\n",
      "Epoch [1/10], Step[48801/60000], Loss: 0.0876\n",
      "Epoch [1/10], Step[48901/60000], Loss: 0.6343\n",
      "Epoch [1/10], Step[49001/60000], Loss: 0.6954\n",
      "Epoch [1/10], Step[49101/60000], Loss: 0.3182\n",
      "Epoch [1/10], Step[49201/60000], Loss: 0.2658\n",
      "Epoch [1/10], Step[49301/60000], Loss: 0.1558\n",
      "Epoch [1/10], Step[49401/60000], Loss: 0.3359\n",
      "Epoch [1/10], Step[49501/60000], Loss: 0.4458\n",
      "Epoch [1/10], Step[49601/60000], Loss: 0.3035\n",
      "Epoch [1/10], Step[49701/60000], Loss: 0.1751\n",
      "Epoch [1/10], Step[49801/60000], Loss: 0.4706\n",
      "Epoch [1/10], Step[49901/60000], Loss: 0.2279\n",
      "Epoch [1/10], Step[50001/60000], Loss: 0.1909\n",
      "Epoch [1/10], Step[50101/60000], Loss: 0.1326\n",
      "Epoch [1/10], Step[50201/60000], Loss: 0.3622\n",
      "Epoch [1/10], Step[50301/60000], Loss: 0.3236\n",
      "Epoch [1/10], Step[50401/60000], Loss: 0.3773\n",
      "Epoch [1/10], Step[50501/60000], Loss: 0.2950\n",
      "Epoch [1/10], Step[50601/60000], Loss: 0.2310\n",
      "Epoch [1/10], Step[50701/60000], Loss: 0.2096\n",
      "Epoch [1/10], Step[50801/60000], Loss: 0.1684\n",
      "Epoch [1/10], Step[50901/60000], Loss: 0.1420\n",
      "Epoch [1/10], Step[51001/60000], Loss: 0.1343\n",
      "Epoch [1/10], Step[51101/60000], Loss: 0.1324\n",
      "Epoch [1/10], Step[51201/60000], Loss: 0.2546\n",
      "Epoch [1/10], Step[51301/60000], Loss: 0.1818\n",
      "Epoch [1/10], Step[51401/60000], Loss: 0.1853\n",
      "Epoch [1/10], Step[51501/60000], Loss: 0.1211\n",
      "Epoch [1/10], Step[51601/60000], Loss: 0.1536\n",
      "Epoch [1/10], Step[51701/60000], Loss: 0.5476\n",
      "Epoch [1/10], Step[51801/60000], Loss: 0.0888\n",
      "Epoch [1/10], Step[51901/60000], Loss: 0.2118\n",
      "Epoch [1/10], Step[52001/60000], Loss: 0.1652\n",
      "Epoch [1/10], Step[52101/60000], Loss: 0.3237\n",
      "Epoch [1/10], Step[52201/60000], Loss: 0.2547\n",
      "Epoch [1/10], Step[52301/60000], Loss: 0.2806\n",
      "Epoch [1/10], Step[52401/60000], Loss: 0.1156\n",
      "Epoch [1/10], Step[52501/60000], Loss: 0.0982\n",
      "Epoch [1/10], Step[52601/60000], Loss: 0.2036\n",
      "Epoch [1/10], Step[52701/60000], Loss: 0.2536\n",
      "Epoch [1/10], Step[52801/60000], Loss: 0.2626\n",
      "Epoch [1/10], Step[52901/60000], Loss: 0.4867\n",
      "Epoch [1/10], Step[53001/60000], Loss: 0.2002\n",
      "Epoch [1/10], Step[53101/60000], Loss: 0.2569\n",
      "Epoch [1/10], Step[53201/60000], Loss: 0.2254\n",
      "Epoch [1/10], Step[53301/60000], Loss: 0.1024\n",
      "Epoch [1/10], Step[53401/60000], Loss: 0.1345\n",
      "Epoch [1/10], Step[53501/60000], Loss: 0.2674\n",
      "Epoch [1/10], Step[53601/60000], Loss: 0.1806\n",
      "Epoch [1/10], Step[53701/60000], Loss: 0.1593\n",
      "Epoch [1/10], Step[53801/60000], Loss: 0.2053\n",
      "Epoch [1/10], Step[53901/60000], Loss: 0.3942\n",
      "Epoch [1/10], Step[54001/60000], Loss: 0.4263\n",
      "Epoch [1/10], Step[54101/60000], Loss: 0.1884\n",
      "Epoch [1/10], Step[54201/60000], Loss: 0.1280\n",
      "Epoch [1/10], Step[54301/60000], Loss: 0.1539\n",
      "Epoch [1/10], Step[54401/60000], Loss: 0.1459\n",
      "Epoch [1/10], Step[54501/60000], Loss: 0.2751\n",
      "Epoch [1/10], Step[54601/60000], Loss: 0.0882\n",
      "Epoch [1/10], Step[54701/60000], Loss: 0.1657\n",
      "Epoch [1/10], Step[54801/60000], Loss: 0.2635\n",
      "Epoch [1/10], Step[54901/60000], Loss: 0.3865\n",
      "Epoch [1/10], Step[55001/60000], Loss: 0.1130\n",
      "Epoch [1/10], Step[55101/60000], Loss: 0.1639\n",
      "Epoch [1/10], Step[55201/60000], Loss: 0.1966\n",
      "Epoch [1/10], Step[55301/60000], Loss: 0.1928\n",
      "Epoch [1/10], Step[55401/60000], Loss: 0.1565\n",
      "Epoch [1/10], Step[55501/60000], Loss: 0.0891\n",
      "Epoch [1/10], Step[55601/60000], Loss: 0.1534\n",
      "Epoch [1/10], Step[55701/60000], Loss: 0.1974\n",
      "Epoch [1/10], Step[55801/60000], Loss: 0.2479\n",
      "Epoch [1/10], Step[55901/60000], Loss: 0.1275\n",
      "Epoch [1/10], Step[56001/60000], Loss: 0.1966\n",
      "Epoch [1/10], Step[56101/60000], Loss: 0.0765\n",
      "Epoch [1/10], Step[56201/60000], Loss: 0.2684\n",
      "Epoch [1/10], Step[56301/60000], Loss: 0.1581\n",
      "Epoch [1/10], Step[56401/60000], Loss: 0.2986\n",
      "Epoch [1/10], Step[56501/60000], Loss: 0.1249\n",
      "Epoch [1/10], Step[56601/60000], Loss: 0.1812\n",
      "Epoch [1/10], Step[56701/60000], Loss: 0.0465\n",
      "Epoch [1/10], Step[56801/60000], Loss: 0.1158\n",
      "Epoch [1/10], Step[56901/60000], Loss: 0.0735\n",
      "Epoch [1/10], Step[57001/60000], Loss: 0.1910\n",
      "Epoch [1/10], Step[57101/60000], Loss: 0.0575\n",
      "Epoch [1/10], Step[57201/60000], Loss: 0.1228\n",
      "Epoch [1/10], Step[57301/60000], Loss: 0.1606\n",
      "Epoch [1/10], Step[57401/60000], Loss: 0.1465\n",
      "Epoch [1/10], Step[57501/60000], Loss: 0.1464\n",
      "Epoch [1/10], Step[57601/60000], Loss: 0.2248\n",
      "Epoch [1/10], Step[57701/60000], Loss: 0.3239\n",
      "Epoch [1/10], Step[57801/60000], Loss: 0.0943\n",
      "Epoch [1/10], Step[57901/60000], Loss: 0.0817\n",
      "Epoch [1/10], Step[58001/60000], Loss: 0.1356\n",
      "Epoch [1/10], Step[58101/60000], Loss: 0.0879\n",
      "Epoch [1/10], Step[58201/60000], Loss: 0.0873\n",
      "Epoch [1/10], Step[58301/60000], Loss: 0.1008\n",
      "Epoch [1/10], Step[58401/60000], Loss: 0.1014\n",
      "Epoch [1/10], Step[58501/60000], Loss: 0.0748\n",
      "Epoch [1/10], Step[58601/60000], Loss: 0.0820\n",
      "Epoch [1/10], Step[58701/60000], Loss: 0.0847\n",
      "Epoch [1/10], Step[58801/60000], Loss: 0.2217\n",
      "Epoch [1/10], Step[58901/60000], Loss: 0.0822\n",
      "Epoch [1/10], Step[59001/60000], Loss: 0.0215\n",
      "Epoch [1/10], Step[59101/60000], Loss: 0.0146\n",
      "Epoch [1/10], Step[59201/60000], Loss: 0.1086\n",
      "Epoch [1/10], Step[59301/60000], Loss: 0.2180\n",
      "Epoch [1/10], Step[59401/60000], Loss: 0.1229\n",
      "Epoch [1/10], Step[59501/60000], Loss: 0.0282\n",
      "Epoch [1/10], Step[59601/60000], Loss: 0.0847\n",
      "Epoch [1/10], Step[59701/60000], Loss: 0.5176\n",
      "Epoch [1/10], Step[59801/60000], Loss: 0.0106\n",
      "Epoch [1/10], Step[59901/60000], Loss: 1.2297\n",
      "Epoch [2/10], Step[1/60000], Loss: 0.1634\n",
      "Epoch [2/10], Step[101/60000], Loss: 0.1938\n",
      "Epoch [2/10], Step[201/60000], Loss: 0.1860\n",
      "Epoch [2/10], Step[301/60000], Loss: 0.0707\n",
      "Epoch [2/10], Step[401/60000], Loss: 0.3276\n",
      "Epoch [2/10], Step[501/60000], Loss: 0.2664\n",
      "Epoch [2/10], Step[601/60000], Loss: 0.3632\n",
      "Epoch [2/10], Step[701/60000], Loss: 0.2393\n",
      "Epoch [2/10], Step[801/60000], Loss: 0.3483\n",
      "Epoch [2/10], Step[901/60000], Loss: 0.1842\n",
      "Epoch [2/10], Step[1001/60000], Loss: 0.4200\n",
      "Epoch [2/10], Step[1101/60000], Loss: 0.3995\n",
      "Epoch [2/10], Step[1201/60000], Loss: 0.3045\n",
      "Epoch [2/10], Step[1301/60000], Loss: 0.2615\n",
      "Epoch [2/10], Step[1401/60000], Loss: 0.1520\n",
      "Epoch [2/10], Step[1501/60000], Loss: 0.3710\n",
      "Epoch [2/10], Step[1601/60000], Loss: 0.1540\n",
      "Epoch [2/10], Step[1701/60000], Loss: 0.1034\n",
      "Epoch [2/10], Step[1801/60000], Loss: 0.2613\n",
      "Epoch [2/10], Step[1901/60000], Loss: 0.1070\n",
      "Epoch [2/10], Step[2001/60000], Loss: 0.1417\n",
      "Epoch [2/10], Step[2101/60000], Loss: 0.1383\n",
      "Epoch [2/10], Step[2201/60000], Loss: 0.1198\n",
      "Epoch [2/10], Step[2301/60000], Loss: 0.0630\n",
      "Epoch [2/10], Step[2401/60000], Loss: 0.2456\n",
      "Epoch [2/10], Step[2501/60000], Loss: 0.7474\n",
      "Epoch [2/10], Step[2601/60000], Loss: 0.2035\n",
      "Epoch [2/10], Step[2701/60000], Loss: 0.1709\n",
      "Epoch [2/10], Step[2801/60000], Loss: 0.1288\n",
      "Epoch [2/10], Step[2901/60000], Loss: 0.1580\n",
      "Epoch [2/10], Step[3001/60000], Loss: 0.1691\n",
      "Epoch [2/10], Step[3101/60000], Loss: 0.0809\n",
      "Epoch [2/10], Step[3201/60000], Loss: 0.3324\n",
      "Epoch [2/10], Step[3301/60000], Loss: 0.1229\n",
      "Epoch [2/10], Step[3401/60000], Loss: 0.0829\n",
      "Epoch [2/10], Step[3501/60000], Loss: 0.2733\n",
      "Epoch [2/10], Step[3601/60000], Loss: 0.2324\n",
      "Epoch [2/10], Step[3701/60000], Loss: 0.2430\n",
      "Epoch [2/10], Step[3801/60000], Loss: 0.1085\n",
      "Epoch [2/10], Step[3901/60000], Loss: 0.0877\n",
      "Epoch [2/10], Step[4001/60000], Loss: 0.3009\n",
      "Epoch [2/10], Step[4101/60000], Loss: 0.2400\n",
      "Epoch [2/10], Step[4201/60000], Loss: 0.2539\n",
      "Epoch [2/10], Step[4301/60000], Loss: 0.1668\n",
      "Epoch [2/10], Step[4401/60000], Loss: 0.0844\n",
      "Epoch [2/10], Step[4501/60000], Loss: 0.1242\n",
      "Epoch [2/10], Step[4601/60000], Loss: 0.1742\n",
      "Epoch [2/10], Step[4701/60000], Loss: 0.0825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step[4801/60000], Loss: 0.1329\n",
      "Epoch [2/10], Step[4901/60000], Loss: 0.2284\n",
      "Epoch [2/10], Step[5001/60000], Loss: 0.1578\n",
      "Epoch [2/10], Step[5101/60000], Loss: 0.4219\n",
      "Epoch [2/10], Step[5201/60000], Loss: 0.0841\n",
      "Epoch [2/10], Step[5301/60000], Loss: 0.1915\n",
      "Epoch [2/10], Step[5401/60000], Loss: 0.0895\n",
      "Epoch [2/10], Step[5501/60000], Loss: 0.1562\n",
      "Epoch [2/10], Step[5601/60000], Loss: 0.1926\n",
      "Epoch [2/10], Step[5701/60000], Loss: 0.1651\n",
      "Epoch [2/10], Step[5801/60000], Loss: 0.2808\n",
      "Epoch [2/10], Step[5901/60000], Loss: 0.0742\n",
      "Epoch [2/10], Step[6001/60000], Loss: 0.0838\n",
      "Epoch [2/10], Step[6101/60000], Loss: 0.1403\n",
      "Epoch [2/10], Step[6201/60000], Loss: 0.1830\n",
      "Epoch [2/10], Step[6301/60000], Loss: 0.1574\n",
      "Epoch [2/10], Step[6401/60000], Loss: 0.1402\n",
      "Epoch [2/10], Step[6501/60000], Loss: 0.0724\n",
      "Epoch [2/10], Step[6601/60000], Loss: 0.1738\n",
      "Epoch [2/10], Step[6701/60000], Loss: 0.1281\n",
      "Epoch [2/10], Step[6801/60000], Loss: 1.1325\n",
      "Epoch [2/10], Step[6901/60000], Loss: 0.3044\n",
      "Epoch [2/10], Step[7001/60000], Loss: 0.1754\n",
      "Epoch [2/10], Step[7101/60000], Loss: 0.1620\n",
      "Epoch [2/10], Step[7201/60000], Loss: 0.2547\n",
      "Epoch [2/10], Step[7301/60000], Loss: 0.2417\n",
      "Epoch [2/10], Step[7401/60000], Loss: 0.1184\n",
      "Epoch [2/10], Step[7501/60000], Loss: 0.1885\n",
      "Epoch [2/10], Step[7601/60000], Loss: 0.1396\n",
      "Epoch [2/10], Step[7701/60000], Loss: 0.1424\n",
      "Epoch [2/10], Step[7801/60000], Loss: 0.2621\n",
      "Epoch [2/10], Step[7901/60000], Loss: 0.1036\n",
      "Epoch [2/10], Step[8001/60000], Loss: 0.1784\n",
      "Epoch [2/10], Step[8101/60000], Loss: 0.1400\n",
      "Epoch [2/10], Step[8201/60000], Loss: 0.3023\n",
      "Epoch [2/10], Step[8301/60000], Loss: 0.1093\n",
      "Epoch [2/10], Step[8401/60000], Loss: 0.2137\n",
      "Epoch [2/10], Step[8501/60000], Loss: 0.0635\n",
      "Epoch [2/10], Step[8601/60000], Loss: 0.2067\n",
      "Epoch [2/10], Step[8701/60000], Loss: 0.3484\n",
      "Epoch [2/10], Step[8801/60000], Loss: 0.3485\n",
      "Epoch [2/10], Step[8901/60000], Loss: 0.1864\n",
      "Epoch [2/10], Step[9001/60000], Loss: 0.1567\n",
      "Epoch [2/10], Step[9101/60000], Loss: 0.3047\n",
      "Epoch [2/10], Step[9201/60000], Loss: 0.3308\n",
      "Epoch [2/10], Step[9301/60000], Loss: 0.1829\n",
      "Epoch [2/10], Step[9401/60000], Loss: 0.2420\n",
      "Epoch [2/10], Step[9501/60000], Loss: 0.2353\n",
      "Epoch [2/10], Step[9601/60000], Loss: 0.1953\n",
      "Epoch [2/10], Step[9701/60000], Loss: 0.1690\n",
      "Epoch [2/10], Step[9801/60000], Loss: 0.0885\n",
      "Epoch [2/10], Step[9901/60000], Loss: 0.0958\n",
      "Epoch [2/10], Step[10001/60000], Loss: 0.1723\n",
      "Epoch [2/10], Step[10101/60000], Loss: 0.1717\n",
      "Epoch [2/10], Step[10201/60000], Loss: 0.1993\n",
      "Epoch [2/10], Step[10301/60000], Loss: 0.0841\n",
      "Epoch [2/10], Step[10401/60000], Loss: 0.0509\n",
      "Epoch [2/10], Step[10501/60000], Loss: 0.0539\n",
      "Epoch [2/10], Step[10601/60000], Loss: 0.0669\n",
      "Epoch [2/10], Step[10701/60000], Loss: 0.2262\n",
      "Epoch [2/10], Step[10801/60000], Loss: 0.1710\n",
      "Epoch [2/10], Step[10901/60000], Loss: 0.1035\n",
      "Epoch [2/10], Step[11001/60000], Loss: 0.0765\n",
      "Epoch [2/10], Step[11101/60000], Loss: 0.0602\n",
      "Epoch [2/10], Step[11201/60000], Loss: 0.4668\n",
      "Epoch [2/10], Step[11301/60000], Loss: 0.0720\n",
      "Epoch [2/10], Step[11401/60000], Loss: 0.3726\n",
      "Epoch [2/10], Step[11501/60000], Loss: 0.4861\n",
      "Epoch [2/10], Step[11601/60000], Loss: 0.2214\n",
      "Epoch [2/10], Step[11701/60000], Loss: 0.2861\n",
      "Epoch [2/10], Step[11801/60000], Loss: 0.1518\n",
      "Epoch [2/10], Step[11901/60000], Loss: 0.1237\n",
      "Epoch [2/10], Step[12001/60000], Loss: 0.1598\n",
      "Epoch [2/10], Step[12101/60000], Loss: 0.1425\n",
      "Epoch [2/10], Step[12201/60000], Loss: 0.1581\n",
      "Epoch [2/10], Step[12301/60000], Loss: 0.4278\n",
      "Epoch [2/10], Step[12401/60000], Loss: 0.5101\n",
      "Epoch [2/10], Step[12501/60000], Loss: 0.4124\n",
      "Epoch [2/10], Step[12601/60000], Loss: 0.4281\n",
      "Epoch [2/10], Step[12701/60000], Loss: 0.1956\n",
      "Epoch [2/10], Step[12801/60000], Loss: 0.1368\n",
      "Epoch [2/10], Step[12901/60000], Loss: 0.1591\n",
      "Epoch [2/10], Step[13001/60000], Loss: 0.3310\n",
      "Epoch [2/10], Step[13101/60000], Loss: 0.1488\n",
      "Epoch [2/10], Step[13201/60000], Loss: 0.1721\n",
      "Epoch [2/10], Step[13301/60000], Loss: 0.1110\n",
      "Epoch [2/10], Step[13401/60000], Loss: 0.1593\n",
      "Epoch [2/10], Step[13501/60000], Loss: 0.0849\n",
      "Epoch [2/10], Step[13601/60000], Loss: 0.1692\n",
      "Epoch [2/10], Step[13701/60000], Loss: 0.1643\n",
      "Epoch [2/10], Step[13801/60000], Loss: 0.1175\n",
      "Epoch [2/10], Step[13901/60000], Loss: 0.2617\n",
      "Epoch [2/10], Step[14001/60000], Loss: 0.1424\n",
      "Epoch [2/10], Step[14101/60000], Loss: 0.1355\n",
      "Epoch [2/10], Step[14201/60000], Loss: 0.2194\n",
      "Epoch [2/10], Step[14301/60000], Loss: 0.2617\n",
      "Epoch [2/10], Step[14401/60000], Loss: 0.0838\n",
      "Epoch [2/10], Step[14501/60000], Loss: 0.1729\n",
      "Epoch [2/10], Step[14601/60000], Loss: 0.1717\n",
      "Epoch [2/10], Step[14701/60000], Loss: 0.6583\n",
      "Epoch [2/10], Step[14801/60000], Loss: 0.1463\n",
      "Epoch [2/10], Step[14901/60000], Loss: 0.0886\n",
      "Epoch [2/10], Step[15001/60000], Loss: 0.1115\n",
      "Epoch [2/10], Step[15101/60000], Loss: 0.4741\n",
      "Epoch [2/10], Step[15201/60000], Loss: 0.2805\n",
      "Epoch [2/10], Step[15301/60000], Loss: 0.1512\n",
      "Epoch [2/10], Step[15401/60000], Loss: 0.1335\n",
      "Epoch [2/10], Step[15501/60000], Loss: 0.1686\n",
      "Epoch [2/10], Step[15601/60000], Loss: 0.1048\n",
      "Epoch [2/10], Step[15701/60000], Loss: 0.2621\n",
      "Epoch [2/10], Step[15801/60000], Loss: 0.1778\n",
      "Epoch [2/10], Step[15901/60000], Loss: 0.2330\n",
      "Epoch [2/10], Step[16001/60000], Loss: 0.2003\n",
      "Epoch [2/10], Step[16101/60000], Loss: 0.1166\n",
      "Epoch [2/10], Step[16201/60000], Loss: 0.0776\n",
      "Epoch [2/10], Step[16301/60000], Loss: 0.0852\n",
      "Epoch [2/10], Step[16401/60000], Loss: 0.1543\n",
      "Epoch [2/10], Step[16501/60000], Loss: 0.1586\n",
      "Epoch [2/10], Step[16601/60000], Loss: 0.1987\n",
      "Epoch [2/10], Step[16701/60000], Loss: 0.2381\n",
      "Epoch [2/10], Step[16801/60000], Loss: 0.3402\n",
      "Epoch [2/10], Step[16901/60000], Loss: 0.1768\n",
      "Epoch [2/10], Step[17001/60000], Loss: 0.1202\n",
      "Epoch [2/10], Step[17101/60000], Loss: 0.1855\n",
      "Epoch [2/10], Step[17201/60000], Loss: 0.2073\n",
      "Epoch [2/10], Step[17301/60000], Loss: 0.1426\n",
      "Epoch [2/10], Step[17401/60000], Loss: 0.1310\n",
      "Epoch [2/10], Step[17501/60000], Loss: 0.2087\n",
      "Epoch [2/10], Step[17601/60000], Loss: 0.1864\n",
      "Epoch [2/10], Step[17701/60000], Loss: 0.2231\n",
      "Epoch [2/10], Step[17801/60000], Loss: 0.1937\n",
      "Epoch [2/10], Step[17901/60000], Loss: 0.1088\n",
      "Epoch [2/10], Step[18001/60000], Loss: 0.1151\n",
      "Epoch [2/10], Step[18101/60000], Loss: 0.0878\n",
      "Epoch [2/10], Step[18201/60000], Loss: 0.0882\n",
      "Epoch [2/10], Step[18301/60000], Loss: 0.0891\n",
      "Epoch [2/10], Step[18401/60000], Loss: 0.1071\n",
      "Epoch [2/10], Step[18501/60000], Loss: 0.1575\n",
      "Epoch [2/10], Step[18601/60000], Loss: 0.1062\n",
      "Epoch [2/10], Step[18701/60000], Loss: 0.2514\n",
      "Epoch [2/10], Step[18801/60000], Loss: 0.0813\n",
      "Epoch [2/10], Step[18901/60000], Loss: 0.0934\n",
      "Epoch [2/10], Step[19001/60000], Loss: 0.1384\n",
      "Epoch [2/10], Step[19101/60000], Loss: 0.1895\n",
      "Epoch [2/10], Step[19201/60000], Loss: 0.1359\n",
      "Epoch [2/10], Step[19301/60000], Loss: 0.1243\n",
      "Epoch [2/10], Step[19401/60000], Loss: 0.0732\n",
      "Epoch [2/10], Step[19501/60000], Loss: 0.1553\n",
      "Epoch [2/10], Step[19601/60000], Loss: 0.0925\n",
      "Epoch [2/10], Step[19701/60000], Loss: 0.1035\n",
      "Epoch [2/10], Step[19801/60000], Loss: 0.1982\n",
      "Epoch [2/10], Step[19901/60000], Loss: 0.1082\n",
      "Epoch [2/10], Step[20001/60000], Loss: 0.1896\n",
      "Epoch [2/10], Step[20101/60000], Loss: 0.2031\n",
      "Epoch [2/10], Step[20201/60000], Loss: 0.1369\n",
      "Epoch [2/10], Step[20301/60000], Loss: 0.1099\n",
      "Epoch [2/10], Step[20401/60000], Loss: 0.0490\n",
      "Epoch [2/10], Step[20501/60000], Loss: 0.0895\n",
      "Epoch [2/10], Step[20601/60000], Loss: 0.2267\n",
      "Epoch [2/10], Step[20701/60000], Loss: 0.3185\n",
      "Epoch [2/10], Step[20801/60000], Loss: 0.1923\n",
      "Epoch [2/10], Step[20901/60000], Loss: 0.2757\n",
      "Epoch [2/10], Step[21001/60000], Loss: 0.2462\n",
      "Epoch [2/10], Step[21101/60000], Loss: 0.1465\n",
      "Epoch [2/10], Step[21201/60000], Loss: 0.0930\n",
      "Epoch [2/10], Step[21301/60000], Loss: 0.1977\n",
      "Epoch [2/10], Step[21401/60000], Loss: 0.1221\n",
      "Epoch [2/10], Step[21501/60000], Loss: 0.1745\n",
      "Epoch [2/10], Step[21601/60000], Loss: 0.2158\n",
      "Epoch [2/10], Step[21701/60000], Loss: 0.0905\n",
      "Epoch [2/10], Step[21801/60000], Loss: 0.0799\n",
      "Epoch [2/10], Step[21901/60000], Loss: 0.1546\n",
      "Epoch [2/10], Step[22001/60000], Loss: 0.0528\n",
      "Epoch [2/10], Step[22101/60000], Loss: 0.1865\n",
      "Epoch [2/10], Step[22201/60000], Loss: 0.1658\n",
      "Epoch [2/10], Step[22301/60000], Loss: 0.0477\n",
      "Epoch [2/10], Step[22401/60000], Loss: 0.2980\n",
      "Epoch [2/10], Step[22501/60000], Loss: 0.2523\n",
      "Epoch [2/10], Step[22601/60000], Loss: 0.1402\n",
      "Epoch [2/10], Step[22701/60000], Loss: 0.2818\n",
      "Epoch [2/10], Step[22801/60000], Loss: 0.0824\n",
      "Epoch [2/10], Step[22901/60000], Loss: 0.0625\n",
      "Epoch [2/10], Step[23001/60000], Loss: 0.1672\n",
      "Epoch [2/10], Step[23101/60000], Loss: 0.1029\n",
      "Epoch [2/10], Step[23201/60000], Loss: 0.1986\n",
      "Epoch [2/10], Step[23301/60000], Loss: 0.1249\n",
      "Epoch [2/10], Step[23401/60000], Loss: 0.1948\n",
      "Epoch [2/10], Step[23501/60000], Loss: 0.1031\n",
      "Epoch [2/10], Step[23601/60000], Loss: 0.1690\n",
      "Epoch [2/10], Step[23701/60000], Loss: 0.2214\n",
      "Epoch [2/10], Step[23801/60000], Loss: 0.0968\n",
      "Epoch [2/10], Step[23901/60000], Loss: 0.2611\n",
      "Epoch [2/10], Step[24001/60000], Loss: 0.1189\n",
      "Epoch [2/10], Step[24101/60000], Loss: 0.0914\n",
      "Epoch [2/10], Step[24201/60000], Loss: 0.1968\n",
      "Epoch [2/10], Step[24301/60000], Loss: 0.0897\n",
      "Epoch [2/10], Step[24401/60000], Loss: 0.0647\n",
      "Epoch [2/10], Step[24501/60000], Loss: 0.1963\n",
      "Epoch [2/10], Step[24601/60000], Loss: 0.1175\n",
      "Epoch [2/10], Step[24701/60000], Loss: 0.1294\n",
      "Epoch [2/10], Step[24801/60000], Loss: 0.1599\n",
      "Epoch [2/10], Step[24901/60000], Loss: 0.1250\n",
      "Epoch [2/10], Step[25001/60000], Loss: 0.0875\n",
      "Epoch [2/10], Step[25101/60000], Loss: 0.1514\n",
      "Epoch [2/10], Step[25201/60000], Loss: 0.0903\n",
      "Epoch [2/10], Step[25301/60000], Loss: 0.1062\n",
      "Epoch [2/10], Step[25401/60000], Loss: 0.0656\n",
      "Epoch [2/10], Step[25501/60000], Loss: 0.1897\n",
      "Epoch [2/10], Step[25601/60000], Loss: 0.1582\n",
      "Epoch [2/10], Step[25701/60000], Loss: 0.1668\n",
      "Epoch [2/10], Step[25801/60000], Loss: 0.2003\n",
      "Epoch [2/10], Step[25901/60000], Loss: 0.1022\n",
      "Epoch [2/10], Step[26001/60000], Loss: 0.0780\n",
      "Epoch [2/10], Step[26101/60000], Loss: 0.1299\n",
      "Epoch [2/10], Step[26201/60000], Loss: 0.1107\n",
      "Epoch [2/10], Step[26301/60000], Loss: 0.2933\n",
      "Epoch [2/10], Step[26401/60000], Loss: 0.3896\n",
      "Epoch [2/10], Step[26501/60000], Loss: 0.2338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step[26601/60000], Loss: 0.1795\n",
      "Epoch [2/10], Step[26701/60000], Loss: 0.2509\n",
      "Epoch [2/10], Step[26801/60000], Loss: 0.2922\n",
      "Epoch [2/10], Step[26901/60000], Loss: 0.0566\n",
      "Epoch [2/10], Step[27001/60000], Loss: 0.0509\n",
      "Epoch [2/10], Step[27101/60000], Loss: 0.2857\n",
      "Epoch [2/10], Step[27201/60000], Loss: 0.1738\n",
      "Epoch [2/10], Step[27301/60000], Loss: 0.0688\n",
      "Epoch [2/10], Step[27401/60000], Loss: 0.0991\n",
      "Epoch [2/10], Step[27501/60000], Loss: 0.1442\n",
      "Epoch [2/10], Step[27601/60000], Loss: 0.1190\n",
      "Epoch [2/10], Step[27701/60000], Loss: 0.1007\n",
      "Epoch [2/10], Step[27801/60000], Loss: 0.1839\n",
      "Epoch [2/10], Step[27901/60000], Loss: 0.0658\n",
      "Epoch [2/10], Step[28001/60000], Loss: 0.1704\n",
      "Epoch [2/10], Step[28101/60000], Loss: 0.0883\n",
      "Epoch [2/10], Step[28201/60000], Loss: 0.1314\n",
      "Epoch [2/10], Step[28301/60000], Loss: 0.2584\n",
      "Epoch [2/10], Step[28401/60000], Loss: 0.0759\n",
      "Epoch [2/10], Step[28501/60000], Loss: 0.1529\n",
      "Epoch [2/10], Step[28601/60000], Loss: 0.3036\n",
      "Epoch [2/10], Step[28701/60000], Loss: 0.1622\n",
      "Epoch [2/10], Step[28801/60000], Loss: 0.0785\n",
      "Epoch [2/10], Step[28901/60000], Loss: 0.1149\n",
      "Epoch [2/10], Step[29001/60000], Loss: 0.1590\n",
      "Epoch [2/10], Step[29101/60000], Loss: 0.1384\n",
      "Epoch [2/10], Step[29201/60000], Loss: 0.1633\n",
      "Epoch [2/10], Step[29301/60000], Loss: 0.2302\n",
      "Epoch [2/10], Step[29401/60000], Loss: 0.1412\n",
      "Epoch [2/10], Step[29501/60000], Loss: 0.0538\n",
      "Epoch [2/10], Step[29601/60000], Loss: 0.1031\n",
      "Epoch [2/10], Step[29701/60000], Loss: 0.1367\n",
      "Epoch [2/10], Step[29801/60000], Loss: 0.1868\n",
      "Epoch [2/10], Step[29901/60000], Loss: 0.2496\n",
      "Epoch [2/10], Step[30001/60000], Loss: 0.1701\n",
      "Epoch [2/10], Step[30101/60000], Loss: 0.1763\n",
      "Epoch [2/10], Step[30201/60000], Loss: 0.0431\n",
      "Epoch [2/10], Step[30301/60000], Loss: 0.0691\n",
      "Epoch [2/10], Step[30401/60000], Loss: 0.0932\n",
      "Epoch [2/10], Step[30501/60000], Loss: 0.1134\n",
      "Epoch [2/10], Step[30601/60000], Loss: 0.1440\n",
      "Epoch [2/10], Step[30701/60000], Loss: 0.0929\n",
      "Epoch [2/10], Step[30801/60000], Loss: 0.1620\n",
      "Epoch [2/10], Step[30901/60000], Loss: 0.1702\n",
      "Epoch [2/10], Step[31001/60000], Loss: 0.0643\n",
      "Epoch [2/10], Step[31101/60000], Loss: 0.4485\n",
      "Epoch [2/10], Step[31201/60000], Loss: 0.7547\n",
      "Epoch [2/10], Step[31301/60000], Loss: 0.2331\n",
      "Epoch [2/10], Step[31401/60000], Loss: 0.1328\n",
      "Epoch [2/10], Step[31501/60000], Loss: 0.1521\n",
      "Epoch [2/10], Step[31601/60000], Loss: 0.4925\n",
      "Epoch [2/10], Step[31701/60000], Loss: 0.3452\n",
      "Epoch [2/10], Step[31801/60000], Loss: 0.1402\n",
      "Epoch [2/10], Step[31901/60000], Loss: 0.1202\n",
      "Epoch [2/10], Step[32001/60000], Loss: 0.4705\n",
      "Epoch [2/10], Step[32101/60000], Loss: 0.1446\n",
      "Epoch [2/10], Step[32201/60000], Loss: 0.2073\n",
      "Epoch [2/10], Step[32301/60000], Loss: 0.3407\n",
      "Epoch [2/10], Step[32401/60000], Loss: 0.2323\n",
      "Epoch [2/10], Step[32501/60000], Loss: 0.0795\n",
      "Epoch [2/10], Step[32601/60000], Loss: 0.2162\n",
      "Epoch [2/10], Step[32701/60000], Loss: 0.1987\n",
      "Epoch [2/10], Step[32801/60000], Loss: 0.1044\n",
      "Epoch [2/10], Step[32901/60000], Loss: 0.1089\n",
      "Epoch [2/10], Step[33001/60000], Loss: 0.1072\n",
      "Epoch [2/10], Step[33101/60000], Loss: 0.0786\n",
      "Epoch [2/10], Step[33201/60000], Loss: 0.0783\n",
      "Epoch [2/10], Step[33301/60000], Loss: 0.1819\n",
      "Epoch [2/10], Step[33401/60000], Loss: 0.1011\n",
      "Epoch [2/10], Step[33501/60000], Loss: 0.1458\n",
      "Epoch [2/10], Step[33601/60000], Loss: 0.1237\n",
      "Epoch [2/10], Step[33701/60000], Loss: 0.2088\n",
      "Epoch [2/10], Step[33801/60000], Loss: 0.0422\n",
      "Epoch [2/10], Step[33901/60000], Loss: 0.0596\n",
      "Epoch [2/10], Step[34001/60000], Loss: 0.1740\n",
      "Epoch [2/10], Step[34101/60000], Loss: 0.0546\n",
      "Epoch [2/10], Step[34201/60000], Loss: 0.0338\n",
      "Epoch [2/10], Step[34301/60000], Loss: 0.0685\n",
      "Epoch [2/10], Step[34401/60000], Loss: 0.2140\n",
      "Epoch [2/10], Step[34501/60000], Loss: 0.2127\n",
      "Epoch [2/10], Step[34601/60000], Loss: 0.2063\n",
      "Epoch [2/10], Step[34701/60000], Loss: 0.2792\n",
      "Epoch [2/10], Step[34801/60000], Loss: 0.2383\n",
      "Epoch [2/10], Step[34901/60000], Loss: 0.1384\n",
      "Epoch [2/10], Step[35001/60000], Loss: 0.0994\n",
      "Epoch [2/10], Step[35101/60000], Loss: 0.2367\n",
      "Epoch [2/10], Step[35201/60000], Loss: 0.1963\n",
      "Epoch [2/10], Step[35301/60000], Loss: 0.1127\n",
      "Epoch [2/10], Step[35401/60000], Loss: 0.2347\n",
      "Epoch [2/10], Step[35501/60000], Loss: 0.0372\n",
      "Epoch [2/10], Step[35601/60000], Loss: 0.1640\n",
      "Epoch [2/10], Step[35701/60000], Loss: 0.0522\n",
      "Epoch [2/10], Step[35801/60000], Loss: 0.0946\n",
      "Epoch [2/10], Step[35901/60000], Loss: 0.1193\n",
      "Epoch [2/10], Step[36001/60000], Loss: 0.2053\n",
      "Epoch [2/10], Step[36101/60000], Loss: 0.1607\n",
      "Epoch [2/10], Step[36201/60000], Loss: 0.1152\n",
      "Epoch [2/10], Step[36301/60000], Loss: 0.0725\n",
      "Epoch [2/10], Step[36401/60000], Loss: 0.2415\n",
      "Epoch [2/10], Step[36501/60000], Loss: 0.0888\n",
      "Epoch [2/10], Step[36601/60000], Loss: 0.1437\n",
      "Epoch [2/10], Step[36701/60000], Loss: 0.1084\n",
      "Epoch [2/10], Step[36801/60000], Loss: 0.1463\n",
      "Epoch [2/10], Step[36901/60000], Loss: 0.1323\n",
      "Epoch [2/10], Step[37001/60000], Loss: 0.1635\n",
      "Epoch [2/10], Step[37101/60000], Loss: 0.1306\n",
      "Epoch [2/10], Step[37201/60000], Loss: 0.3018\n",
      "Epoch [2/10], Step[37301/60000], Loss: 0.3537\n",
      "Epoch [2/10], Step[37401/60000], Loss: 0.4249\n",
      "Epoch [2/10], Step[37501/60000], Loss: 0.1094\n",
      "Epoch [2/10], Step[37601/60000], Loss: 0.0706\n",
      "Epoch [2/10], Step[37701/60000], Loss: 0.4678\n",
      "Epoch [2/10], Step[37801/60000], Loss: 0.2492\n",
      "Epoch [2/10], Step[37901/60000], Loss: 0.1277\n",
      "Epoch [2/10], Step[38001/60000], Loss: 0.0784\n",
      "Epoch [2/10], Step[38101/60000], Loss: 0.0531\n",
      "Epoch [2/10], Step[38201/60000], Loss: 0.1022\n",
      "Epoch [2/10], Step[38301/60000], Loss: 0.3635\n",
      "Epoch [2/10], Step[38401/60000], Loss: 0.0629\n",
      "Epoch [2/10], Step[38501/60000], Loss: 0.1785\n",
      "Epoch [2/10], Step[38601/60000], Loss: 0.1662\n",
      "Epoch [2/10], Step[38701/60000], Loss: 0.1890\n",
      "Epoch [2/10], Step[38801/60000], Loss: 0.0469\n",
      "Epoch [2/10], Step[38901/60000], Loss: 0.2113\n",
      "Epoch [2/10], Step[39001/60000], Loss: 0.0980\n",
      "Epoch [2/10], Step[39101/60000], Loss: 0.1827\n",
      "Epoch [2/10], Step[39201/60000], Loss: 0.0681\n",
      "Epoch [2/10], Step[39301/60000], Loss: 0.3046\n",
      "Epoch [2/10], Step[39401/60000], Loss: 0.1867\n",
      "Epoch [2/10], Step[39501/60000], Loss: 0.0477\n",
      "Epoch [2/10], Step[39601/60000], Loss: 0.2099\n",
      "Epoch [2/10], Step[39701/60000], Loss: 0.0717\n",
      "Epoch [2/10], Step[39801/60000], Loss: 0.1770\n",
      "Epoch [2/10], Step[39901/60000], Loss: 0.1252\n",
      "Epoch [2/10], Step[40001/60000], Loss: 0.0597\n",
      "Epoch [2/10], Step[40101/60000], Loss: 0.0808\n",
      "Epoch [2/10], Step[40201/60000], Loss: 0.1125\n",
      "Epoch [2/10], Step[40301/60000], Loss: 0.1493\n",
      "Epoch [2/10], Step[40401/60000], Loss: 0.0452\n",
      "Epoch [2/10], Step[40501/60000], Loss: 0.0686\n",
      "Epoch [2/10], Step[40601/60000], Loss: 0.0733\n",
      "Epoch [2/10], Step[40701/60000], Loss: 0.0883\n",
      "Epoch [2/10], Step[40801/60000], Loss: 0.0747\n",
      "Epoch [2/10], Step[40901/60000], Loss: 0.1093\n",
      "Epoch [2/10], Step[41001/60000], Loss: 0.1525\n",
      "Epoch [2/10], Step[41101/60000], Loss: 0.0799\n",
      "Epoch [2/10], Step[41201/60000], Loss: 0.2183\n",
      "Epoch [2/10], Step[41301/60000], Loss: 0.2363\n",
      "Epoch [2/10], Step[41401/60000], Loss: 0.4366\n",
      "Epoch [2/10], Step[41501/60000], Loss: 0.1775\n",
      "Epoch [2/10], Step[41601/60000], Loss: 0.0975\n",
      "Epoch [2/10], Step[41701/60000], Loss: 0.0768\n",
      "Epoch [2/10], Step[41801/60000], Loss: 0.1191\n",
      "Epoch [2/10], Step[41901/60000], Loss: 0.1698\n",
      "Epoch [2/10], Step[42001/60000], Loss: 0.1151\n",
      "Epoch [2/10], Step[42101/60000], Loss: 0.1867\n",
      "Epoch [2/10], Step[42201/60000], Loss: 0.1184\n",
      "Epoch [2/10], Step[42301/60000], Loss: 0.1587\n",
      "Epoch [2/10], Step[42401/60000], Loss: 0.2102\n",
      "Epoch [2/10], Step[42501/60000], Loss: 0.3399\n",
      "Epoch [2/10], Step[42601/60000], Loss: 0.0552\n",
      "Epoch [2/10], Step[42701/60000], Loss: 0.1835\n",
      "Epoch [2/10], Step[42801/60000], Loss: 0.1891\n",
      "Epoch [2/10], Step[42901/60000], Loss: 0.1790\n",
      "Epoch [2/10], Step[43001/60000], Loss: 0.1693\n",
      "Epoch [2/10], Step[43101/60000], Loss: 0.1202\n",
      "Epoch [2/10], Step[43201/60000], Loss: 0.0714\n",
      "Epoch [2/10], Step[43301/60000], Loss: 0.0444\n",
      "Epoch [2/10], Step[43401/60000], Loss: 0.0661\n",
      "Epoch [2/10], Step[43501/60000], Loss: 0.7333\n",
      "Epoch [2/10], Step[43601/60000], Loss: 0.1380\n",
      "Epoch [2/10], Step[43701/60000], Loss: 0.1467\n",
      "Epoch [2/10], Step[43801/60000], Loss: 0.2323\n",
      "Epoch [2/10], Step[43901/60000], Loss: 0.1498\n",
      "Epoch [2/10], Step[44001/60000], Loss: 0.3195\n",
      "Epoch [2/10], Step[44101/60000], Loss: 0.2489\n",
      "Epoch [2/10], Step[44201/60000], Loss: 0.1756\n",
      "Epoch [2/10], Step[44301/60000], Loss: 0.2026\n",
      "Epoch [2/10], Step[44401/60000], Loss: 0.2471\n",
      "Epoch [2/10], Step[44501/60000], Loss: 0.0667\n",
      "Epoch [2/10], Step[44601/60000], Loss: 0.0880\n",
      "Epoch [2/10], Step[44701/60000], Loss: 0.3319\n",
      "Epoch [2/10], Step[44801/60000], Loss: 0.2795\n",
      "Epoch [2/10], Step[44901/60000], Loss: 0.3397\n",
      "Epoch [2/10], Step[45001/60000], Loss: 0.1962\n",
      "Epoch [2/10], Step[45101/60000], Loss: 0.1645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step[45201/60000], Loss: 0.1651\n",
      "Epoch [2/10], Step[45301/60000], Loss: 0.0798\n",
      "Epoch [2/10], Step[45401/60000], Loss: 0.1484\n",
      "Epoch [2/10], Step[45501/60000], Loss: 0.1925\n",
      "Epoch [2/10], Step[45601/60000], Loss: 0.2264\n",
      "Epoch [2/10], Step[45701/60000], Loss: 0.0840\n",
      "Epoch [2/10], Step[45801/60000], Loss: 0.1891\n",
      "Epoch [2/10], Step[45901/60000], Loss: 0.1824\n",
      "Epoch [2/10], Step[46001/60000], Loss: 0.3855\n",
      "Epoch [2/10], Step[46101/60000], Loss: 0.1471\n",
      "Epoch [2/10], Step[46201/60000], Loss: 0.2592\n",
      "Epoch [2/10], Step[46301/60000], Loss: 0.1724\n",
      "Epoch [2/10], Step[46401/60000], Loss: 0.2294\n",
      "Epoch [2/10], Step[46501/60000], Loss: 0.0453\n",
      "Epoch [2/10], Step[46601/60000], Loss: 0.0754\n",
      "Epoch [2/10], Step[46701/60000], Loss: 0.1248\n",
      "Epoch [2/10], Step[46801/60000], Loss: 0.1413\n",
      "Epoch [2/10], Step[46901/60000], Loss: 0.0943\n",
      "Epoch [2/10], Step[47001/60000], Loss: 0.1354\n",
      "Epoch [2/10], Step[47101/60000], Loss: 0.0933\n",
      "Epoch [2/10], Step[47201/60000], Loss: 0.3440\n",
      "Epoch [2/10], Step[47301/60000], Loss: 0.1673\n",
      "Epoch [2/10], Step[47401/60000], Loss: 0.1791\n",
      "Epoch [2/10], Step[47501/60000], Loss: 0.1105\n",
      "Epoch [2/10], Step[47601/60000], Loss: 0.1889\n",
      "Epoch [2/10], Step[47701/60000], Loss: 0.1319\n",
      "Epoch [2/10], Step[47801/60000], Loss: 0.1134\n",
      "Epoch [2/10], Step[47901/60000], Loss: 0.2122\n",
      "Epoch [2/10], Step[48001/60000], Loss: 0.1201\n",
      "Epoch [2/10], Step[48101/60000], Loss: 0.1255\n",
      "Epoch [2/10], Step[48201/60000], Loss: 0.0732\n",
      "Epoch [2/10], Step[48301/60000], Loss: 0.1627\n",
      "Epoch [2/10], Step[48401/60000], Loss: 0.0579\n",
      "Epoch [2/10], Step[48501/60000], Loss: 0.1521\n",
      "Epoch [2/10], Step[48601/60000], Loss: 0.1445\n",
      "Epoch [2/10], Step[48701/60000], Loss: 0.0538\n",
      "Epoch [2/10], Step[48801/60000], Loss: 0.0813\n",
      "Epoch [2/10], Step[48901/60000], Loss: 0.3565\n",
      "Epoch [2/10], Step[49001/60000], Loss: 0.4486\n",
      "Epoch [2/10], Step[49101/60000], Loss: 0.0939\n",
      "Epoch [2/10], Step[49201/60000], Loss: 0.1588\n",
      "Epoch [2/10], Step[49301/60000], Loss: 0.0764\n",
      "Epoch [2/10], Step[49401/60000], Loss: 0.2108\n",
      "Epoch [2/10], Step[49501/60000], Loss: 0.2859\n",
      "Epoch [2/10], Step[49601/60000], Loss: 0.1969\n",
      "Epoch [2/10], Step[49701/60000], Loss: 0.0951\n",
      "Epoch [2/10], Step[49801/60000], Loss: 0.3198\n",
      "Epoch [2/10], Step[49901/60000], Loss: 0.1110\n",
      "Epoch [2/10], Step[50001/60000], Loss: 0.1455\n",
      "Epoch [2/10], Step[50101/60000], Loss: 0.0671\n",
      "Epoch [2/10], Step[50201/60000], Loss: 0.2738\n",
      "Epoch [2/10], Step[50301/60000], Loss: 0.1737\n",
      "Epoch [2/10], Step[50401/60000], Loss: 0.2558\n",
      "Epoch [2/10], Step[50501/60000], Loss: 0.1660\n",
      "Epoch [2/10], Step[50601/60000], Loss: 0.1098\n",
      "Epoch [2/10], Step[50701/60000], Loss: 0.1097\n",
      "Epoch [2/10], Step[50801/60000], Loss: 0.0957\n",
      "Epoch [2/10], Step[50901/60000], Loss: 0.0870\n",
      "Epoch [2/10], Step[51001/60000], Loss: 0.0603\n",
      "Epoch [2/10], Step[51101/60000], Loss: 0.0995\n",
      "Epoch [2/10], Step[51201/60000], Loss: 0.1636\n",
      "Epoch [2/10], Step[51301/60000], Loss: 0.1071\n",
      "Epoch [2/10], Step[51401/60000], Loss: 0.1634\n",
      "Epoch [2/10], Step[51501/60000], Loss: 0.0686\n",
      "Epoch [2/10], Step[51601/60000], Loss: 0.0997\n",
      "Epoch [2/10], Step[51701/60000], Loss: 0.2552\n",
      "Epoch [2/10], Step[51801/60000], Loss: 0.0390\n",
      "Epoch [2/10], Step[51901/60000], Loss: 0.1256\n",
      "Epoch [2/10], Step[52001/60000], Loss: 0.1048\n",
      "Epoch [2/10], Step[52101/60000], Loss: 0.1973\n",
      "Epoch [2/10], Step[52201/60000], Loss: 0.1505\n",
      "Epoch [2/10], Step[52301/60000], Loss: 0.1462\n",
      "Epoch [2/10], Step[52401/60000], Loss: 0.0449\n",
      "Epoch [2/10], Step[52501/60000], Loss: 0.0687\n",
      "Epoch [2/10], Step[52601/60000], Loss: 0.0927\n",
      "Epoch [2/10], Step[52701/60000], Loss: 0.1234\n",
      "Epoch [2/10], Step[52801/60000], Loss: 0.1837\n",
      "Epoch [2/10], Step[52901/60000], Loss: 0.3175\n",
      "Epoch [2/10], Step[53001/60000], Loss: 0.1009\n",
      "Epoch [2/10], Step[53101/60000], Loss: 0.1242\n",
      "Epoch [2/10], Step[53201/60000], Loss: 0.2856\n",
      "Epoch [2/10], Step[53301/60000], Loss: 0.0575\n",
      "Epoch [2/10], Step[53401/60000], Loss: 0.0969\n",
      "Epoch [2/10], Step[53501/60000], Loss: 0.1570\n",
      "Epoch [2/10], Step[53601/60000], Loss: 0.1347\n",
      "Epoch [2/10], Step[53701/60000], Loss: 0.0806\n",
      "Epoch [2/10], Step[53801/60000], Loss: 0.1456\n",
      "Epoch [2/10], Step[53901/60000], Loss: 0.1813\n",
      "Epoch [2/10], Step[54001/60000], Loss: 1.1901\n",
      "Epoch [2/10], Step[54101/60000], Loss: 0.0874\n",
      "Epoch [2/10], Step[54201/60000], Loss: 0.0731\n",
      "Epoch [2/10], Step[54301/60000], Loss: 0.0842\n",
      "Epoch [2/10], Step[54401/60000], Loss: 0.0807\n",
      "Epoch [2/10], Step[54501/60000], Loss: 0.1659\n",
      "Epoch [2/10], Step[54601/60000], Loss: 0.0465\n",
      "Epoch [2/10], Step[54701/60000], Loss: 0.0724\n",
      "Epoch [2/10], Step[54801/60000], Loss: 0.8279\n",
      "Epoch [2/10], Step[54901/60000], Loss: 0.2454\n",
      "Epoch [2/10], Step[55001/60000], Loss: 0.0721\n",
      "Epoch [2/10], Step[55101/60000], Loss: 0.0871\n",
      "Epoch [2/10], Step[55201/60000], Loss: 0.1582\n",
      "Epoch [2/10], Step[55301/60000], Loss: 0.1313\n",
      "Epoch [2/10], Step[55401/60000], Loss: 0.1097\n",
      "Epoch [2/10], Step[55501/60000], Loss: 0.0922\n",
      "Epoch [2/10], Step[55601/60000], Loss: 0.1198\n",
      "Epoch [2/10], Step[55701/60000], Loss: 0.1781\n",
      "Epoch [2/10], Step[55801/60000], Loss: 0.1858\n",
      "Epoch [2/10], Step[55901/60000], Loss: 0.0901\n",
      "Epoch [2/10], Step[56001/60000], Loss: 0.1395\n",
      "Epoch [2/10], Step[56101/60000], Loss: 0.0468\n",
      "Epoch [2/10], Step[56201/60000], Loss: 0.1890\n",
      "Epoch [2/10], Step[56301/60000], Loss: 0.0831\n",
      "Epoch [2/10], Step[56401/60000], Loss: 0.3261\n",
      "Epoch [2/10], Step[56501/60000], Loss: 0.0798\n",
      "Epoch [2/10], Step[56601/60000], Loss: 0.1119\n",
      "Epoch [2/10], Step[56701/60000], Loss: 0.0316\n",
      "Epoch [2/10], Step[56801/60000], Loss: 0.1015\n",
      "Epoch [2/10], Step[56901/60000], Loss: 0.0535\n",
      "Epoch [2/10], Step[57001/60000], Loss: 0.1010\n",
      "Epoch [2/10], Step[57101/60000], Loss: 0.0257\n",
      "Epoch [2/10], Step[57201/60000], Loss: 0.1027\n",
      "Epoch [2/10], Step[57301/60000], Loss: 0.1023\n",
      "Epoch [2/10], Step[57401/60000], Loss: 0.1070\n",
      "Epoch [2/10], Step[57501/60000], Loss: 0.0871\n",
      "Epoch [2/10], Step[57601/60000], Loss: 0.1356\n",
      "Epoch [2/10], Step[57701/60000], Loss: 0.1997\n",
      "Epoch [2/10], Step[57801/60000], Loss: 0.0694\n",
      "Epoch [2/10], Step[57901/60000], Loss: 0.0545\n",
      "Epoch [2/10], Step[58001/60000], Loss: 0.0886\n",
      "Epoch [2/10], Step[58101/60000], Loss: 0.0575\n",
      "Epoch [2/10], Step[58201/60000], Loss: 0.0670\n",
      "Epoch [2/10], Step[58301/60000], Loss: 0.0675\n",
      "Epoch [2/10], Step[58401/60000], Loss: 0.0549\n",
      "Epoch [2/10], Step[58501/60000], Loss: 0.0367\n",
      "Epoch [2/10], Step[58601/60000], Loss: 0.0608\n",
      "Epoch [2/10], Step[58701/60000], Loss: 0.0338\n",
      "Epoch [2/10], Step[58801/60000], Loss: 0.1467\n",
      "Epoch [2/10], Step[58901/60000], Loss: 0.1594\n",
      "Epoch [2/10], Step[59001/60000], Loss: 0.0123\n",
      "Epoch [2/10], Step[59101/60000], Loss: 0.0066\n",
      "Epoch [2/10], Step[59201/60000], Loss: 0.0343\n",
      "Epoch [2/10], Step[59301/60000], Loss: 0.1170\n",
      "Epoch [2/10], Step[59401/60000], Loss: 0.0561\n",
      "Epoch [2/10], Step[59501/60000], Loss: 0.0134\n",
      "Epoch [2/10], Step[59601/60000], Loss: 0.0557\n",
      "Epoch [2/10], Step[59701/60000], Loss: 0.5443\n",
      "Epoch [2/10], Step[59801/60000], Loss: 0.0076\n",
      "Epoch [2/10], Step[59901/60000], Loss: 0.2185\n",
      "Epoch [3/10], Step[1/60000], Loss: 0.1188\n",
      "Epoch [3/10], Step[101/60000], Loss: 0.1394\n",
      "Epoch [3/10], Step[201/60000], Loss: 0.0973\n",
      "Epoch [3/10], Step[301/60000], Loss: 0.0313\n",
      "Epoch [3/10], Step[401/60000], Loss: 0.1997\n",
      "Epoch [3/10], Step[501/60000], Loss: 0.1328\n",
      "Epoch [3/10], Step[601/60000], Loss: 0.2994\n",
      "Epoch [3/10], Step[701/60000], Loss: 0.1767\n",
      "Epoch [3/10], Step[801/60000], Loss: 0.1625\n",
      "Epoch [3/10], Step[901/60000], Loss: 0.1429\n",
      "Epoch [3/10], Step[1001/60000], Loss: 0.2710\n",
      "Epoch [3/10], Step[1101/60000], Loss: 0.3029\n",
      "Epoch [3/10], Step[1201/60000], Loss: 0.5047\n",
      "Epoch [3/10], Step[1301/60000], Loss: 0.1333\n",
      "Epoch [3/10], Step[1401/60000], Loss: 0.1660\n",
      "Epoch [3/10], Step[1501/60000], Loss: 0.1578\n",
      "Epoch [3/10], Step[1601/60000], Loss: 0.1001\n",
      "Epoch [3/10], Step[1701/60000], Loss: 0.0781\n",
      "Epoch [3/10], Step[1801/60000], Loss: 0.2320\n",
      "Epoch [3/10], Step[1901/60000], Loss: 0.0599\n",
      "Epoch [3/10], Step[2001/60000], Loss: 0.0974\n",
      "Epoch [3/10], Step[2101/60000], Loss: 0.0626\n",
      "Epoch [3/10], Step[2201/60000], Loss: 0.0765\n",
      "Epoch [3/10], Step[2301/60000], Loss: 0.0262\n",
      "Epoch [3/10], Step[2401/60000], Loss: 0.1070\n",
      "Epoch [3/10], Step[2501/60000], Loss: 1.3246\n",
      "Epoch [3/10], Step[2601/60000], Loss: 0.1476\n",
      "Epoch [3/10], Step[2701/60000], Loss: 0.1253\n",
      "Epoch [3/10], Step[2801/60000], Loss: 0.0339\n",
      "Epoch [3/10], Step[2901/60000], Loss: 0.0958\n",
      "Epoch [3/10], Step[3001/60000], Loss: 0.1063\n",
      "Epoch [3/10], Step[3101/60000], Loss: 0.0289\n",
      "Epoch [3/10], Step[3201/60000], Loss: 0.3222\n",
      "Epoch [3/10], Step[3301/60000], Loss: 0.0484\n",
      "Epoch [3/10], Step[3401/60000], Loss: 0.1711\n",
      "Epoch [3/10], Step[3501/60000], Loss: 0.1911\n",
      "Epoch [3/10], Step[3601/60000], Loss: 0.1646\n",
      "Epoch [3/10], Step[3701/60000], Loss: 0.1031\n",
      "Epoch [3/10], Step[3801/60000], Loss: 0.0618\n",
      "Epoch [3/10], Step[3901/60000], Loss: 0.0431\n",
      "Epoch [3/10], Step[4001/60000], Loss: 0.1561\n",
      "Epoch [3/10], Step[4101/60000], Loss: 0.2443\n",
      "Epoch [3/10], Step[4201/60000], Loss: 0.1220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step[4301/60000], Loss: 0.1009\n",
      "Epoch [3/10], Step[4401/60000], Loss: 0.0726\n",
      "Epoch [3/10], Step[4501/60000], Loss: 0.0576\n",
      "Epoch [3/10], Step[4601/60000], Loss: 0.1297\n",
      "Epoch [3/10], Step[4701/60000], Loss: 0.0282\n",
      "Epoch [3/10], Step[4801/60000], Loss: 0.0296\n",
      "Epoch [3/10], Step[4901/60000], Loss: 0.1676\n",
      "Epoch [3/10], Step[5001/60000], Loss: 0.1307\n",
      "Epoch [3/10], Step[5101/60000], Loss: 0.2769\n",
      "Epoch [3/10], Step[5201/60000], Loss: 0.0583\n",
      "Epoch [3/10], Step[5301/60000], Loss: 0.1301\n",
      "Epoch [3/10], Step[5401/60000], Loss: 0.0488\n",
      "Epoch [3/10], Step[5501/60000], Loss: 0.0878\n",
      "Epoch [3/10], Step[5601/60000], Loss: 0.1106\n",
      "Epoch [3/10], Step[5701/60000], Loss: 0.1274\n",
      "Epoch [3/10], Step[5801/60000], Loss: 0.1847\n",
      "Epoch [3/10], Step[5901/60000], Loss: 0.0404\n",
      "Epoch [3/10], Step[6001/60000], Loss: 0.0508\n",
      "Epoch [3/10], Step[6101/60000], Loss: 0.0861\n",
      "Epoch [3/10], Step[6201/60000], Loss: 0.1411\n",
      "Epoch [3/10], Step[6301/60000], Loss: 0.0711\n",
      "Epoch [3/10], Step[6401/60000], Loss: 0.0695\n",
      "Epoch [3/10], Step[6501/60000], Loss: 0.0339\n",
      "Epoch [3/10], Step[6601/60000], Loss: 0.1220\n",
      "Epoch [3/10], Step[6701/60000], Loss: 0.0833\n",
      "Epoch [3/10], Step[6801/60000], Loss: 0.4515\n",
      "Epoch [3/10], Step[6901/60000], Loss: 0.2329\n",
      "Epoch [3/10], Step[7001/60000], Loss: 0.1583\n",
      "Epoch [3/10], Step[7101/60000], Loss: 0.0988\n",
      "Epoch [3/10], Step[7201/60000], Loss: 0.2732\n",
      "Epoch [3/10], Step[7301/60000], Loss: 0.1407\n",
      "Epoch [3/10], Step[7401/60000], Loss: 0.0659\n",
      "Epoch [3/10], Step[7501/60000], Loss: 0.1090\n",
      "Epoch [3/10], Step[7601/60000], Loss: 0.0810\n",
      "Epoch [3/10], Step[7701/60000], Loss: 0.0737\n",
      "Epoch [3/10], Step[7801/60000], Loss: 0.1732\n",
      "Epoch [3/10], Step[7901/60000], Loss: 0.0609\n",
      "Epoch [3/10], Step[8001/60000], Loss: 0.0601\n",
      "Epoch [3/10], Step[8101/60000], Loss: 0.1287\n",
      "Epoch [3/10], Step[8201/60000], Loss: 0.3670\n",
      "Epoch [3/10], Step[8301/60000], Loss: 0.0776\n",
      "Epoch [3/10], Step[8401/60000], Loss: 0.1299\n",
      "Epoch [3/10], Step[8501/60000], Loss: 0.0417\n",
      "Epoch [3/10], Step[8601/60000], Loss: 0.1377\n",
      "Epoch [3/10], Step[8701/60000], Loss: 0.1800\n",
      "Epoch [3/10], Step[8801/60000], Loss: 0.2503\n",
      "Epoch [3/10], Step[8901/60000], Loss: 0.0989\n",
      "Epoch [3/10], Step[9001/60000], Loss: 0.0889\n",
      "Epoch [3/10], Step[9101/60000], Loss: 0.1131\n",
      "Epoch [3/10], Step[9201/60000], Loss: 0.1549\n",
      "Epoch [3/10], Step[9301/60000], Loss: 0.1010\n",
      "Epoch [3/10], Step[9401/60000], Loss: 0.1121\n",
      "Epoch [3/10], Step[9501/60000], Loss: 0.1016\n",
      "Epoch [3/10], Step[9601/60000], Loss: 0.0879\n",
      "Epoch [3/10], Step[9701/60000], Loss: 0.1193\n",
      "Epoch [3/10], Step[9801/60000], Loss: 0.0419\n",
      "Epoch [3/10], Step[9901/60000], Loss: 0.0518\n",
      "Epoch [3/10], Step[10001/60000], Loss: 0.0710\n",
      "Epoch [3/10], Step[10101/60000], Loss: 0.1265\n",
      "Epoch [3/10], Step[10201/60000], Loss: 0.1301\n",
      "Epoch [3/10], Step[10301/60000], Loss: 0.0548\n",
      "Epoch [3/10], Step[10401/60000], Loss: 0.0247\n",
      "Epoch [3/10], Step[10501/60000], Loss: 0.0268\n",
      "Epoch [3/10], Step[10601/60000], Loss: 0.0298\n",
      "Epoch [3/10], Step[10701/60000], Loss: 0.1334\n",
      "Epoch [3/10], Step[10801/60000], Loss: 0.0959\n",
      "Epoch [3/10], Step[10901/60000], Loss: 0.0980\n",
      "Epoch [3/10], Step[11001/60000], Loss: 0.0457\n",
      "Epoch [3/10], Step[11101/60000], Loss: 0.0333\n",
      "Epoch [3/10], Step[11201/60000], Loss: 0.1027\n",
      "Epoch [3/10], Step[11301/60000], Loss: 0.0381\n",
      "Epoch [3/10], Step[11401/60000], Loss: 0.0613\n",
      "Epoch [3/10], Step[11501/60000], Loss: 0.1876\n",
      "Epoch [3/10], Step[11601/60000], Loss: 0.1968\n",
      "Epoch [3/10], Step[11701/60000], Loss: 0.1062\n",
      "Epoch [3/10], Step[11801/60000], Loss: 0.1058\n",
      "Epoch [3/10], Step[11901/60000], Loss: 0.0643\n",
      "Epoch [3/10], Step[12001/60000], Loss: 0.1034\n",
      "Epoch [3/10], Step[12101/60000], Loss: 0.0335\n",
      "Epoch [3/10], Step[12201/60000], Loss: 0.1808\n",
      "Epoch [3/10], Step[12301/60000], Loss: 0.2510\n",
      "Epoch [3/10], Step[12401/60000], Loss: 0.3355\n",
      "Epoch [3/10], Step[12501/60000], Loss: 0.2729\n",
      "Epoch [3/10], Step[12601/60000], Loss: 0.2804\n",
      "Epoch [3/10], Step[12701/60000], Loss: 0.0743\n",
      "Epoch [3/10], Step[12801/60000], Loss: 0.0812\n",
      "Epoch [3/10], Step[12901/60000], Loss: 0.1221\n",
      "Epoch [3/10], Step[13001/60000], Loss: 0.2224\n",
      "Epoch [3/10], Step[13101/60000], Loss: 0.1336\n",
      "Epoch [3/10], Step[13201/60000], Loss: 0.1363\n",
      "Epoch [3/10], Step[13301/60000], Loss: 0.0916\n",
      "Epoch [3/10], Step[13401/60000], Loss: 0.1655\n",
      "Epoch [3/10], Step[13501/60000], Loss: 0.0742\n",
      "Epoch [3/10], Step[13601/60000], Loss: 0.1570\n",
      "Epoch [3/10], Step[13701/60000], Loss: 0.0992\n",
      "Epoch [3/10], Step[13801/60000], Loss: 0.0610\n",
      "Epoch [3/10], Step[13901/60000], Loss: 0.1147\n",
      "Epoch [3/10], Step[14001/60000], Loss: 0.1071\n",
      "Epoch [3/10], Step[14101/60000], Loss: 0.0732\n",
      "Epoch [3/10], Step[14201/60000], Loss: 0.0800\n",
      "Epoch [3/10], Step[14301/60000], Loss: 0.1854\n",
      "Epoch [3/10], Step[14401/60000], Loss: 0.0479\n",
      "Epoch [3/10], Step[14501/60000], Loss: 0.0938\n",
      "Epoch [3/10], Step[14601/60000], Loss: 0.0746\n",
      "Epoch [3/10], Step[14701/60000], Loss: 0.2002\n",
      "Epoch [3/10], Step[14801/60000], Loss: 0.0880\n",
      "Epoch [3/10], Step[14901/60000], Loss: 0.0506\n",
      "Epoch [3/10], Step[15001/60000], Loss: 0.0920\n",
      "Epoch [3/10], Step[15101/60000], Loss: 0.2827\n",
      "Epoch [3/10], Step[15201/60000], Loss: 0.1295\n",
      "Epoch [3/10], Step[15301/60000], Loss: 0.0989\n",
      "Epoch [3/10], Step[15401/60000], Loss: 0.1008\n",
      "Epoch [3/10], Step[15501/60000], Loss: 0.0739\n",
      "Epoch [3/10], Step[15601/60000], Loss: 0.0576\n",
      "Epoch [3/10], Step[15701/60000], Loss: 0.1526\n",
      "Epoch [3/10], Step[15801/60000], Loss: 0.1445\n",
      "Epoch [3/10], Step[15901/60000], Loss: 0.1827\n",
      "Epoch [3/10], Step[16001/60000], Loss: 0.1175\n",
      "Epoch [3/10], Step[16101/60000], Loss: 0.0874\n",
      "Epoch [3/10], Step[16201/60000], Loss: 0.0519\n",
      "Epoch [3/10], Step[16301/60000], Loss: 0.0826\n",
      "Epoch [3/10], Step[16401/60000], Loss: 0.1253\n",
      "Epoch [3/10], Step[16501/60000], Loss: 0.0991\n",
      "Epoch [3/10], Step[16601/60000], Loss: 0.1068\n",
      "Epoch [3/10], Step[16701/60000], Loss: 0.1531\n",
      "Epoch [3/10], Step[16801/60000], Loss: 0.2870\n",
      "Epoch [3/10], Step[16901/60000], Loss: 0.1176\n",
      "Epoch [3/10], Step[17001/60000], Loss: 0.0623\n",
      "Epoch [3/10], Step[17101/60000], Loss: 0.1296\n",
      "Epoch [3/10], Step[17201/60000], Loss: 0.1040\n",
      "Epoch [3/10], Step[17301/60000], Loss: 0.2021\n",
      "Epoch [3/10], Step[17401/60000], Loss: 0.1048\n",
      "Epoch [3/10], Step[17501/60000], Loss: 0.1283\n",
      "Epoch [3/10], Step[17601/60000], Loss: 0.0818\n",
      "Epoch [3/10], Step[17701/60000], Loss: 0.1658\n",
      "Epoch [3/10], Step[17801/60000], Loss: 0.1071\n",
      "Epoch [3/10], Step[17901/60000], Loss: 0.0588\n",
      "Epoch [3/10], Step[18001/60000], Loss: 0.0813\n",
      "Epoch [3/10], Step[18101/60000], Loss: 0.0647\n",
      "Epoch [3/10], Step[18201/60000], Loss: 0.0607\n",
      "Epoch [3/10], Step[18301/60000], Loss: 0.0968\n",
      "Epoch [3/10], Step[18401/60000], Loss: 0.0637\n",
      "Epoch [3/10], Step[18501/60000], Loss: 0.0862\n",
      "Epoch [3/10], Step[18601/60000], Loss: 0.0342\n",
      "Epoch [3/10], Step[18701/60000], Loss: 0.0921\n",
      "Epoch [3/10], Step[18801/60000], Loss: 0.0345\n",
      "Epoch [3/10], Step[18901/60000], Loss: 0.0353\n",
      "Epoch [3/10], Step[19001/60000], Loss: 0.1297\n",
      "Epoch [3/10], Step[19101/60000], Loss: 0.0988\n",
      "Epoch [3/10], Step[19201/60000], Loss: 0.0744\n",
      "Epoch [3/10], Step[19301/60000], Loss: 0.1319\n",
      "Epoch [3/10], Step[19401/60000], Loss: 0.0510\n",
      "Epoch [3/10], Step[19501/60000], Loss: 0.0947\n",
      "Epoch [3/10], Step[19601/60000], Loss: 0.0305\n",
      "Epoch [3/10], Step[19701/60000], Loss: 0.0513\n",
      "Epoch [3/10], Step[19801/60000], Loss: 0.1076\n",
      "Epoch [3/10], Step[19901/60000], Loss: 0.0651\n",
      "Epoch [3/10], Step[20001/60000], Loss: 0.1130\n",
      "Epoch [3/10], Step[20101/60000], Loss: 0.1026\n",
      "Epoch [3/10], Step[20201/60000], Loss: 0.0888\n",
      "Epoch [3/10], Step[20301/60000], Loss: 0.0867\n",
      "Epoch [3/10], Step[20401/60000], Loss: 0.0262\n",
      "Epoch [3/10], Step[20501/60000], Loss: 0.0514\n",
      "Epoch [3/10], Step[20601/60000], Loss: 0.1675\n",
      "Epoch [3/10], Step[20701/60000], Loss: 0.2907\n",
      "Epoch [3/10], Step[20801/60000], Loss: 0.1158\n",
      "Epoch [3/10], Step[20901/60000], Loss: 0.1716\n",
      "Epoch [3/10], Step[21001/60000], Loss: 0.1515\n",
      "Epoch [3/10], Step[21101/60000], Loss: 0.1141\n",
      "Epoch [3/10], Step[21201/60000], Loss: 0.0545\n",
      "Epoch [3/10], Step[21301/60000], Loss: 0.1043\n",
      "Epoch [3/10], Step[21401/60000], Loss: 0.0609\n",
      "Epoch [3/10], Step[21501/60000], Loss: 0.1142\n",
      "Epoch [3/10], Step[21601/60000], Loss: 0.1555\n",
      "Epoch [3/10], Step[21701/60000], Loss: 0.0348\n",
      "Epoch [3/10], Step[21801/60000], Loss: 0.0539\n",
      "Epoch [3/10], Step[21901/60000], Loss: 0.1129\n",
      "Epoch [3/10], Step[22001/60000], Loss: 0.0271\n",
      "Epoch [3/10], Step[22101/60000], Loss: 0.1545\n",
      "Epoch [3/10], Step[22201/60000], Loss: 0.0975\n",
      "Epoch [3/10], Step[22301/60000], Loss: 0.0219\n",
      "Epoch [3/10], Step[22401/60000], Loss: 0.3025\n",
      "Epoch [3/10], Step[22501/60000], Loss: 0.1724\n",
      "Epoch [3/10], Step[22601/60000], Loss: 0.0792\n",
      "Epoch [3/10], Step[22701/60000], Loss: 0.2427\n",
      "Epoch [3/10], Step[22801/60000], Loss: 0.0448\n",
      "Epoch [3/10], Step[22901/60000], Loss: 0.0350\n",
      "Epoch [3/10], Step[23001/60000], Loss: 0.0937\n",
      "Epoch [3/10], Step[23101/60000], Loss: 0.0522\n",
      "Epoch [3/10], Step[23201/60000], Loss: 0.1769\n",
      "Epoch [3/10], Step[23301/60000], Loss: 0.0685\n",
      "Epoch [3/10], Step[23401/60000], Loss: 0.1742\n",
      "Epoch [3/10], Step[23501/60000], Loss: 0.0800\n",
      "Epoch [3/10], Step[23601/60000], Loss: 0.1005\n",
      "Epoch [3/10], Step[23701/60000], Loss: 0.1236\n",
      "Epoch [3/10], Step[23801/60000], Loss: 0.0608\n",
      "Epoch [3/10], Step[23901/60000], Loss: 0.2172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step[24001/60000], Loss: 0.0729\n",
      "Epoch [3/10], Step[24101/60000], Loss: 0.0463\n",
      "Epoch [3/10], Step[24201/60000], Loss: 0.1348\n",
      "Epoch [3/10], Step[24301/60000], Loss: 0.0478\n",
      "Epoch [3/10], Step[24401/60000], Loss: 0.0329\n",
      "Epoch [3/10], Step[24501/60000], Loss: 0.1293\n",
      "Epoch [3/10], Step[24601/60000], Loss: 0.0511\n",
      "Epoch [3/10], Step[24701/60000], Loss: 0.0563\n",
      "Epoch [3/10], Step[24801/60000], Loss: 0.0678\n",
      "Epoch [3/10], Step[24901/60000], Loss: 0.0754\n",
      "Epoch [3/10], Step[25001/60000], Loss: 0.0463\n",
      "Epoch [3/10], Step[25101/60000], Loss: 0.1220\n",
      "Epoch [3/10], Step[25201/60000], Loss: 0.0684\n",
      "Epoch [3/10], Step[25301/60000], Loss: 0.0436\n",
      "Epoch [3/10], Step[25401/60000], Loss: 0.0421\n",
      "Epoch [3/10], Step[25501/60000], Loss: 0.1687\n",
      "Epoch [3/10], Step[25601/60000], Loss: 0.0780\n",
      "Epoch [3/10], Step[25701/60000], Loss: 0.1096\n",
      "Epoch [3/10], Step[25801/60000], Loss: 0.1242\n",
      "Epoch [3/10], Step[25901/60000], Loss: 0.0853\n",
      "Epoch [3/10], Step[26001/60000], Loss: 0.0522\n",
      "Epoch [3/10], Step[26101/60000], Loss: 0.0550\n",
      "Epoch [3/10], Step[26201/60000], Loss: 0.0530\n",
      "Epoch [3/10], Step[26301/60000], Loss: 0.1763\n",
      "Epoch [3/10], Step[26401/60000], Loss: 0.0872\n",
      "Epoch [3/10], Step[26501/60000], Loss: 0.2158\n",
      "Epoch [3/10], Step[26601/60000], Loss: 0.1089\n",
      "Epoch [3/10], Step[26701/60000], Loss: 0.1786\n",
      "Epoch [3/10], Step[26801/60000], Loss: 0.3003\n",
      "Epoch [3/10], Step[26901/60000], Loss: 0.0532\n",
      "Epoch [3/10], Step[27001/60000], Loss: 0.0272\n",
      "Epoch [3/10], Step[27101/60000], Loss: 0.1874\n",
      "Epoch [3/10], Step[27201/60000], Loss: 0.1172\n",
      "Epoch [3/10], Step[27301/60000], Loss: 0.0317\n",
      "Epoch [3/10], Step[27401/60000], Loss: 0.0597\n",
      "Epoch [3/10], Step[27501/60000], Loss: 0.1093\n",
      "Epoch [3/10], Step[27601/60000], Loss: 0.0709\n",
      "Epoch [3/10], Step[27701/60000], Loss: 0.0585\n",
      "Epoch [3/10], Step[27801/60000], Loss: 0.1440\n",
      "Epoch [3/10], Step[27901/60000], Loss: 0.0406\n",
      "Epoch [3/10], Step[28001/60000], Loss: 0.1075\n",
      "Epoch [3/10], Step[28101/60000], Loss: 0.0455\n",
      "Epoch [3/10], Step[28201/60000], Loss: 0.0758\n",
      "Epoch [3/10], Step[28301/60000], Loss: 0.1574\n",
      "Epoch [3/10], Step[28401/60000], Loss: 0.0559\n",
      "Epoch [3/10], Step[28501/60000], Loss: 0.0860\n",
      "Epoch [3/10], Step[28601/60000], Loss: 0.2365\n",
      "Epoch [3/10], Step[28701/60000], Loss: 0.0979\n",
      "Epoch [3/10], Step[28801/60000], Loss: 0.0512\n",
      "Epoch [3/10], Step[28901/60000], Loss: 0.0658\n",
      "Epoch [3/10], Step[29001/60000], Loss: 0.0882\n",
      "Epoch [3/10], Step[29101/60000], Loss: 0.0722\n",
      "Epoch [3/10], Step[29201/60000], Loss: 0.1054\n",
      "Epoch [3/10], Step[29301/60000], Loss: 0.1409\n",
      "Epoch [3/10], Step[29401/60000], Loss: 0.1341\n",
      "Epoch [3/10], Step[29501/60000], Loss: 0.0199\n",
      "Epoch [3/10], Step[29601/60000], Loss: 0.0655\n",
      "Epoch [3/10], Step[29701/60000], Loss: 0.0939\n",
      "Epoch [3/10], Step[29801/60000], Loss: 0.1085\n",
      "Epoch [3/10], Step[29901/60000], Loss: 0.1238\n",
      "Epoch [3/10], Step[30001/60000], Loss: 0.1325\n",
      "Epoch [3/10], Step[30101/60000], Loss: 0.0970\n",
      "Epoch [3/10], Step[30201/60000], Loss: 0.0236\n",
      "Epoch [3/10], Step[30301/60000], Loss: 0.0468\n",
      "Epoch [3/10], Step[30401/60000], Loss: 0.0632\n",
      "Epoch [3/10], Step[30501/60000], Loss: 0.0541\n",
      "Epoch [3/10], Step[30601/60000], Loss: 0.0938\n",
      "Epoch [3/10], Step[30701/60000], Loss: 0.0747\n",
      "Epoch [3/10], Step[30801/60000], Loss: 0.0485\n",
      "Epoch [3/10], Step[30901/60000], Loss: 0.1385\n",
      "Epoch [3/10], Step[31001/60000], Loss: 0.0417\n",
      "Epoch [3/10], Step[31101/60000], Loss: 0.3296\n",
      "Epoch [3/10], Step[31201/60000], Loss: 0.0654\n",
      "Epoch [3/10], Step[31301/60000], Loss: 0.1677\n",
      "Epoch [3/10], Step[31401/60000], Loss: 0.0636\n",
      "Epoch [3/10], Step[31501/60000], Loss: 0.1198\n",
      "Epoch [3/10], Step[31601/60000], Loss: 0.8604\n",
      "Epoch [3/10], Step[31701/60000], Loss: 0.2535\n",
      "Epoch [3/10], Step[31801/60000], Loss: 0.1162\n",
      "Epoch [3/10], Step[31901/60000], Loss: 0.0932\n",
      "Epoch [3/10], Step[32001/60000], Loss: 0.1528\n",
      "Epoch [3/10], Step[32101/60000], Loss: 0.0772\n",
      "Epoch [3/10], Step[32201/60000], Loss: 0.1334\n",
      "Epoch [3/10], Step[32301/60000], Loss: 0.1517\n",
      "Epoch [3/10], Step[32401/60000], Loss: 0.1728\n",
      "Epoch [3/10], Step[32501/60000], Loss: 0.0714\n",
      "Epoch [3/10], Step[32601/60000], Loss: 0.2543\n",
      "Epoch [3/10], Step[32701/60000], Loss: 0.1229\n",
      "Epoch [3/10], Step[32801/60000], Loss: 0.0550\n",
      "Epoch [3/10], Step[32901/60000], Loss: 0.0690\n",
      "Epoch [3/10], Step[33001/60000], Loss: 0.0536\n",
      "Epoch [3/10], Step[33101/60000], Loss: 0.0639\n",
      "Epoch [3/10], Step[33201/60000], Loss: 0.0409\n",
      "Epoch [3/10], Step[33301/60000], Loss: 0.1359\n",
      "Epoch [3/10], Step[33401/60000], Loss: 0.0726\n",
      "Epoch [3/10], Step[33501/60000], Loss: 0.0512\n",
      "Epoch [3/10], Step[33601/60000], Loss: 0.1114\n",
      "Epoch [3/10], Step[33701/60000], Loss: 0.1773\n",
      "Epoch [3/10], Step[33801/60000], Loss: 0.0223\n",
      "Epoch [3/10], Step[33901/60000], Loss: 0.0321\n",
      "Epoch [3/10], Step[34001/60000], Loss: 0.1651\n",
      "Epoch [3/10], Step[34101/60000], Loss: 0.0275\n",
      "Epoch [3/10], Step[34201/60000], Loss: 0.0209\n",
      "Epoch [3/10], Step[34301/60000], Loss: 0.0336\n",
      "Epoch [3/10], Step[34401/60000], Loss: 0.1832\n",
      "Epoch [3/10], Step[34501/60000], Loss: 0.1471\n",
      "Epoch [3/10], Step[34601/60000], Loss: 0.1867\n",
      "Epoch [3/10], Step[34701/60000], Loss: 0.1246\n",
      "Epoch [3/10], Step[34801/60000], Loss: 0.0666\n",
      "Epoch [3/10], Step[34901/60000], Loss: 0.1075\n",
      "Epoch [3/10], Step[35001/60000], Loss: 0.0729\n",
      "Epoch [3/10], Step[35101/60000], Loss: 0.1756\n",
      "Epoch [3/10], Step[35201/60000], Loss: 0.1408\n",
      "Epoch [3/10], Step[35301/60000], Loss: 0.0819\n",
      "Epoch [3/10], Step[35401/60000], Loss: 0.2146\n",
      "Epoch [3/10], Step[35501/60000], Loss: 0.0247\n",
      "Epoch [3/10], Step[35601/60000], Loss: 0.1347\n",
      "Epoch [3/10], Step[35701/60000], Loss: 0.0279\n",
      "Epoch [3/10], Step[35801/60000], Loss: 0.0431\n",
      "Epoch [3/10], Step[35901/60000], Loss: 0.1021\n",
      "Epoch [3/10], Step[36001/60000], Loss: 0.1643\n",
      "Epoch [3/10], Step[36101/60000], Loss: 0.1396\n",
      "Epoch [3/10], Step[36201/60000], Loss: 0.0653\n",
      "Epoch [3/10], Step[36301/60000], Loss: 0.0396\n",
      "Epoch [3/10], Step[36401/60000], Loss: 0.1929\n",
      "Epoch [3/10], Step[36501/60000], Loss: 0.0512\n",
      "Epoch [3/10], Step[36601/60000], Loss: 0.0464\n",
      "Epoch [3/10], Step[36701/60000], Loss: 0.0901\n",
      "Epoch [3/10], Step[36801/60000], Loss: 0.1716\n",
      "Epoch [3/10], Step[36901/60000], Loss: 0.1114\n",
      "Epoch [3/10], Step[37001/60000], Loss: 0.1180\n",
      "Epoch [3/10], Step[37101/60000], Loss: 0.0732\n",
      "Epoch [3/10], Step[37201/60000], Loss: 0.6257\n",
      "Epoch [3/10], Step[37301/60000], Loss: 0.2105\n",
      "Epoch [3/10], Step[37401/60000], Loss: 0.2792\n",
      "Epoch [3/10], Step[37501/60000], Loss: 0.0667\n",
      "Epoch [3/10], Step[37601/60000], Loss: 0.0419\n",
      "Epoch [3/10], Step[37701/60000], Loss: 0.2876\n",
      "Epoch [3/10], Step[37801/60000], Loss: 0.2270\n",
      "Epoch [3/10], Step[37901/60000], Loss: 0.0727\n",
      "Epoch [3/10], Step[38001/60000], Loss: 0.0385\n",
      "Epoch [3/10], Step[38101/60000], Loss: 0.0284\n",
      "Epoch [3/10], Step[38201/60000], Loss: 0.0351\n",
      "Epoch [3/10], Step[38301/60000], Loss: 0.1812\n",
      "Epoch [3/10], Step[38401/60000], Loss: 0.0747\n",
      "Epoch [3/10], Step[38501/60000], Loss: 0.1429\n",
      "Epoch [3/10], Step[38601/60000], Loss: 0.1297\n",
      "Epoch [3/10], Step[38701/60000], Loss: 0.1284\n",
      "Epoch [3/10], Step[38801/60000], Loss: 0.0357\n",
      "Epoch [3/10], Step[38901/60000], Loss: 0.4945\n",
      "Epoch [3/10], Step[39001/60000], Loss: 0.0788\n",
      "Epoch [3/10], Step[39101/60000], Loss: 0.1104\n",
      "Epoch [3/10], Step[39201/60000], Loss: 0.0666\n",
      "Epoch [3/10], Step[39301/60000], Loss: 0.2043\n",
      "Epoch [3/10], Step[39401/60000], Loss: 0.1536\n",
      "Epoch [3/10], Step[39501/60000], Loss: 0.0400\n",
      "Epoch [3/10], Step[39601/60000], Loss: 0.1527\n",
      "Epoch [3/10], Step[39701/60000], Loss: 0.0367\n",
      "Epoch [3/10], Step[39801/60000], Loss: 0.1186\n",
      "Epoch [3/10], Step[39901/60000], Loss: 0.0843\n",
      "Epoch [3/10], Step[40001/60000], Loss: 0.0424\n",
      "Epoch [3/10], Step[40101/60000], Loss: 0.0711\n",
      "Epoch [3/10], Step[40201/60000], Loss: 0.1039\n",
      "Epoch [3/10], Step[40301/60000], Loss: 0.1023\n",
      "Epoch [3/10], Step[40401/60000], Loss: 0.0170\n",
      "Epoch [3/10], Step[40501/60000], Loss: 0.0680\n",
      "Epoch [3/10], Step[40601/60000], Loss: 0.0553\n",
      "Epoch [3/10], Step[40701/60000], Loss: 0.0625\n",
      "Epoch [3/10], Step[40801/60000], Loss: 0.0667\n",
      "Epoch [3/10], Step[40901/60000], Loss: 0.0726\n",
      "Epoch [3/10], Step[41001/60000], Loss: 0.1032\n",
      "Epoch [3/10], Step[41101/60000], Loss: 0.0690\n",
      "Epoch [3/10], Step[41201/60000], Loss: 0.1671\n",
      "Epoch [3/10], Step[41301/60000], Loss: 0.1645\n",
      "Epoch [3/10], Step[41401/60000], Loss: 0.1880\n",
      "Epoch [3/10], Step[41501/60000], Loss: 0.1719\n",
      "Epoch [3/10], Step[41601/60000], Loss: 0.0556\n",
      "Epoch [3/10], Step[41701/60000], Loss: 0.0416\n",
      "Epoch [3/10], Step[41801/60000], Loss: 0.0835\n",
      "Epoch [3/10], Step[41901/60000], Loss: 0.1600\n",
      "Epoch [3/10], Step[42001/60000], Loss: 0.0576\n",
      "Epoch [3/10], Step[42101/60000], Loss: 0.1428\n",
      "Epoch [3/10], Step[42201/60000], Loss: 0.0836\n",
      "Epoch [3/10], Step[42301/60000], Loss: 0.1935\n",
      "Epoch [3/10], Step[42401/60000], Loss: 0.1620\n",
      "Epoch [3/10], Step[42501/60000], Loss: 0.2252\n",
      "Epoch [3/10], Step[42601/60000], Loss: 0.0386\n",
      "Epoch [3/10], Step[42701/60000], Loss: 0.0713\n",
      "Epoch [3/10], Step[42801/60000], Loss: 0.1324\n",
      "Epoch [3/10], Step[42901/60000], Loss: 0.1310\n",
      "Epoch [3/10], Step[43001/60000], Loss: 0.1333\n",
      "Epoch [3/10], Step[43101/60000], Loss: 0.0781\n",
      "Epoch [3/10], Step[43201/60000], Loss: 0.0336\n",
      "Epoch [3/10], Step[43301/60000], Loss: 0.0235\n",
      "Epoch [3/10], Step[43401/60000], Loss: 0.0717\n",
      "Epoch [3/10], Step[43501/60000], Loss: 0.1054\n",
      "Epoch [3/10], Step[43601/60000], Loss: 0.1244\n",
      "Epoch [3/10], Step[43701/60000], Loss: 0.0451\n",
      "Epoch [3/10], Step[43801/60000], Loss: 0.1279\n",
      "Epoch [3/10], Step[43901/60000], Loss: 0.1025\n",
      "Epoch [3/10], Step[44001/60000], Loss: 0.1561\n",
      "Epoch [3/10], Step[44101/60000], Loss: 0.1941\n",
      "Epoch [3/10], Step[44201/60000], Loss: 0.1221\n",
      "Epoch [3/10], Step[44301/60000], Loss: 0.0808\n",
      "Epoch [3/10], Step[44401/60000], Loss: 0.2167\n",
      "Epoch [3/10], Step[44501/60000], Loss: 0.0438\n",
      "Epoch [3/10], Step[44601/60000], Loss: 0.0582\n",
      "Epoch [3/10], Step[44701/60000], Loss: 0.1436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step[44801/60000], Loss: 0.1810\n",
      "Epoch [3/10], Step[44901/60000], Loss: 0.0941\n",
      "Epoch [3/10], Step[45001/60000], Loss: 0.1603\n",
      "Epoch [3/10], Step[45101/60000], Loss: 0.1137\n",
      "Epoch [3/10], Step[45201/60000], Loss: 0.0913\n",
      "Epoch [3/10], Step[45301/60000], Loss: 0.0328\n",
      "Epoch [3/10], Step[45401/60000], Loss: 0.0625\n",
      "Epoch [3/10], Step[45501/60000], Loss: 0.1402\n",
      "Epoch [3/10], Step[45601/60000], Loss: 0.1458\n",
      "Epoch [3/10], Step[45701/60000], Loss: 0.0424\n",
      "Epoch [3/10], Step[45801/60000], Loss: 0.1195\n",
      "Epoch [3/10], Step[45901/60000], Loss: 0.1210\n",
      "Epoch [3/10], Step[46001/60000], Loss: 0.5206\n",
      "Epoch [3/10], Step[46101/60000], Loss: 0.0697\n",
      "Epoch [3/10], Step[46201/60000], Loss: 0.2018\n",
      "Epoch [3/10], Step[46301/60000], Loss: 0.1197\n",
      "Epoch [3/10], Step[46401/60000], Loss: 0.1558\n",
      "Epoch [3/10], Step[46501/60000], Loss: 0.0703\n",
      "Epoch [3/10], Step[46601/60000], Loss: 0.0518\n",
      "Epoch [3/10], Step[46701/60000], Loss: 0.1237\n",
      "Epoch [3/10], Step[46801/60000], Loss: 0.0986\n",
      "Epoch [3/10], Step[46901/60000], Loss: 0.0913\n",
      "Epoch [3/10], Step[47001/60000], Loss: 0.1336\n",
      "Epoch [3/10], Step[47101/60000], Loss: 0.0831\n",
      "Epoch [3/10], Step[47201/60000], Loss: 0.2202\n",
      "Epoch [3/10], Step[47301/60000], Loss: 0.1426\n",
      "Epoch [3/10], Step[47401/60000], Loss: 0.1486\n",
      "Epoch [3/10], Step[47501/60000], Loss: 0.1170\n",
      "Epoch [3/10], Step[47601/60000], Loss: 0.1636\n",
      "Epoch [3/10], Step[47701/60000], Loss: 0.1622\n",
      "Epoch [3/10], Step[47801/60000], Loss: 0.0679\n",
      "Epoch [3/10], Step[47901/60000], Loss: 0.1952\n",
      "Epoch [3/10], Step[48001/60000], Loss: 0.0597\n",
      "Epoch [3/10], Step[48101/60000], Loss: 0.0826\n",
      "Epoch [3/10], Step[48201/60000], Loss: 0.0579\n",
      "Epoch [3/10], Step[48301/60000], Loss: 0.1040\n",
      "Epoch [3/10], Step[48401/60000], Loss: 0.0250\n",
      "Epoch [3/10], Step[48501/60000], Loss: 0.0960\n",
      "Epoch [3/10], Step[48601/60000], Loss: 0.0766\n",
      "Epoch [3/10], Step[48701/60000], Loss: 0.0268\n",
      "Epoch [3/10], Step[48801/60000], Loss: 0.0863\n",
      "Epoch [3/10], Step[48901/60000], Loss: 0.3330\n",
      "Epoch [3/10], Step[49001/60000], Loss: 0.3526\n",
      "Epoch [3/10], Step[49101/60000], Loss: 0.0351\n",
      "Epoch [3/10], Step[49201/60000], Loss: 0.0879\n",
      "Epoch [3/10], Step[49301/60000], Loss: 0.0574\n",
      "Epoch [3/10], Step[49401/60000], Loss: 0.1177\n",
      "Epoch [3/10], Step[49501/60000], Loss: 0.2152\n",
      "Epoch [3/10], Step[49601/60000], Loss: 0.1339\n",
      "Epoch [3/10], Step[49701/60000], Loss: 0.0633\n",
      "Epoch [3/10], Step[49801/60000], Loss: 0.3024\n",
      "Epoch [3/10], Step[49901/60000], Loss: 0.0827\n",
      "Epoch [3/10], Step[50001/60000], Loss: 0.1110\n",
      "Epoch [3/10], Step[50101/60000], Loss: 0.0377\n",
      "Epoch [3/10], Step[50201/60000], Loss: 0.2312\n",
      "Epoch [3/10], Step[50301/60000], Loss: 0.1210\n",
      "Epoch [3/10], Step[50401/60000], Loss: 0.2002\n",
      "Epoch [3/10], Step[50501/60000], Loss: 0.1151\n",
      "Epoch [3/10], Step[50601/60000], Loss: 0.0542\n",
      "Epoch [3/10], Step[50701/60000], Loss: 0.0735\n",
      "Epoch [3/10], Step[50801/60000], Loss: 0.0775\n",
      "Epoch [3/10], Step[50901/60000], Loss: 0.0552\n",
      "Epoch [3/10], Step[51001/60000], Loss: 0.0259\n",
      "Epoch [3/10], Step[51101/60000], Loss: 0.0790\n",
      "Epoch [3/10], Step[51201/60000], Loss: 0.1593\n",
      "Epoch [3/10], Step[51301/60000], Loss: 0.0879\n",
      "Epoch [3/10], Step[51401/60000], Loss: 0.1497\n",
      "Epoch [3/10], Step[51501/60000], Loss: 0.0323\n",
      "Epoch [3/10], Step[51601/60000], Loss: 0.0515\n",
      "Epoch [3/10], Step[51701/60000], Loss: 0.0526\n",
      "Epoch [3/10], Step[51801/60000], Loss: 0.0274\n",
      "Epoch [3/10], Step[51901/60000], Loss: 0.0938\n",
      "Epoch [3/10], Step[52001/60000], Loss: 0.0623\n",
      "Epoch [3/10], Step[52101/60000], Loss: 0.1217\n",
      "Epoch [3/10], Step[52201/60000], Loss: 0.1022\n",
      "Epoch [3/10], Step[52301/60000], Loss: 0.0792\n",
      "Epoch [3/10], Step[52401/60000], Loss: 0.0424\n",
      "Epoch [3/10], Step[52501/60000], Loss: 0.0523\n",
      "Epoch [3/10], Step[52601/60000], Loss: 0.0755\n",
      "Epoch [3/10], Step[52701/60000], Loss: 0.0723\n",
      "Epoch [3/10], Step[52801/60000], Loss: 0.1162\n",
      "Epoch [3/10], Step[52901/60000], Loss: 0.2264\n",
      "Epoch [3/10], Step[53001/60000], Loss: 0.0753\n",
      "Epoch [3/10], Step[53101/60000], Loss: 0.0654\n",
      "Epoch [3/10], Step[53201/60000], Loss: 0.1018\n",
      "Epoch [3/10], Step[53301/60000], Loss: 0.0426\n",
      "Epoch [3/10], Step[53401/60000], Loss: 0.0643\n",
      "Epoch [3/10], Step[53501/60000], Loss: 0.1130\n",
      "Epoch [3/10], Step[53601/60000], Loss: 0.1186\n",
      "Epoch [3/10], Step[53701/60000], Loss: 0.0432\n",
      "Epoch [3/10], Step[53801/60000], Loss: 0.0516\n",
      "Epoch [3/10], Step[53901/60000], Loss: 0.2198\n",
      "Epoch [3/10], Step[54001/60000], Loss: 0.3783\n",
      "Epoch [3/10], Step[54101/60000], Loss: 0.0689\n",
      "Epoch [3/10], Step[54201/60000], Loss: 0.0540\n",
      "Epoch [3/10], Step[54301/60000], Loss: 0.0415\n",
      "Epoch [3/10], Step[54401/60000], Loss: 0.0449\n",
      "Epoch [3/10], Step[54501/60000], Loss: 0.1177\n",
      "Epoch [3/10], Step[54601/60000], Loss: 0.0261\n",
      "Epoch [3/10], Step[54701/60000], Loss: 0.0488\n",
      "Epoch [3/10], Step[54801/60000], Loss: 0.7371\n",
      "Epoch [3/10], Step[54901/60000], Loss: 0.1029\n",
      "Epoch [3/10], Step[55001/60000], Loss: 0.0459\n",
      "Epoch [3/10], Step[55101/60000], Loss: 0.0494\n",
      "Epoch [3/10], Step[55201/60000], Loss: 0.1135\n",
      "Epoch [3/10], Step[55301/60000], Loss: 0.0976\n",
      "Epoch [3/10], Step[55401/60000], Loss: 0.0726\n",
      "Epoch [3/10], Step[55501/60000], Loss: 0.0650\n",
      "Epoch [3/10], Step[55601/60000], Loss: 0.3039\n",
      "Epoch [3/10], Step[55701/60000], Loss: 0.1339\n",
      "Epoch [3/10], Step[55801/60000], Loss: 0.1461\n",
      "Epoch [3/10], Step[55901/60000], Loss: 0.0611\n",
      "Epoch [3/10], Step[56001/60000], Loss: 0.1131\n",
      "Epoch [3/10], Step[56101/60000], Loss: 0.0285\n",
      "Epoch [3/10], Step[56201/60000], Loss: 0.1415\n",
      "Epoch [3/10], Step[56301/60000], Loss: 0.0629\n",
      "Epoch [3/10], Step[56401/60000], Loss: 0.1766\n",
      "Epoch [3/10], Step[56501/60000], Loss: 0.0585\n",
      "Epoch [3/10], Step[56601/60000], Loss: 0.0714\n",
      "Epoch [3/10], Step[56701/60000], Loss: 0.0309\n",
      "Epoch [3/10], Step[56801/60000], Loss: 0.0595\n",
      "Epoch [3/10], Step[56901/60000], Loss: 0.0370\n",
      "Epoch [3/10], Step[57001/60000], Loss: 0.0692\n",
      "Epoch [3/10], Step[57101/60000], Loss: 0.0166\n",
      "Epoch [3/10], Step[57201/60000], Loss: 0.0878\n",
      "Epoch [3/10], Step[57301/60000], Loss: 0.0757\n",
      "Epoch [3/10], Step[57401/60000], Loss: 0.0703\n",
      "Epoch [3/10], Step[57501/60000], Loss: 0.0501\n",
      "Epoch [3/10], Step[57601/60000], Loss: 0.0801\n",
      "Epoch [3/10], Step[57701/60000], Loss: 0.1528\n",
      "Epoch [3/10], Step[57801/60000], Loss: 0.0477\n",
      "Epoch [3/10], Step[57901/60000], Loss: 0.0373\n",
      "Epoch [3/10], Step[58001/60000], Loss: 0.0708\n",
      "Epoch [3/10], Step[58101/60000], Loss: 0.0398\n",
      "Epoch [3/10], Step[58201/60000], Loss: 0.0531\n",
      "Epoch [3/10], Step[58301/60000], Loss: 0.0473\n",
      "Epoch [3/10], Step[58401/60000], Loss: 0.0245\n",
      "Epoch [3/10], Step[58501/60000], Loss: 0.0183\n",
      "Epoch [3/10], Step[58601/60000], Loss: 0.0556\n",
      "Epoch [3/10], Step[58701/60000], Loss: 0.0160\n",
      "Epoch [3/10], Step[58801/60000], Loss: 0.0927\n",
      "Epoch [3/10], Step[58901/60000], Loss: 0.3740\n",
      "Epoch [3/10], Step[59001/60000], Loss: 0.0074\n",
      "Epoch [3/10], Step[59101/60000], Loss: 0.0036\n",
      "Epoch [3/10], Step[59201/60000], Loss: 0.0145\n",
      "Epoch [3/10], Step[59301/60000], Loss: 0.0752\n",
      "Epoch [3/10], Step[59401/60000], Loss: 0.0395\n",
      "Epoch [3/10], Step[59501/60000], Loss: 0.0104\n",
      "Epoch [3/10], Step[59601/60000], Loss: 0.0502\n",
      "Epoch [3/10], Step[59701/60000], Loss: 0.4809\n",
      "Epoch [3/10], Step[59801/60000], Loss: 0.0042\n",
      "Epoch [3/10], Step[59901/60000], Loss: 0.1937\n",
      "Epoch [4/10], Step[1/60000], Loss: 0.0930\n",
      "Epoch [4/10], Step[101/60000], Loss: 0.1348\n",
      "Epoch [4/10], Step[201/60000], Loss: 0.0683\n",
      "Epoch [4/10], Step[301/60000], Loss: 0.0211\n",
      "Epoch [4/10], Step[401/60000], Loss: 0.1686\n",
      "Epoch [4/10], Step[501/60000], Loss: 0.1115\n",
      "Epoch [4/10], Step[601/60000], Loss: 0.5196\n",
      "Epoch [4/10], Step[701/60000], Loss: 0.1379\n",
      "Epoch [4/10], Step[801/60000], Loss: 0.1623\n",
      "Epoch [4/10], Step[901/60000], Loss: 0.1168\n",
      "Epoch [4/10], Step[1001/60000], Loss: 0.1717\n",
      "Epoch [4/10], Step[1101/60000], Loss: 0.1790\n",
      "Epoch [4/10], Step[1201/60000], Loss: 0.3910\n",
      "Epoch [4/10], Step[1301/60000], Loss: 0.0883\n",
      "Epoch [4/10], Step[1401/60000], Loss: 0.0540\n",
      "Epoch [4/10], Step[1501/60000], Loss: 0.1067\n",
      "Epoch [4/10], Step[1601/60000], Loss: 0.0641\n",
      "Epoch [4/10], Step[1701/60000], Loss: 0.0512\n",
      "Epoch [4/10], Step[1801/60000], Loss: 0.0337\n",
      "Epoch [4/10], Step[1901/60000], Loss: 0.0564\n",
      "Epoch [4/10], Step[2001/60000], Loss: 0.0834\n",
      "Epoch [4/10], Step[2101/60000], Loss: 0.1189\n",
      "Epoch [4/10], Step[2201/60000], Loss: 0.0531\n",
      "Epoch [4/10], Step[2301/60000], Loss: 0.0176\n",
      "Epoch [4/10], Step[2401/60000], Loss: 0.0759\n",
      "Epoch [4/10], Step[2501/60000], Loss: 0.0352\n",
      "Epoch [4/10], Step[2601/60000], Loss: 0.1155\n",
      "Epoch [4/10], Step[2701/60000], Loss: 0.1017\n",
      "Epoch [4/10], Step[2801/60000], Loss: 0.0197\n",
      "Epoch [4/10], Step[2901/60000], Loss: 0.0569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step[3001/60000], Loss: 0.0534\n",
      "Epoch [4/10], Step[3101/60000], Loss: 0.0154\n",
      "Epoch [4/10], Step[3201/60000], Loss: 0.2470\n",
      "Epoch [4/10], Step[3301/60000], Loss: 0.0300\n",
      "Epoch [4/10], Step[3401/60000], Loss: 0.0293\n",
      "Epoch [4/10], Step[3501/60000], Loss: 0.1094\n",
      "Epoch [4/10], Step[3601/60000], Loss: 0.1349\n",
      "Epoch [4/10], Step[3701/60000], Loss: 0.0497\n",
      "Epoch [4/10], Step[3801/60000], Loss: 0.0479\n",
      "Epoch [4/10], Step[3901/60000], Loss: 0.0219\n",
      "Epoch [4/10], Step[4001/60000], Loss: 0.1103\n",
      "Epoch [4/10], Step[4101/60000], Loss: 0.1137\n",
      "Epoch [4/10], Step[4201/60000], Loss: 0.0931\n",
      "Epoch [4/10], Step[4301/60000], Loss: 0.0691\n",
      "Epoch [4/10], Step[4401/60000], Loss: 0.0607\n",
      "Epoch [4/10], Step[4501/60000], Loss: 0.0206\n",
      "Epoch [4/10], Step[4601/60000], Loss: 0.1192\n",
      "Epoch [4/10], Step[4701/60000], Loss: 0.0125\n",
      "Epoch [4/10], Step[4801/60000], Loss: 0.0155\n",
      "Epoch [4/10], Step[4901/60000], Loss: 0.1327\n",
      "Epoch [4/10], Step[5001/60000], Loss: 0.1042\n",
      "Epoch [4/10], Step[5101/60000], Loss: 0.2011\n",
      "Epoch [4/10], Step[5201/60000], Loss: 0.0332\n",
      "Epoch [4/10], Step[5301/60000], Loss: 0.0746\n",
      "Epoch [4/10], Step[5401/60000], Loss: 0.0311\n",
      "Epoch [4/10], Step[5501/60000], Loss: 0.0496\n",
      "Epoch [4/10], Step[5601/60000], Loss: 0.0596\n",
      "Epoch [4/10], Step[5701/60000], Loss: 0.1505\n",
      "Epoch [4/10], Step[5801/60000], Loss: 0.1516\n",
      "Epoch [4/10], Step[5901/60000], Loss: 0.0294\n",
      "Epoch [4/10], Step[6001/60000], Loss: 0.0294\n",
      "Epoch [4/10], Step[6101/60000], Loss: 0.0636\n",
      "Epoch [4/10], Step[6201/60000], Loss: 0.0982\n",
      "Epoch [4/10], Step[6301/60000], Loss: 0.0435\n",
      "Epoch [4/10], Step[6401/60000], Loss: 0.0482\n",
      "Epoch [4/10], Step[6501/60000], Loss: 0.0203\n",
      "Epoch [4/10], Step[6601/60000], Loss: 0.0955\n",
      "Epoch [4/10], Step[6701/60000], Loss: 0.0437\n",
      "Epoch [4/10], Step[6801/60000], Loss: 0.5959\n",
      "Epoch [4/10], Step[6901/60000], Loss: 0.0839\n",
      "Epoch [4/10], Step[7001/60000], Loss: 0.1304\n",
      "Epoch [4/10], Step[7101/60000], Loss: 0.0555\n",
      "Epoch [4/10], Step[7201/60000], Loss: 0.1287\n",
      "Epoch [4/10], Step[7301/60000], Loss: 0.0888\n",
      "Epoch [4/10], Step[7401/60000], Loss: 0.0505\n",
      "Epoch [4/10], Step[7501/60000], Loss: 0.0787\n",
      "Epoch [4/10], Step[7601/60000], Loss: 0.0570\n",
      "Epoch [4/10], Step[7701/60000], Loss: 0.0433\n",
      "Epoch [4/10], Step[7801/60000], Loss: 0.1555\n",
      "Epoch [4/10], Step[7901/60000], Loss: 0.0597\n",
      "Epoch [4/10], Step[8001/60000], Loss: 0.0308\n",
      "Epoch [4/10], Step[8101/60000], Loss: 0.0504\n",
      "Epoch [4/10], Step[8201/60000], Loss: 0.3593\n",
      "Epoch [4/10], Step[8301/60000], Loss: 0.0564\n",
      "Epoch [4/10], Step[8401/60000], Loss: 0.0922\n",
      "Epoch [4/10], Step[8501/60000], Loss: 0.0267\n",
      "Epoch [4/10], Step[8601/60000], Loss: 0.0698\n",
      "Epoch [4/10], Step[8701/60000], Loss: 0.1111\n",
      "Epoch [4/10], Step[8801/60000], Loss: 0.2445\n",
      "Epoch [4/10], Step[8901/60000], Loss: 0.0647\n",
      "Epoch [4/10], Step[9001/60000], Loss: 0.0884\n",
      "Epoch [4/10], Step[9101/60000], Loss: 0.0965\n",
      "Epoch [4/10], Step[9201/60000], Loss: 0.1345\n",
      "Epoch [4/10], Step[9301/60000], Loss: 0.0610\n",
      "Epoch [4/10], Step[9401/60000], Loss: 0.0706\n",
      "Epoch [4/10], Step[9501/60000], Loss: 0.0642\n",
      "Epoch [4/10], Step[9601/60000], Loss: 0.0630\n",
      "Epoch [4/10], Step[9701/60000], Loss: 0.0974\n",
      "Epoch [4/10], Step[9801/60000], Loss: 0.0262\n",
      "Epoch [4/10], Step[9901/60000], Loss: 0.0362\n",
      "Epoch [4/10], Step[10001/60000], Loss: 0.0548\n",
      "Epoch [4/10], Step[10101/60000], Loss: 0.0672\n",
      "Epoch [4/10], Step[10201/60000], Loss: 0.0904\n",
      "Epoch [4/10], Step[10301/60000], Loss: 0.0392\n",
      "Epoch [4/10], Step[10401/60000], Loss: 0.0143\n",
      "Epoch [4/10], Step[10501/60000], Loss: 0.0151\n",
      "Epoch [4/10], Step[10601/60000], Loss: 0.0119\n",
      "Epoch [4/10], Step[10701/60000], Loss: 0.0482\n",
      "Epoch [4/10], Step[10801/60000], Loss: 0.0857\n",
      "Epoch [4/10], Step[10901/60000], Loss: 0.0818\n",
      "Epoch [4/10], Step[11001/60000], Loss: 0.0189\n",
      "Epoch [4/10], Step[11101/60000], Loss: 0.0243\n",
      "Epoch [4/10], Step[11201/60000], Loss: 0.0838\n",
      "Epoch [4/10], Step[11301/60000], Loss: 0.0212\n",
      "Epoch [4/10], Step[11401/60000], Loss: 0.0351\n",
      "Epoch [4/10], Step[11501/60000], Loss: 0.0829\n",
      "Epoch [4/10], Step[11601/60000], Loss: 0.4210\n",
      "Epoch [4/10], Step[11701/60000], Loss: 0.0639\n",
      "Epoch [4/10], Step[11801/60000], Loss: 0.0607\n",
      "Epoch [4/10], Step[11901/60000], Loss: 0.0512\n",
      "Epoch [4/10], Step[12001/60000], Loss: 0.0927\n",
      "Epoch [4/10], Step[12101/60000], Loss: 0.0447\n",
      "Epoch [4/10], Step[12201/60000], Loss: 0.0489\n",
      "Epoch [4/10], Step[12301/60000], Loss: 0.0671\n",
      "Epoch [4/10], Step[12401/60000], Loss: 0.2581\n",
      "Epoch [4/10], Step[12501/60000], Loss: 0.1764\n",
      "Epoch [4/10], Step[12601/60000], Loss: 0.1932\n",
      "Epoch [4/10], Step[12701/60000], Loss: 0.0361\n",
      "Epoch [4/10], Step[12801/60000], Loss: 0.0551\n",
      "Epoch [4/10], Step[12901/60000], Loss: 0.0515\n",
      "Epoch [4/10], Step[13001/60000], Loss: 0.1516\n",
      "Epoch [4/10], Step[13101/60000], Loss: 0.0435\n",
      "Epoch [4/10], Step[13201/60000], Loss: 0.0416\n",
      "Epoch [4/10], Step[13301/60000], Loss: 0.0473\n",
      "Epoch [4/10], Step[13401/60000], Loss: 0.0574\n",
      "Epoch [4/10], Step[13501/60000], Loss: 0.0344\n",
      "Epoch [4/10], Step[13601/60000], Loss: 0.0806\n",
      "Epoch [4/10], Step[13701/60000], Loss: 0.0593\n",
      "Epoch [4/10], Step[13801/60000], Loss: 0.0404\n",
      "Epoch [4/10], Step[13901/60000], Loss: 0.0690\n",
      "Epoch [4/10], Step[14001/60000], Loss: 0.0849\n",
      "Epoch [4/10], Step[14101/60000], Loss: 0.0648\n",
      "Epoch [4/10], Step[14201/60000], Loss: 0.0650\n",
      "Epoch [4/10], Step[14301/60000], Loss: 0.1289\n",
      "Epoch [4/10], Step[14401/60000], Loss: 0.0303\n",
      "Epoch [4/10], Step[14501/60000], Loss: 0.0693\n",
      "Epoch [4/10], Step[14601/60000], Loss: 0.1308\n",
      "Epoch [4/10], Step[14701/60000], Loss: 0.1025\n",
      "Epoch [4/10], Step[14801/60000], Loss: 0.0324\n",
      "Epoch [4/10], Step[14901/60000], Loss: 0.0290\n",
      "Epoch [4/10], Step[15001/60000], Loss: 0.0664\n",
      "Epoch [4/10], Step[15101/60000], Loss: 0.2750\n",
      "Epoch [4/10], Step[15201/60000], Loss: 0.2842\n",
      "Epoch [4/10], Step[15301/60000], Loss: 0.0582\n",
      "Epoch [4/10], Step[15401/60000], Loss: 0.0515\n",
      "Epoch [4/10], Step[15501/60000], Loss: 0.0482\n",
      "Epoch [4/10], Step[15601/60000], Loss: 0.0375\n",
      "Epoch [4/10], Step[15701/60000], Loss: 0.1081\n",
      "Epoch [4/10], Step[15801/60000], Loss: 0.1447\n",
      "Epoch [4/10], Step[15901/60000], Loss: 0.1058\n",
      "Epoch [4/10], Step[16001/60000], Loss: 0.0764\n",
      "Epoch [4/10], Step[16101/60000], Loss: 0.0641\n",
      "Epoch [4/10], Step[16201/60000], Loss: 0.0269\n",
      "Epoch [4/10], Step[16301/60000], Loss: 0.0709\n",
      "Epoch [4/10], Step[16401/60000], Loss: 0.1180\n",
      "Epoch [4/10], Step[16501/60000], Loss: 0.0602\n",
      "Epoch [4/10], Step[16601/60000], Loss: 0.0936\n",
      "Epoch [4/10], Step[16701/60000], Loss: 0.0944\n",
      "Epoch [4/10], Step[16801/60000], Loss: 0.2223\n",
      "Epoch [4/10], Step[16901/60000], Loss: 0.0958\n",
      "Epoch [4/10], Step[17001/60000], Loss: 0.0613\n",
      "Epoch [4/10], Step[17101/60000], Loss: 0.0949\n",
      "Epoch [4/10], Step[17201/60000], Loss: 0.0847\n",
      "Epoch [4/10], Step[17301/60000], Loss: 0.1755\n",
      "Epoch [4/10], Step[17401/60000], Loss: 0.0580\n",
      "Epoch [4/10], Step[17501/60000], Loss: 0.1010\n",
      "Epoch [4/10], Step[17601/60000], Loss: 0.0644\n",
      "Epoch [4/10], Step[17701/60000], Loss: 0.1325\n",
      "Epoch [4/10], Step[17801/60000], Loss: 0.0824\n",
      "Epoch [4/10], Step[17901/60000], Loss: 0.0424\n",
      "Epoch [4/10], Step[18001/60000], Loss: 0.0984\n",
      "Epoch [4/10], Step[18101/60000], Loss: 0.0514\n",
      "Epoch [4/10], Step[18201/60000], Loss: 0.0524\n",
      "Epoch [4/10], Step[18301/60000], Loss: 0.0709\n",
      "Epoch [4/10], Step[18401/60000], Loss: 0.0279\n",
      "Epoch [4/10], Step[18501/60000], Loss: 0.0585\n",
      "Epoch [4/10], Step[18601/60000], Loss: 0.0420\n",
      "Epoch [4/10], Step[18701/60000], Loss: 0.1122\n",
      "Epoch [4/10], Step[18801/60000], Loss: 0.0245\n",
      "Epoch [4/10], Step[18901/60000], Loss: 0.0216\n",
      "Epoch [4/10], Step[19001/60000], Loss: 0.0562\n",
      "Epoch [4/10], Step[19101/60000], Loss: 0.0771\n",
      "Epoch [4/10], Step[19201/60000], Loss: 0.0515\n",
      "Epoch [4/10], Step[19301/60000], Loss: 0.1077\n",
      "Epoch [4/10], Step[19401/60000], Loss: 0.0395\n",
      "Epoch [4/10], Step[19501/60000], Loss: 0.0604\n",
      "Epoch [4/10], Step[19601/60000], Loss: 0.0139\n",
      "Epoch [4/10], Step[19701/60000], Loss: 0.0268\n",
      "Epoch [4/10], Step[19801/60000], Loss: 0.0768\n",
      "Epoch [4/10], Step[19901/60000], Loss: 0.0807\n",
      "Epoch [4/10], Step[20001/60000], Loss: 0.0973\n",
      "Epoch [4/10], Step[20101/60000], Loss: 0.0834\n",
      "Epoch [4/10], Step[20201/60000], Loss: 0.0552\n",
      "Epoch [4/10], Step[20301/60000], Loss: 0.0733\n",
      "Epoch [4/10], Step[20401/60000], Loss: 0.0126\n",
      "Epoch [4/10], Step[20501/60000], Loss: 0.0203\n",
      "Epoch [4/10], Step[20601/60000], Loss: 0.1246\n",
      "Epoch [4/10], Step[20701/60000], Loss: 0.2215\n",
      "Epoch [4/10], Step[20801/60000], Loss: 0.0772\n",
      "Epoch [4/10], Step[20901/60000], Loss: 0.1087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step[21001/60000], Loss: 0.1180\n",
      "Epoch [4/10], Step[21101/60000], Loss: 0.1032\n",
      "Epoch [4/10], Step[21201/60000], Loss: 0.0349\n",
      "Epoch [4/10], Step[21301/60000], Loss: 0.0771\n",
      "Epoch [4/10], Step[21401/60000], Loss: 0.0638\n",
      "Epoch [4/10], Step[21501/60000], Loss: 0.0621\n",
      "Epoch [4/10], Step[21601/60000], Loss: 0.1215\n",
      "Epoch [4/10], Step[21701/60000], Loss: 0.0176\n",
      "Epoch [4/10], Step[21801/60000], Loss: 0.0517\n",
      "Epoch [4/10], Step[21901/60000], Loss: 0.0851\n",
      "Epoch [4/10], Step[22001/60000], Loss: 0.1070\n",
      "Epoch [4/10], Step[22101/60000], Loss: 0.1011\n",
      "Epoch [4/10], Step[22201/60000], Loss: 0.0608\n",
      "Epoch [4/10], Step[22301/60000], Loss: 0.0155\n",
      "Epoch [4/10], Step[22401/60000], Loss: 0.1709\n",
      "Epoch [4/10], Step[22501/60000], Loss: 0.1068\n",
      "Epoch [4/10], Step[22601/60000], Loss: 0.0308\n",
      "Epoch [4/10], Step[22701/60000], Loss: 0.0452\n",
      "Epoch [4/10], Step[22801/60000], Loss: 0.0354\n",
      "Epoch [4/10], Step[22901/60000], Loss: 0.0237\n",
      "Epoch [4/10], Step[23001/60000], Loss: 0.0496\n",
      "Epoch [4/10], Step[23101/60000], Loss: 0.0395\n",
      "Epoch [4/10], Step[23201/60000], Loss: 0.1872\n",
      "Epoch [4/10], Step[23301/60000], Loss: 0.0518\n",
      "Epoch [4/10], Step[23401/60000], Loss: 0.0998\n",
      "Epoch [4/10], Step[23501/60000], Loss: 0.0476\n",
      "Epoch [4/10], Step[23601/60000], Loss: 0.0533\n",
      "Epoch [4/10], Step[23701/60000], Loss: 0.0988\n",
      "Epoch [4/10], Step[23801/60000], Loss: 0.0580\n",
      "Epoch [4/10], Step[23901/60000], Loss: 0.1723\n",
      "Epoch [4/10], Step[24001/60000], Loss: 0.0494\n",
      "Epoch [4/10], Step[24101/60000], Loss: 0.0455\n",
      "Epoch [4/10], Step[24201/60000], Loss: 0.0905\n",
      "Epoch [4/10], Step[24301/60000], Loss: 0.0434\n",
      "Epoch [4/10], Step[24401/60000], Loss: 0.0131\n",
      "Epoch [4/10], Step[24501/60000], Loss: 0.0924\n",
      "Epoch [4/10], Step[24601/60000], Loss: 0.0341\n",
      "Epoch [4/10], Step[24701/60000], Loss: 0.0546\n",
      "Epoch [4/10], Step[24801/60000], Loss: 0.0738\n",
      "Epoch [4/10], Step[24901/60000], Loss: 0.0492\n",
      "Epoch [4/10], Step[25001/60000], Loss: 0.0225\n",
      "Epoch [4/10], Step[25101/60000], Loss: 0.0905\n",
      "Epoch [4/10], Step[25201/60000], Loss: 0.0489\n",
      "Epoch [4/10], Step[25301/60000], Loss: 0.0324\n",
      "Epoch [4/10], Step[25401/60000], Loss: 0.0313\n",
      "Epoch [4/10], Step[25501/60000], Loss: 0.1665\n",
      "Epoch [4/10], Step[25601/60000], Loss: 0.0610\n",
      "Epoch [4/10], Step[25701/60000], Loss: 0.0905\n",
      "Epoch [4/10], Step[25801/60000], Loss: 0.0935\n",
      "Epoch [4/10], Step[25901/60000], Loss: 0.0329\n",
      "Epoch [4/10], Step[26001/60000], Loss: 0.0368\n",
      "Epoch [4/10], Step[26101/60000], Loss: 0.0933\n",
      "Epoch [4/10], Step[26201/60000], Loss: 0.0444\n",
      "Epoch [4/10], Step[26301/60000], Loss: 0.1117\n",
      "Epoch [4/10], Step[26401/60000], Loss: 0.0628\n",
      "Epoch [4/10], Step[26501/60000], Loss: 0.1838\n",
      "Epoch [4/10], Step[26601/60000], Loss: 0.0803\n",
      "Epoch [4/10], Step[26701/60000], Loss: 0.1401\n",
      "Epoch [4/10], Step[26801/60000], Loss: 0.2702\n",
      "Epoch [4/10], Step[26901/60000], Loss: 0.0501\n",
      "Epoch [4/10], Step[27001/60000], Loss: 0.0254\n",
      "Epoch [4/10], Step[27101/60000], Loss: 0.1377\n",
      "Epoch [4/10], Step[27201/60000], Loss: 0.1044\n",
      "Epoch [4/10], Step[27301/60000], Loss: 0.0219\n",
      "Epoch [4/10], Step[27401/60000], Loss: 0.0335\n",
      "Epoch [4/10], Step[27501/60000], Loss: 0.0912\n",
      "Epoch [4/10], Step[27601/60000], Loss: 0.0439\n",
      "Epoch [4/10], Step[27701/60000], Loss: 0.0498\n",
      "Epoch [4/10], Step[27801/60000], Loss: 0.1292\n",
      "Epoch [4/10], Step[27901/60000], Loss: 0.0244\n",
      "Epoch [4/10], Step[28001/60000], Loss: 0.0172\n",
      "Epoch [4/10], Step[28101/60000], Loss: 0.0292\n",
      "Epoch [4/10], Step[28201/60000], Loss: 0.0546\n",
      "Epoch [4/10], Step[28301/60000], Loss: 0.1054\n",
      "Epoch [4/10], Step[28401/60000], Loss: 0.0353\n",
      "Epoch [4/10], Step[28501/60000], Loss: 0.0409\n",
      "Epoch [4/10], Step[28601/60000], Loss: 0.1628\n",
      "Epoch [4/10], Step[28701/60000], Loss: 0.0789\n",
      "Epoch [4/10], Step[28801/60000], Loss: 0.0809\n",
      "Epoch [4/10], Step[28901/60000], Loss: 0.0443\n",
      "Epoch [4/10], Step[29001/60000], Loss: 0.0488\n",
      "Epoch [4/10], Step[29101/60000], Loss: 0.0440\n",
      "Epoch [4/10], Step[29201/60000], Loss: 0.0824\n",
      "Epoch [4/10], Step[29301/60000], Loss: 0.0840\n",
      "Epoch [4/10], Step[29401/60000], Loss: 0.0572\n",
      "Epoch [4/10], Step[29501/60000], Loss: 0.0444\n",
      "Epoch [4/10], Step[29601/60000], Loss: 0.0509\n",
      "Epoch [4/10], Step[29701/60000], Loss: 0.0756\n",
      "Epoch [4/10], Step[29801/60000], Loss: 0.0564\n",
      "Epoch [4/10], Step[29901/60000], Loss: 0.0884\n",
      "Epoch [4/10], Step[30001/60000], Loss: 0.0894\n",
      "Epoch [4/10], Step[30101/60000], Loss: 0.0574\n",
      "Epoch [4/10], Step[30201/60000], Loss: 0.0131\n",
      "Epoch [4/10], Step[30301/60000], Loss: 0.0385\n",
      "Epoch [4/10], Step[30401/60000], Loss: 0.0414\n",
      "Epoch [4/10], Step[30501/60000], Loss: 0.0350\n",
      "Epoch [4/10], Step[30601/60000], Loss: 0.0460\n",
      "Epoch [4/10], Step[30701/60000], Loss: 0.0386\n",
      "Epoch [4/10], Step[30801/60000], Loss: 0.0303\n",
      "Epoch [4/10], Step[30901/60000], Loss: 0.1008\n",
      "Epoch [4/10], Step[31001/60000], Loss: 0.0342\n",
      "Epoch [4/10], Step[31101/60000], Loss: 0.2803\n",
      "Epoch [4/10], Step[31201/60000], Loss: 0.4119\n",
      "Epoch [4/10], Step[31301/60000], Loss: 0.0626\n",
      "Epoch [4/10], Step[31401/60000], Loss: 0.0434\n",
      "Epoch [4/10], Step[31501/60000], Loss: 0.1062\n",
      "Epoch [4/10], Step[31601/60000], Loss: 0.1444\n",
      "Epoch [4/10], Step[31701/60000], Loss: 0.3425\n",
      "Epoch [4/10], Step[31801/60000], Loss: 0.0859\n",
      "Epoch [4/10], Step[31901/60000], Loss: 0.0844\n",
      "Epoch [4/10], Step[32001/60000], Loss: 0.2106\n",
      "Epoch [4/10], Step[32101/60000], Loss: 0.0375\n",
      "Epoch [4/10], Step[32201/60000], Loss: 0.0916\n",
      "Epoch [4/10], Step[32301/60000], Loss: 0.2576\n",
      "Epoch [4/10], Step[32401/60000], Loss: 0.1328\n",
      "Epoch [4/10], Step[32501/60000], Loss: 0.0484\n",
      "Epoch [4/10], Step[32601/60000], Loss: 0.4941\n",
      "Epoch [4/10], Step[32701/60000], Loss: 0.0890\n",
      "Epoch [4/10], Step[32801/60000], Loss: 0.0283\n",
      "Epoch [4/10], Step[32901/60000], Loss: 0.0975\n",
      "Epoch [4/10], Step[33001/60000], Loss: 0.0313\n",
      "Epoch [4/10], Step[33101/60000], Loss: 0.0627\n",
      "Epoch [4/10], Step[33201/60000], Loss: 0.0417\n",
      "Epoch [4/10], Step[33301/60000], Loss: 0.0932\n",
      "Epoch [4/10], Step[33401/60000], Loss: 0.0578\n",
      "Epoch [4/10], Step[33501/60000], Loss: 0.0375\n",
      "Epoch [4/10], Step[33601/60000], Loss: 0.0808\n",
      "Epoch [4/10], Step[33701/60000], Loss: 0.1495\n",
      "Epoch [4/10], Step[33801/60000], Loss: 0.0144\n",
      "Epoch [4/10], Step[33901/60000], Loss: 0.0196\n",
      "Epoch [4/10], Step[34001/60000], Loss: 0.1257\n",
      "Epoch [4/10], Step[34101/60000], Loss: 0.0209\n",
      "Epoch [4/10], Step[34201/60000], Loss: 0.0115\n",
      "Epoch [4/10], Step[34301/60000], Loss: 0.0256\n",
      "Epoch [4/10], Step[34401/60000], Loss: 0.2077\n",
      "Epoch [4/10], Step[34501/60000], Loss: 0.0940\n",
      "Epoch [4/10], Step[34601/60000], Loss: 0.0708\n",
      "Epoch [4/10], Step[34701/60000], Loss: 0.2764\n",
      "Epoch [4/10], Step[34801/60000], Loss: 0.0646\n",
      "Epoch [4/10], Step[34901/60000], Loss: 0.0742\n",
      "Epoch [4/10], Step[35001/60000], Loss: 0.0554\n",
      "Epoch [4/10], Step[35101/60000], Loss: 0.2536\n",
      "Epoch [4/10], Step[35201/60000], Loss: 0.1336\n",
      "Epoch [4/10], Step[35301/60000], Loss: 0.0490\n",
      "Epoch [4/10], Step[35401/60000], Loss: 0.1649\n",
      "Epoch [4/10], Step[35501/60000], Loss: 0.0198\n",
      "Epoch [4/10], Step[35601/60000], Loss: 0.1330\n",
      "Epoch [4/10], Step[35701/60000], Loss: 0.0165\n",
      "Epoch [4/10], Step[35801/60000], Loss: 0.0320\n",
      "Epoch [4/10], Step[35901/60000], Loss: 0.1159\n",
      "Epoch [4/10], Step[36001/60000], Loss: 0.1350\n",
      "Epoch [4/10], Step[36101/60000], Loss: 0.1246\n",
      "Epoch [4/10], Step[36201/60000], Loss: 0.0378\n",
      "Epoch [4/10], Step[36301/60000], Loss: 0.0227\n",
      "Epoch [4/10], Step[36401/60000], Loss: 0.1367\n",
      "Epoch [4/10], Step[36501/60000], Loss: 0.0380\n",
      "Epoch [4/10], Step[36601/60000], Loss: 0.0152\n",
      "Epoch [4/10], Step[36701/60000], Loss: 0.0546\n",
      "Epoch [4/10], Step[36801/60000], Loss: 0.0807\n",
      "Epoch [4/10], Step[36901/60000], Loss: 0.0967\n",
      "Epoch [4/10], Step[37001/60000], Loss: 0.1042\n",
      "Epoch [4/10], Step[37101/60000], Loss: 0.0587\n",
      "Epoch [4/10], Step[37201/60000], Loss: 0.6255\n",
      "Epoch [4/10], Step[37301/60000], Loss: 0.1488\n",
      "Epoch [4/10], Step[37401/60000], Loss: 0.2005\n",
      "Epoch [4/10], Step[37501/60000], Loss: 0.0531\n",
      "Epoch [4/10], Step[37601/60000], Loss: 0.0264\n",
      "Epoch [4/10], Step[37701/60000], Loss: 0.0555\n",
      "Epoch [4/10], Step[37801/60000], Loss: 0.1842\n",
      "Epoch [4/10], Step[37901/60000], Loss: 0.0386\n",
      "Epoch [4/10], Step[38001/60000], Loss: 0.0377\n",
      "Epoch [4/10], Step[38101/60000], Loss: 0.0320\n",
      "Epoch [4/10], Step[38201/60000], Loss: 0.0218\n",
      "Epoch [4/10], Step[38301/60000], Loss: 0.1115\n",
      "Epoch [4/10], Step[38401/60000], Loss: 0.0505\n",
      "Epoch [4/10], Step[38501/60000], Loss: 0.1033\n",
      "Epoch [4/10], Step[38601/60000], Loss: 0.0955\n",
      "Epoch [4/10], Step[38701/60000], Loss: 0.0856\n",
      "Epoch [4/10], Step[38801/60000], Loss: 0.0193\n",
      "Epoch [4/10], Step[38901/60000], Loss: 0.0706\n",
      "Epoch [4/10], Step[39001/60000], Loss: 0.0531\n",
      "Epoch [4/10], Step[39101/60000], Loss: 0.0806\n",
      "Epoch [4/10], Step[39201/60000], Loss: 0.0515\n",
      "Epoch [4/10], Step[39301/60000], Loss: 0.2239\n",
      "Epoch [4/10], Step[39401/60000], Loss: 0.1243\n",
      "Epoch [4/10], Step[39501/60000], Loss: 0.0425\n",
      "Epoch [4/10], Step[39601/60000], Loss: 0.1168\n",
      "Epoch [4/10], Step[39701/60000], Loss: 0.0237\n",
      "Epoch [4/10], Step[39801/60000], Loss: 0.1014\n",
      "Epoch [4/10], Step[39901/60000], Loss: 0.0450\n",
      "Epoch [4/10], Step[40001/60000], Loss: 0.0360\n",
      "Epoch [4/10], Step[40101/60000], Loss: 0.2983\n",
      "Epoch [4/10], Step[40201/60000], Loss: 0.0683\n",
      "Epoch [4/10], Step[40301/60000], Loss: 0.0626\n",
      "Epoch [4/10], Step[40401/60000], Loss: 0.0096\n",
      "Epoch [4/10], Step[40501/60000], Loss: 0.0166\n",
      "Epoch [4/10], Step[40601/60000], Loss: 0.2045\n",
      "Epoch [4/10], Step[40701/60000], Loss: 0.0484\n",
      "Epoch [4/10], Step[40801/60000], Loss: 0.0534\n",
      "Epoch [4/10], Step[40901/60000], Loss: 0.0682\n",
      "Epoch [4/10], Step[41001/60000], Loss: 0.0911\n",
      "Epoch [4/10], Step[41101/60000], Loss: 0.0417\n",
      "Epoch [4/10], Step[41201/60000], Loss: 0.1093\n",
      "Epoch [4/10], Step[41301/60000], Loss: 0.1340\n",
      "Epoch [4/10], Step[41401/60000], Loss: 0.0997\n",
      "Epoch [4/10], Step[41501/60000], Loss: 0.1366\n",
      "Epoch [4/10], Step[41601/60000], Loss: 0.0406\n",
      "Epoch [4/10], Step[41701/60000], Loss: 0.0319\n",
      "Epoch [4/10], Step[41801/60000], Loss: 0.0616\n",
      "Epoch [4/10], Step[41901/60000], Loss: 0.1227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step[42001/60000], Loss: 0.0366\n",
      "Epoch [4/10], Step[42101/60000], Loss: 0.0880\n",
      "Epoch [4/10], Step[42201/60000], Loss: 0.0304\n",
      "Epoch [4/10], Step[42301/60000], Loss: 0.1354\n",
      "Epoch [4/10], Step[42401/60000], Loss: 0.0889\n",
      "Epoch [4/10], Step[42501/60000], Loss: 0.1625\n",
      "Epoch [4/10], Step[42601/60000], Loss: 0.0269\n",
      "Epoch [4/10], Step[42701/60000], Loss: 0.0550\n",
      "Epoch [4/10], Step[42801/60000], Loss: 0.0927\n",
      "Epoch [4/10], Step[42901/60000], Loss: 0.0923\n",
      "Epoch [4/10], Step[43001/60000], Loss: 0.1245\n",
      "Epoch [4/10], Step[43101/60000], Loss: 0.0626\n",
      "Epoch [4/10], Step[43201/60000], Loss: 0.0249\n",
      "Epoch [4/10], Step[43301/60000], Loss: 0.0131\n",
      "Epoch [4/10], Step[43401/60000], Loss: 0.0478\n",
      "Epoch [4/10], Step[43501/60000], Loss: 0.0700\n",
      "Epoch [4/10], Step[43601/60000], Loss: 0.1329\n",
      "Epoch [4/10], Step[43701/60000], Loss: 0.0210\n",
      "Epoch [4/10], Step[43801/60000], Loss: 0.0908\n",
      "Epoch [4/10], Step[43901/60000], Loss: 0.0775\n",
      "Epoch [4/10], Step[44001/60000], Loss: 0.0967\n",
      "Epoch [4/10], Step[44101/60000], Loss: 0.1300\n",
      "Epoch [4/10], Step[44201/60000], Loss: 0.1166\n",
      "Epoch [4/10], Step[44301/60000], Loss: 0.1311\n",
      "Epoch [4/10], Step[44401/60000], Loss: 0.1695\n",
      "Epoch [4/10], Step[44501/60000], Loss: 0.0235\n",
      "Epoch [4/10], Step[44601/60000], Loss: 0.0327\n",
      "Epoch [4/10], Step[44701/60000], Loss: 0.0217\n",
      "Epoch [4/10], Step[44801/60000], Loss: 0.1493\n",
      "Epoch [4/10], Step[44901/60000], Loss: 0.0394\n",
      "Epoch [4/10], Step[45001/60000], Loss: 0.2986\n",
      "Epoch [4/10], Step[45101/60000], Loss: 0.2868\n",
      "Epoch [4/10], Step[45201/60000], Loss: 0.0760\n",
      "Epoch [4/10], Step[45301/60000], Loss: 0.0374\n",
      "Epoch [4/10], Step[45401/60000], Loss: 0.0339\n",
      "Epoch [4/10], Step[45501/60000], Loss: 0.0943\n",
      "Epoch [4/10], Step[45601/60000], Loss: 0.1440\n",
      "Epoch [4/10], Step[45701/60000], Loss: 0.0273\n",
      "Epoch [4/10], Step[45801/60000], Loss: 0.0680\n",
      "Epoch [4/10], Step[45901/60000], Loss: 0.0721\n",
      "Epoch [4/10], Step[46001/60000], Loss: 0.3707\n",
      "Epoch [4/10], Step[46101/60000], Loss: 0.0778\n",
      "Epoch [4/10], Step[46201/60000], Loss: 0.1471\n",
      "Epoch [4/10], Step[46301/60000], Loss: 0.0632\n",
      "Epoch [4/10], Step[46401/60000], Loss: 0.1169\n",
      "Epoch [4/10], Step[46501/60000], Loss: 0.0664\n",
      "Epoch [4/10], Step[46601/60000], Loss: 0.3354\n",
      "Epoch [4/10], Step[46701/60000], Loss: 0.1004\n",
      "Epoch [4/10], Step[46801/60000], Loss: 0.0775\n",
      "Epoch [4/10], Step[46901/60000], Loss: 0.0691\n",
      "Epoch [4/10], Step[47001/60000], Loss: 0.1142\n",
      "Epoch [4/10], Step[47101/60000], Loss: 0.0520\n",
      "Epoch [4/10], Step[47201/60000], Loss: 0.1590\n",
      "Epoch [4/10], Step[47301/60000], Loss: 0.1231\n",
      "Epoch [4/10], Step[47401/60000], Loss: 0.2792\n",
      "Epoch [4/10], Step[47501/60000], Loss: 0.0557\n",
      "Epoch [4/10], Step[47601/60000], Loss: 0.1269\n",
      "Epoch [4/10], Step[47701/60000], Loss: 0.0510\n",
      "Epoch [4/10], Step[47801/60000], Loss: 0.0534\n",
      "Epoch [4/10], Step[47901/60000], Loss: 0.0923\n",
      "Epoch [4/10], Step[48001/60000], Loss: 0.0310\n",
      "Epoch [4/10], Step[48101/60000], Loss: 0.0691\n",
      "Epoch [4/10], Step[48201/60000], Loss: 0.0449\n",
      "Epoch [4/10], Step[48301/60000], Loss: 0.0643\n",
      "Epoch [4/10], Step[48401/60000], Loss: 0.0121\n",
      "Epoch [4/10], Step[48501/60000], Loss: 0.0765\n",
      "Epoch [4/10], Step[48601/60000], Loss: 0.0619\n",
      "Epoch [4/10], Step[48701/60000], Loss: 0.0234\n",
      "Epoch [4/10], Step[48801/60000], Loss: 0.0917\n",
      "Epoch [4/10], Step[48901/60000], Loss: 0.1619\n",
      "Epoch [4/10], Step[49001/60000], Loss: 0.2507\n",
      "Epoch [4/10], Step[49101/60000], Loss: 0.0459\n",
      "Epoch [4/10], Step[49201/60000], Loss: 0.0793\n",
      "Epoch [4/10], Step[49301/60000], Loss: 0.0530\n",
      "Epoch [4/10], Step[49401/60000], Loss: 0.0743\n",
      "Epoch [4/10], Step[49501/60000], Loss: 0.2136\n",
      "Epoch [4/10], Step[49601/60000], Loss: 0.0880\n",
      "Epoch [4/10], Step[49701/60000], Loss: 0.0340\n",
      "Epoch [4/10], Step[49801/60000], Loss: 0.2077\n",
      "Epoch [4/10], Step[49901/60000], Loss: 0.0523\n",
      "Epoch [4/10], Step[50001/60000], Loss: 0.0845\n",
      "Epoch [4/10], Step[50101/60000], Loss: 0.0248\n",
      "Epoch [4/10], Step[50201/60000], Loss: 0.1857\n",
      "Epoch [4/10], Step[50301/60000], Loss: 0.0694\n",
      "Epoch [4/10], Step[50401/60000], Loss: 0.1045\n",
      "Epoch [4/10], Step[50501/60000], Loss: 0.0507\n",
      "Epoch [4/10], Step[50601/60000], Loss: 0.0389\n",
      "Epoch [4/10], Step[50701/60000], Loss: 0.0432\n",
      "Epoch [4/10], Step[50801/60000], Loss: 0.0539\n",
      "Epoch [4/10], Step[50901/60000], Loss: 0.0375\n",
      "Epoch [4/10], Step[51001/60000], Loss: 0.0197\n",
      "Epoch [4/10], Step[51101/60000], Loss: 0.0556\n",
      "Epoch [4/10], Step[51201/60000], Loss: 0.1472\n",
      "Epoch [4/10], Step[51301/60000], Loss: 0.0437\n",
      "Epoch [4/10], Step[51401/60000], Loss: 0.1330\n",
      "Epoch [4/10], Step[51501/60000], Loss: 0.0475\n",
      "Epoch [4/10], Step[51601/60000], Loss: 0.0448\n",
      "Epoch [4/10], Step[51701/60000], Loss: 0.1298\n",
      "Epoch [4/10], Step[51801/60000], Loss: 0.0113\n",
      "Epoch [4/10], Step[51901/60000], Loss: 0.0642\n",
      "Epoch [4/10], Step[52001/60000], Loss: 0.0609\n",
      "Epoch [4/10], Step[52101/60000], Loss: 0.0920\n",
      "Epoch [4/10], Step[52201/60000], Loss: 0.0747\n",
      "Epoch [4/10], Step[52301/60000], Loss: 0.0744\n",
      "Epoch [4/10], Step[52401/60000], Loss: 0.0159\n",
      "Epoch [4/10], Step[52501/60000], Loss: 0.0369\n",
      "Epoch [4/10], Step[52601/60000], Loss: 0.0502\n",
      "Epoch [4/10], Step[52701/60000], Loss: 0.0525\n",
      "Epoch [4/10], Step[52801/60000], Loss: 0.0862\n",
      "Epoch [4/10], Step[52901/60000], Loss: 0.1462\n",
      "Epoch [4/10], Step[53001/60000], Loss: 0.0469\n",
      "Epoch [4/10], Step[53101/60000], Loss: 0.0304\n",
      "Epoch [4/10], Step[53201/60000], Loss: 0.1074\n",
      "Epoch [4/10], Step[53301/60000], Loss: 0.0481\n",
      "Epoch [4/10], Step[53401/60000], Loss: 0.0454\n",
      "Epoch [4/10], Step[53501/60000], Loss: 0.0753\n",
      "Epoch [4/10], Step[53601/60000], Loss: 0.0812\n",
      "Epoch [4/10], Step[53701/60000], Loss: 0.0227\n",
      "Epoch [4/10], Step[53801/60000], Loss: 0.0307\n",
      "Epoch [4/10], Step[53901/60000], Loss: 0.1256\n",
      "Epoch [4/10], Step[54001/60000], Loss: 0.1392\n",
      "Epoch [4/10], Step[54101/60000], Loss: 0.0460\n",
      "Epoch [4/10], Step[54201/60000], Loss: 0.0494\n",
      "Epoch [4/10], Step[54301/60000], Loss: 0.0223\n",
      "Epoch [4/10], Step[54401/60000], Loss: 0.0371\n",
      "Epoch [4/10], Step[54501/60000], Loss: 0.1022\n",
      "Epoch [4/10], Step[54601/60000], Loss: 0.0228\n",
      "Epoch [4/10], Step[54701/60000], Loss: 0.0366\n",
      "Epoch [4/10], Step[54801/60000], Loss: 0.3838\n",
      "Epoch [4/10], Step[54901/60000], Loss: 0.0546\n",
      "Epoch [4/10], Step[55001/60000], Loss: 0.0364\n",
      "Epoch [4/10], Step[55101/60000], Loss: 0.0309\n",
      "Epoch [4/10], Step[55201/60000], Loss: 0.0761\n",
      "Epoch [4/10], Step[55301/60000], Loss: 0.0941\n",
      "Epoch [4/10], Step[55401/60000], Loss: 0.0478\n",
      "Epoch [4/10], Step[55501/60000], Loss: 0.0413\n",
      "Epoch [4/10], Step[55601/60000], Loss: 0.1510\n",
      "Epoch [4/10], Step[55701/60000], Loss: 0.0844\n",
      "Epoch [4/10], Step[55801/60000], Loss: 0.0807\n",
      "Epoch [4/10], Step[55901/60000], Loss: 0.0428\n",
      "Epoch [4/10], Step[56001/60000], Loss: 0.1249\n",
      "Epoch [4/10], Step[56101/60000], Loss: 0.0216\n",
      "Epoch [4/10], Step[56201/60000], Loss: 0.1231\n",
      "Epoch [4/10], Step[56301/60000], Loss: 0.0450\n",
      "Epoch [4/10], Step[56401/60000], Loss: 0.0913\n",
      "Epoch [4/10], Step[56501/60000], Loss: 0.0515\n",
      "Epoch [4/10], Step[56601/60000], Loss: 0.0384\n",
      "Epoch [4/10], Step[56701/60000], Loss: 0.0284\n",
      "Epoch [4/10], Step[56801/60000], Loss: 0.0339\n",
      "Epoch [4/10], Step[56901/60000], Loss: 0.0260\n",
      "Epoch [4/10], Step[57001/60000], Loss: 0.0398\n",
      "Epoch [4/10], Step[57101/60000], Loss: 0.0106\n",
      "Epoch [4/10], Step[57201/60000], Loss: 0.3354\n",
      "Epoch [4/10], Step[57301/60000], Loss: 0.0685\n",
      "Epoch [4/10], Step[57401/60000], Loss: 0.0503\n",
      "Epoch [4/10], Step[57501/60000], Loss: 0.0423\n",
      "Epoch [4/10], Step[57601/60000], Loss: 0.0666\n",
      "Epoch [4/10], Step[57701/60000], Loss: 0.1178\n",
      "Epoch [4/10], Step[57801/60000], Loss: 0.0416\n",
      "Epoch [4/10], Step[57901/60000], Loss: 0.0407\n",
      "Epoch [4/10], Step[58001/60000], Loss: 0.0640\n",
      "Epoch [4/10], Step[58101/60000], Loss: 0.0372\n",
      "Epoch [4/10], Step[58201/60000], Loss: 0.0377\n",
      "Epoch [4/10], Step[58301/60000], Loss: 0.0264\n",
      "Epoch [4/10], Step[58401/60000], Loss: 0.0159\n",
      "Epoch [4/10], Step[58501/60000], Loss: 0.0196\n",
      "Epoch [4/10], Step[58601/60000], Loss: 0.0539\n",
      "Epoch [4/10], Step[58701/60000], Loss: 0.0094\n",
      "Epoch [4/10], Step[58801/60000], Loss: 0.0654\n",
      "Epoch [4/10], Step[58901/60000], Loss: 0.0320\n",
      "Epoch [4/10], Step[59001/60000], Loss: 0.0055\n",
      "Epoch [4/10], Step[59101/60000], Loss: 0.0031\n",
      "Epoch [4/10], Step[59201/60000], Loss: 0.0219\n",
      "Epoch [4/10], Step[59301/60000], Loss: 0.0500\n",
      "Epoch [4/10], Step[59401/60000], Loss: 0.0228\n",
      "Epoch [4/10], Step[59501/60000], Loss: 0.0092\n",
      "Epoch [4/10], Step[59601/60000], Loss: 0.0190\n",
      "Epoch [4/10], Step[59701/60000], Loss: 0.2549\n",
      "Epoch [4/10], Step[59801/60000], Loss: 0.0019\n",
      "Epoch [4/10], Step[59901/60000], Loss: 0.2128\n",
      "Epoch [5/10], Step[1/60000], Loss: 0.0741\n",
      "Epoch [5/10], Step[101/60000], Loss: 0.1072\n",
      "Epoch [5/10], Step[201/60000], Loss: 0.0577\n",
      "Epoch [5/10], Step[301/60000], Loss: 0.0114\n",
      "Epoch [5/10], Step[401/60000], Loss: 0.2175\n",
      "Epoch [5/10], Step[501/60000], Loss: 0.0903\n",
      "Epoch [5/10], Step[601/60000], Loss: 0.0679\n",
      "Epoch [5/10], Step[701/60000], Loss: 0.0814\n",
      "Epoch [5/10], Step[801/60000], Loss: 0.0487\n",
      "Epoch [5/10], Step[901/60000], Loss: 0.0842\n",
      "Epoch [5/10], Step[1001/60000], Loss: 0.1326\n",
      "Epoch [5/10], Step[1101/60000], Loss: 0.0693\n",
      "Epoch [5/10], Step[1201/60000], Loss: 0.1312\n",
      "Epoch [5/10], Step[1301/60000], Loss: 0.0533\n",
      "Epoch [5/10], Step[1401/60000], Loss: 0.0508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step[1501/60000], Loss: 0.0755\n",
      "Epoch [5/10], Step[1601/60000], Loss: 0.0391\n",
      "Epoch [5/10], Step[1701/60000], Loss: 0.0405\n",
      "Epoch [5/10], Step[1801/60000], Loss: 0.0157\n",
      "Epoch [5/10], Step[1901/60000], Loss: 0.0503\n",
      "Epoch [5/10], Step[2001/60000], Loss: 0.0443\n",
      "Epoch [5/10], Step[2101/60000], Loss: 0.1146\n",
      "Epoch [5/10], Step[2201/60000], Loss: 0.0289\n",
      "Epoch [5/10], Step[2301/60000], Loss: 0.0157\n",
      "Epoch [5/10], Step[2401/60000], Loss: 0.0344\n",
      "Epoch [5/10], Step[2501/60000], Loss: 0.0243\n",
      "Epoch [5/10], Step[2601/60000], Loss: 0.0940\n",
      "Epoch [5/10], Step[2701/60000], Loss: 0.0766\n",
      "Epoch [5/10], Step[2801/60000], Loss: 0.0272\n",
      "Epoch [5/10], Step[2901/60000], Loss: 0.0306\n",
      "Epoch [5/10], Step[3001/60000], Loss: 0.0435\n",
      "Epoch [5/10], Step[3101/60000], Loss: 0.0084\n",
      "Epoch [5/10], Step[3201/60000], Loss: 0.0472\n",
      "Epoch [5/10], Step[3301/60000], Loss: 0.0270\n",
      "Epoch [5/10], Step[3401/60000], Loss: 0.0285\n",
      "Epoch [5/10], Step[3501/60000], Loss: 0.0546\n",
      "Epoch [5/10], Step[3601/60000], Loss: 0.1125\n",
      "Epoch [5/10], Step[3701/60000], Loss: 0.1272\n",
      "Epoch [5/10], Step[3801/60000], Loss: 0.0443\n",
      "Epoch [5/10], Step[3901/60000], Loss: 0.0204\n",
      "Epoch [5/10], Step[4001/60000], Loss: 0.0499\n",
      "Epoch [5/10], Step[4101/60000], Loss: 0.3675\n",
      "Epoch [5/10], Step[4201/60000], Loss: 0.0334\n",
      "Epoch [5/10], Step[4301/60000], Loss: 0.0443\n",
      "Epoch [5/10], Step[4401/60000], Loss: 0.0642\n",
      "Epoch [5/10], Step[4501/60000], Loss: 0.0135\n",
      "Epoch [5/10], Step[4601/60000], Loss: 0.1114\n",
      "Epoch [5/10], Step[4701/60000], Loss: 0.0090\n",
      "Epoch [5/10], Step[4801/60000], Loss: 0.0096\n",
      "Epoch [5/10], Step[4901/60000], Loss: 0.1046\n",
      "Epoch [5/10], Step[5001/60000], Loss: 0.0902\n",
      "Epoch [5/10], Step[5101/60000], Loss: 0.1556\n",
      "Epoch [5/10], Step[5201/60000], Loss: 0.0230\n",
      "Epoch [5/10], Step[5301/60000], Loss: 0.0454\n",
      "Epoch [5/10], Step[5401/60000], Loss: 0.0294\n",
      "Epoch [5/10], Step[5501/60000], Loss: 0.0368\n",
      "Epoch [5/10], Step[5601/60000], Loss: 0.0345\n",
      "Epoch [5/10], Step[5701/60000], Loss: 0.1196\n",
      "Epoch [5/10], Step[5801/60000], Loss: 0.1391\n",
      "Epoch [5/10], Step[5901/60000], Loss: 0.0324\n",
      "Epoch [5/10], Step[6001/60000], Loss: 0.0149\n",
      "Epoch [5/10], Step[6101/60000], Loss: 0.0393\n",
      "Epoch [5/10], Step[6201/60000], Loss: 0.1553\n",
      "Epoch [5/10], Step[6301/60000], Loss: 0.2287\n",
      "Epoch [5/10], Step[6401/60000], Loss: 0.0322\n",
      "Epoch [5/10], Step[6501/60000], Loss: 0.0126\n",
      "Epoch [5/10], Step[6601/60000], Loss: 0.0704\n",
      "Epoch [5/10], Step[6701/60000], Loss: 0.0291\n",
      "Epoch [5/10], Step[6801/60000], Loss: 0.5165\n",
      "Epoch [5/10], Step[6901/60000], Loss: 0.0546\n",
      "Epoch [5/10], Step[7001/60000], Loss: 0.0983\n",
      "Epoch [5/10], Step[7101/60000], Loss: 0.0409\n",
      "Epoch [5/10], Step[7201/60000], Loss: 0.1177\n",
      "Epoch [5/10], Step[7301/60000], Loss: 0.0662\n",
      "Epoch [5/10], Step[7401/60000], Loss: 0.0380\n",
      "Epoch [5/10], Step[7501/60000], Loss: 0.0546\n",
      "Epoch [5/10], Step[7601/60000], Loss: 0.0514\n",
      "Epoch [5/10], Step[7701/60000], Loss: 0.0371\n",
      "Epoch [5/10], Step[7801/60000], Loss: 0.1051\n",
      "Epoch [5/10], Step[7901/60000], Loss: 0.0500\n",
      "Epoch [5/10], Step[8001/60000], Loss: 0.0202\n",
      "Epoch [5/10], Step[8101/60000], Loss: 0.0303\n",
      "Epoch [5/10], Step[8201/60000], Loss: 0.1595\n",
      "Epoch [5/10], Step[8301/60000], Loss: 0.0430\n",
      "Epoch [5/10], Step[8401/60000], Loss: 0.0670\n",
      "Epoch [5/10], Step[8501/60000], Loss: 0.0176\n",
      "Epoch [5/10], Step[8601/60000], Loss: 0.0390\n",
      "Epoch [5/10], Step[8701/60000], Loss: 0.0988\n",
      "Epoch [5/10], Step[8801/60000], Loss: 0.1791\n",
      "Epoch [5/10], Step[8901/60000], Loss: 0.0412\n",
      "Epoch [5/10], Step[9001/60000], Loss: 0.0775\n",
      "Epoch [5/10], Step[9101/60000], Loss: 0.0353\n",
      "Epoch [5/10], Step[9201/60000], Loss: 0.1500\n",
      "Epoch [5/10], Step[9301/60000], Loss: 0.0380\n",
      "Epoch [5/10], Step[9401/60000], Loss: 0.0303\n",
      "Epoch [5/10], Step[9501/60000], Loss: 0.0569\n",
      "Epoch [5/10], Step[9601/60000], Loss: 0.0270\n",
      "Epoch [5/10], Step[9701/60000], Loss: 0.0680\n",
      "Epoch [5/10], Step[9801/60000], Loss: 0.0153\n",
      "Epoch [5/10], Step[9901/60000], Loss: 0.0186\n",
      "Epoch [5/10], Step[10001/60000], Loss: 0.0409\n",
      "Epoch [5/10], Step[10101/60000], Loss: 0.0739\n",
      "Epoch [5/10], Step[10201/60000], Loss: 0.0768\n",
      "Epoch [5/10], Step[10301/60000], Loss: 0.0290\n",
      "Epoch [5/10], Step[10401/60000], Loss: 0.0080\n",
      "Epoch [5/10], Step[10501/60000], Loss: 0.0064\n",
      "Epoch [5/10], Step[10601/60000], Loss: 0.0064\n",
      "Epoch [5/10], Step[10701/60000], Loss: 0.0303\n",
      "Epoch [5/10], Step[10801/60000], Loss: 0.0688\n",
      "Epoch [5/10], Step[10901/60000], Loss: 0.0709\n",
      "Epoch [5/10], Step[11001/60000], Loss: 0.0111\n",
      "Epoch [5/10], Step[11101/60000], Loss: 0.0135\n",
      "Epoch [5/10], Step[11201/60000], Loss: 0.0627\n",
      "Epoch [5/10], Step[11301/60000], Loss: 0.0135\n",
      "Epoch [5/10], Step[11401/60000], Loss: 0.0213\n",
      "Epoch [5/10], Step[11501/60000], Loss: 0.0427\n",
      "Epoch [5/10], Step[11601/60000], Loss: 0.5784\n",
      "Epoch [5/10], Step[11701/60000], Loss: 0.0495\n",
      "Epoch [5/10], Step[11801/60000], Loss: 0.0307\n",
      "Epoch [5/10], Step[11901/60000], Loss: 0.0456\n",
      "Epoch [5/10], Step[12001/60000], Loss: 0.0618\n",
      "Epoch [5/10], Step[12101/60000], Loss: 0.0327\n",
      "Epoch [5/10], Step[12201/60000], Loss: 0.0222\n",
      "Epoch [5/10], Step[12301/60000], Loss: 0.0376\n",
      "Epoch [5/10], Step[12401/60000], Loss: 0.2545\n",
      "Epoch [5/10], Step[12501/60000], Loss: 0.1276\n",
      "Epoch [5/10], Step[12601/60000], Loss: 0.1369\n",
      "Epoch [5/10], Step[12701/60000], Loss: 0.0196\n",
      "Epoch [5/10], Step[12801/60000], Loss: 0.0424\n",
      "Epoch [5/10], Step[12901/60000], Loss: 0.0328\n",
      "Epoch [5/10], Step[13001/60000], Loss: 0.0898\n",
      "Epoch [5/10], Step[13101/60000], Loss: 0.0287\n",
      "Epoch [5/10], Step[13201/60000], Loss: 0.0375\n",
      "Epoch [5/10], Step[13301/60000], Loss: 0.0397\n",
      "Epoch [5/10], Step[13401/60000], Loss: 0.0315\n",
      "Epoch [5/10], Step[13501/60000], Loss: 0.0255\n",
      "Epoch [5/10], Step[13601/60000], Loss: 0.0469\n",
      "Epoch [5/10], Step[13701/60000], Loss: 0.0441\n",
      "Epoch [5/10], Step[13801/60000], Loss: 0.0311\n",
      "Epoch [5/10], Step[13901/60000], Loss: 0.0443\n",
      "Epoch [5/10], Step[14001/60000], Loss: 0.0526\n",
      "Epoch [5/10], Step[14101/60000], Loss: 0.0409\n",
      "Epoch [5/10], Step[14201/60000], Loss: 0.0454\n",
      "Epoch [5/10], Step[14301/60000], Loss: 0.0734\n",
      "Epoch [5/10], Step[14401/60000], Loss: 0.0224\n",
      "Epoch [5/10], Step[14501/60000], Loss: 0.0506\n",
      "Epoch [5/10], Step[14601/60000], Loss: 0.1332\n",
      "Epoch [5/10], Step[14701/60000], Loss: 0.0960\n",
      "Epoch [5/10], Step[14801/60000], Loss: 0.0209\n",
      "Epoch [5/10], Step[14901/60000], Loss: 0.0200\n",
      "Epoch [5/10], Step[15001/60000], Loss: 0.0493\n",
      "Epoch [5/10], Step[15101/60000], Loss: 0.2575\n",
      "Epoch [5/10], Step[15201/60000], Loss: 0.1880\n",
      "Epoch [5/10], Step[15301/60000], Loss: 0.0382\n",
      "Epoch [5/10], Step[15401/60000], Loss: 0.0660\n",
      "Epoch [5/10], Step[15501/60000], Loss: 0.0379\n",
      "Epoch [5/10], Step[15601/60000], Loss: 0.0210\n",
      "Epoch [5/10], Step[15701/60000], Loss: 0.1053\n",
      "Epoch [5/10], Step[15801/60000], Loss: 0.0845\n",
      "Epoch [5/10], Step[15901/60000], Loss: 0.0684\n",
      "Epoch [5/10], Step[16001/60000], Loss: 0.0530\n",
      "Epoch [5/10], Step[16101/60000], Loss: 0.0599\n",
      "Epoch [5/10], Step[16201/60000], Loss: 0.0227\n",
      "Epoch [5/10], Step[16301/60000], Loss: 0.0492\n",
      "Epoch [5/10], Step[16401/60000], Loss: 0.0695\n",
      "Epoch [5/10], Step[16501/60000], Loss: 0.0573\n",
      "Epoch [5/10], Step[16601/60000], Loss: 0.0524\n",
      "Epoch [5/10], Step[16701/60000], Loss: 0.0681\n",
      "Epoch [5/10], Step[16801/60000], Loss: 0.3013\n",
      "Epoch [5/10], Step[16901/60000], Loss: 0.0743\n",
      "Epoch [5/10], Step[17001/60000], Loss: 0.0430\n",
      "Epoch [5/10], Step[17101/60000], Loss: 0.0666\n",
      "Epoch [5/10], Step[17201/60000], Loss: 0.0770\n",
      "Epoch [5/10], Step[17301/60000], Loss: 0.0217\n",
      "Epoch [5/10], Step[17401/60000], Loss: 0.0484\n",
      "Epoch [5/10], Step[17501/60000], Loss: 0.0752\n",
      "Epoch [5/10], Step[17601/60000], Loss: 0.0988\n",
      "Epoch [5/10], Step[17701/60000], Loss: 0.0968\n",
      "Epoch [5/10], Step[17801/60000], Loss: 0.0455\n",
      "Epoch [5/10], Step[17901/60000], Loss: 0.0174\n",
      "Epoch [5/10], Step[18001/60000], Loss: 0.0961\n",
      "Epoch [5/10], Step[18101/60000], Loss: 0.0459\n",
      "Epoch [5/10], Step[18201/60000], Loss: 0.0472\n",
      "Epoch [5/10], Step[18301/60000], Loss: 0.0664\n",
      "Epoch [5/10], Step[18401/60000], Loss: 0.0189\n",
      "Epoch [5/10], Step[18501/60000], Loss: 0.0231\n",
      "Epoch [5/10], Step[18601/60000], Loss: 0.4621\n",
      "Epoch [5/10], Step[18701/60000], Loss: 0.0658\n",
      "Epoch [5/10], Step[18801/60000], Loss: 0.0194\n",
      "Epoch [5/10], Step[18901/60000], Loss: 0.0223\n",
      "Epoch [5/10], Step[19001/60000], Loss: 0.0474\n",
      "Epoch [5/10], Step[19101/60000], Loss: 0.0774\n",
      "Epoch [5/10], Step[19201/60000], Loss: 0.0328\n",
      "Epoch [5/10], Step[19301/60000], Loss: 0.0874\n",
      "Epoch [5/10], Step[19401/60000], Loss: 0.0316\n",
      "Epoch [5/10], Step[19501/60000], Loss: 0.0463\n",
      "Epoch [5/10], Step[19601/60000], Loss: 0.0068\n",
      "Epoch [5/10], Step[19701/60000], Loss: 0.0148\n",
      "Epoch [5/10], Step[19801/60000], Loss: 0.0563\n",
      "Epoch [5/10], Step[19901/60000], Loss: 0.0501\n",
      "Epoch [5/10], Step[20001/60000], Loss: 0.0952\n",
      "Epoch [5/10], Step[20101/60000], Loss: 0.0975\n",
      "Epoch [5/10], Step[20201/60000], Loss: 0.0441\n",
      "Epoch [5/10], Step[20301/60000], Loss: 0.0609\n",
      "Epoch [5/10], Step[20401/60000], Loss: 0.0089\n",
      "Epoch [5/10], Step[20501/60000], Loss: 0.0071\n",
      "Epoch [5/10], Step[20601/60000], Loss: 0.0846\n",
      "Epoch [5/10], Step[20701/60000], Loss: 0.1544\n",
      "Epoch [5/10], Step[20801/60000], Loss: 0.0449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step[20901/60000], Loss: 0.0711\n",
      "Epoch [5/10], Step[21001/60000], Loss: 0.0890\n",
      "Epoch [5/10], Step[21101/60000], Loss: 0.0845\n",
      "Epoch [5/10], Step[21201/60000], Loss: 0.0187\n",
      "Epoch [5/10], Step[21301/60000], Loss: 0.0622\n",
      "Epoch [5/10], Step[21401/60000], Loss: 0.0487\n",
      "Epoch [5/10], Step[21501/60000], Loss: 0.0351\n",
      "Epoch [5/10], Step[21601/60000], Loss: 0.0891\n",
      "Epoch [5/10], Step[21701/60000], Loss: 0.0106\n",
      "Epoch [5/10], Step[21801/60000], Loss: 0.0960\n",
      "Epoch [5/10], Step[21901/60000], Loss: 0.0720\n",
      "Epoch [5/10], Step[22001/60000], Loss: 0.0111\n",
      "Epoch [5/10], Step[22101/60000], Loss: 0.0830\n",
      "Epoch [5/10], Step[22201/60000], Loss: 0.0859\n",
      "Epoch [5/10], Step[22301/60000], Loss: 0.0124\n",
      "Epoch [5/10], Step[22401/60000], Loss: 0.1298\n",
      "Epoch [5/10], Step[22501/60000], Loss: 0.0847\n",
      "Epoch [5/10], Step[22601/60000], Loss: 0.0410\n",
      "Epoch [5/10], Step[22701/60000], Loss: 0.0647\n",
      "Epoch [5/10], Step[22801/60000], Loss: 0.0134\n",
      "Epoch [5/10], Step[22901/60000], Loss: 0.0169\n",
      "Epoch [5/10], Step[23001/60000], Loss: 0.0404\n",
      "Epoch [5/10], Step[23101/60000], Loss: 0.0198\n",
      "Epoch [5/10], Step[23201/60000], Loss: 0.2010\n",
      "Epoch [5/10], Step[23301/60000], Loss: 0.0309\n",
      "Epoch [5/10], Step[23401/60000], Loss: 0.0367\n",
      "Epoch [5/10], Step[23501/60000], Loss: 0.0533\n",
      "Epoch [5/10], Step[23601/60000], Loss: 0.0364\n",
      "Epoch [5/10], Step[23701/60000], Loss: 0.0365\n",
      "Epoch [5/10], Step[23801/60000], Loss: 0.0401\n",
      "Epoch [5/10], Step[23901/60000], Loss: 0.1112\n",
      "Epoch [5/10], Step[24001/60000], Loss: 0.0410\n",
      "Epoch [5/10], Step[24101/60000], Loss: 0.0292\n",
      "Epoch [5/10], Step[24201/60000], Loss: 0.0572\n",
      "Epoch [5/10], Step[24301/60000], Loss: 0.0300\n",
      "Epoch [5/10], Step[24401/60000], Loss: 0.0217\n",
      "Epoch [5/10], Step[24501/60000], Loss: 0.0700\n",
      "Epoch [5/10], Step[24601/60000], Loss: 0.0225\n",
      "Epoch [5/10], Step[24701/60000], Loss: 0.0332\n",
      "Epoch [5/10], Step[24801/60000], Loss: 0.0352\n",
      "Epoch [5/10], Step[24901/60000], Loss: 0.0368\n",
      "Epoch [5/10], Step[25001/60000], Loss: 0.0214\n",
      "Epoch [5/10], Step[25101/60000], Loss: 0.0540\n",
      "Epoch [5/10], Step[25201/60000], Loss: 0.0398\n",
      "Epoch [5/10], Step[25301/60000], Loss: 0.0206\n",
      "Epoch [5/10], Step[25401/60000], Loss: 0.0274\n",
      "Epoch [5/10], Step[25501/60000], Loss: 0.1623\n",
      "Epoch [5/10], Step[25601/60000], Loss: 0.0452\n",
      "Epoch [5/10], Step[25701/60000], Loss: 0.0740\n",
      "Epoch [5/10], Step[25801/60000], Loss: 0.0535\n",
      "Epoch [5/10], Step[25901/60000], Loss: 0.0223\n",
      "Epoch [5/10], Step[26001/60000], Loss: 0.0281\n",
      "Epoch [5/10], Step[26101/60000], Loss: 0.0451\n",
      "Epoch [5/10], Step[26201/60000], Loss: 0.0402\n",
      "Epoch [5/10], Step[26301/60000], Loss: 0.0772\n",
      "Epoch [5/10], Step[26401/60000], Loss: 0.0591\n",
      "Epoch [5/10], Step[26501/60000], Loss: 0.1437\n",
      "Epoch [5/10], Step[26601/60000], Loss: 0.0651\n",
      "Epoch [5/10], Step[26701/60000], Loss: 0.1847\n",
      "Epoch [5/10], Step[26801/60000], Loss: 0.2143\n",
      "Epoch [5/10], Step[26901/60000], Loss: 0.0412\n",
      "Epoch [5/10], Step[27001/60000], Loss: 0.0263\n",
      "Epoch [5/10], Step[27101/60000], Loss: 0.0889\n",
      "Epoch [5/10], Step[27201/60000], Loss: 0.0806\n",
      "Epoch [5/10], Step[27301/60000], Loss: 0.0161\n",
      "Epoch [5/10], Step[27401/60000], Loss: 0.0381\n",
      "Epoch [5/10], Step[27501/60000], Loss: 0.0681\n",
      "Epoch [5/10], Step[27601/60000], Loss: 0.0313\n",
      "Epoch [5/10], Step[27701/60000], Loss: 0.0385\n",
      "Epoch [5/10], Step[27801/60000], Loss: 0.0920\n",
      "Epoch [5/10], Step[27901/60000], Loss: 0.0150\n",
      "Epoch [5/10], Step[28001/60000], Loss: 0.0107\n",
      "Epoch [5/10], Step[28101/60000], Loss: 0.0247\n",
      "Epoch [5/10], Step[28201/60000], Loss: 0.0256\n",
      "Epoch [5/10], Step[28301/60000], Loss: 0.0742\n",
      "Epoch [5/10], Step[28401/60000], Loss: 0.0334\n",
      "Epoch [5/10], Step[28501/60000], Loss: 0.0263\n",
      "Epoch [5/10], Step[28601/60000], Loss: 0.0954\n",
      "Epoch [5/10], Step[28701/60000], Loss: 0.0560\n",
      "Epoch [5/10], Step[28801/60000], Loss: 0.0280\n",
      "Epoch [5/10], Step[28901/60000], Loss: 0.0364\n",
      "Epoch [5/10], Step[29001/60000], Loss: 0.0336\n",
      "Epoch [5/10], Step[29101/60000], Loss: 0.0423\n",
      "Epoch [5/10], Step[29201/60000], Loss: 0.0554\n",
      "Epoch [5/10], Step[29301/60000], Loss: 0.0443\n",
      "Epoch [5/10], Step[29401/60000], Loss: 0.0454\n",
      "Epoch [5/10], Step[29501/60000], Loss: 0.0350\n",
      "Epoch [5/10], Step[29601/60000], Loss: 0.0338\n",
      "Epoch [5/10], Step[29701/60000], Loss: 0.0652\n",
      "Epoch [5/10], Step[29801/60000], Loss: 0.0372\n",
      "Epoch [5/10], Step[29901/60000], Loss: 0.0444\n",
      "Epoch [5/10], Step[30001/60000], Loss: 0.0548\n",
      "Epoch [5/10], Step[30101/60000], Loss: 0.0414\n",
      "Epoch [5/10], Step[30201/60000], Loss: 0.0088\n",
      "Epoch [5/10], Step[30301/60000], Loss: 0.0206\n",
      "Epoch [5/10], Step[30401/60000], Loss: 0.0320\n",
      "Epoch [5/10], Step[30501/60000], Loss: 0.1074\n",
      "Epoch [5/10], Step[30601/60000], Loss: 0.0330\n",
      "Epoch [5/10], Step[30701/60000], Loss: 0.0391\n",
      "Epoch [5/10], Step[30801/60000], Loss: 0.0156\n",
      "Epoch [5/10], Step[30901/60000], Loss: 0.0699\n",
      "Epoch [5/10], Step[31001/60000], Loss: 0.0245\n",
      "Epoch [5/10], Step[31101/60000], Loss: 0.2297\n",
      "Epoch [5/10], Step[31201/60000], Loss: 0.0202\n",
      "Epoch [5/10], Step[31301/60000], Loss: 0.1041\n",
      "Epoch [5/10], Step[31401/60000], Loss: 0.0266\n",
      "Epoch [5/10], Step[31501/60000], Loss: 0.0764\n",
      "Epoch [5/10], Step[31601/60000], Loss: 0.0434\n",
      "Epoch [5/10], Step[31701/60000], Loss: 0.0942\n",
      "Epoch [5/10], Step[31801/60000], Loss: 0.0455\n",
      "Epoch [5/10], Step[31901/60000], Loss: 0.0582\n",
      "Epoch [5/10], Step[32001/60000], Loss: 0.0350\n",
      "Epoch [5/10], Step[32101/60000], Loss: 0.0260\n",
      "Epoch [5/10], Step[32201/60000], Loss: 0.0734\n",
      "Epoch [5/10], Step[32301/60000], Loss: 0.0624\n",
      "Epoch [5/10], Step[32401/60000], Loss: 0.1054\n",
      "Epoch [5/10], Step[32501/60000], Loss: 0.0453\n",
      "Epoch [5/10], Step[32601/60000], Loss: 0.0247\n",
      "Epoch [5/10], Step[32701/60000], Loss: 0.0679\n",
      "Epoch [5/10], Step[32801/60000], Loss: 0.0265\n",
      "Epoch [5/10], Step[32901/60000], Loss: 0.0232\n",
      "Epoch [5/10], Step[33001/60000], Loss: 0.0093\n",
      "Epoch [5/10], Step[33101/60000], Loss: 0.0366\n",
      "Epoch [5/10], Step[33201/60000], Loss: 0.0271\n",
      "Epoch [5/10], Step[33301/60000], Loss: 0.0524\n",
      "Epoch [5/10], Step[33401/60000], Loss: 0.0486\n",
      "Epoch [5/10], Step[33501/60000], Loss: 0.0227\n",
      "Epoch [5/10], Step[33601/60000], Loss: 0.0595\n",
      "Epoch [5/10], Step[33701/60000], Loss: 0.1009\n",
      "Epoch [5/10], Step[33801/60000], Loss: 0.0055\n",
      "Epoch [5/10], Step[33901/60000], Loss: 0.0181\n",
      "Epoch [5/10], Step[34001/60000], Loss: 0.0915\n",
      "Epoch [5/10], Step[34101/60000], Loss: 0.0102\n",
      "Epoch [5/10], Step[34201/60000], Loss: 0.0338\n",
      "Epoch [5/10], Step[34301/60000], Loss: 0.0206\n",
      "Epoch [5/10], Step[34401/60000], Loss: 0.1267\n",
      "Epoch [5/10], Step[34501/60000], Loss: 0.0634\n",
      "Epoch [5/10], Step[34601/60000], Loss: 0.0583\n",
      "Epoch [5/10], Step[34701/60000], Loss: 0.0753\n",
      "Epoch [5/10], Step[34801/60000], Loss: 0.0570\n",
      "Epoch [5/10], Step[34901/60000], Loss: 0.0629\n",
      "Epoch [5/10], Step[35001/60000], Loss: 0.0457\n",
      "Epoch [5/10], Step[35101/60000], Loss: 0.0416\n",
      "Epoch [5/10], Step[35201/60000], Loss: 0.0945\n",
      "Epoch [5/10], Step[35301/60000], Loss: 0.0342\n",
      "Epoch [5/10], Step[35401/60000], Loss: 0.1484\n",
      "Epoch [5/10], Step[35501/60000], Loss: 0.0181\n",
      "Epoch [5/10], Step[35601/60000], Loss: 0.1210\n",
      "Epoch [5/10], Step[35701/60000], Loss: 0.0139\n",
      "Epoch [5/10], Step[35801/60000], Loss: 0.0290\n",
      "Epoch [5/10], Step[35901/60000], Loss: 0.0430\n",
      "Epoch [5/10], Step[36001/60000], Loss: 0.0534\n",
      "Epoch [5/10], Step[36101/60000], Loss: 0.1190\n",
      "Epoch [5/10], Step[36201/60000], Loss: 0.0134\n",
      "Epoch [5/10], Step[36301/60000], Loss: 0.0218\n",
      "Epoch [5/10], Step[36401/60000], Loss: 0.1040\n",
      "Epoch [5/10], Step[36501/60000], Loss: 0.0256\n",
      "Epoch [5/10], Step[36601/60000], Loss: 0.0993\n",
      "Epoch [5/10], Step[36701/60000], Loss: 0.0541\n",
      "Epoch [5/10], Step[36801/60000], Loss: 0.1976\n",
      "Epoch [5/10], Step[36901/60000], Loss: 0.0660\n",
      "Epoch [5/10], Step[37001/60000], Loss: 0.0795\n",
      "Epoch [5/10], Step[37101/60000], Loss: 0.0322\n",
      "Epoch [5/10], Step[37201/60000], Loss: 0.3144\n",
      "Epoch [5/10], Step[37301/60000], Loss: 0.0914\n",
      "Epoch [5/10], Step[37401/60000], Loss: 0.1545\n",
      "Epoch [5/10], Step[37501/60000], Loss: 0.0411\n",
      "Epoch [5/10], Step[37601/60000], Loss: 0.0233\n",
      "Epoch [5/10], Step[37701/60000], Loss: 0.0288\n",
      "Epoch [5/10], Step[37801/60000], Loss: 0.1603\n",
      "Epoch [5/10], Step[37901/60000], Loss: 0.0311\n",
      "Epoch [5/10], Step[38001/60000], Loss: 0.0371\n",
      "Epoch [5/10], Step[38101/60000], Loss: 0.0120\n",
      "Epoch [5/10], Step[38201/60000], Loss: 0.0095\n",
      "Epoch [5/10], Step[38301/60000], Loss: 0.0961\n",
      "Epoch [5/10], Step[38401/60000], Loss: 0.0251\n",
      "Epoch [5/10], Step[38501/60000], Loss: 0.0627\n",
      "Epoch [5/10], Step[38601/60000], Loss: 0.0726\n",
      "Epoch [5/10], Step[38701/60000], Loss: 0.0610\n",
      "Epoch [5/10], Step[38801/60000], Loss: 0.0428\n",
      "Epoch [5/10], Step[38901/60000], Loss: 0.0397\n",
      "Epoch [5/10], Step[39001/60000], Loss: 0.0362\n",
      "Epoch [5/10], Step[39101/60000], Loss: 0.0410\n",
      "Epoch [5/10], Step[39201/60000], Loss: 0.0617\n",
      "Epoch [5/10], Step[39301/60000], Loss: 0.1179\n",
      "Epoch [5/10], Step[39401/60000], Loss: 0.0809\n",
      "Epoch [5/10], Step[39501/60000], Loss: 0.0207\n",
      "Epoch [5/10], Step[39601/60000], Loss: 0.1021\n",
      "Epoch [5/10], Step[39701/60000], Loss: 0.0165\n",
      "Epoch [5/10], Step[39801/60000], Loss: 0.0566\n",
      "Epoch [5/10], Step[39901/60000], Loss: 0.0217\n",
      "Epoch [5/10], Step[40001/60000], Loss: 0.0296\n",
      "Epoch [5/10], Step[40101/60000], Loss: 0.0949\n",
      "Epoch [5/10], Step[40201/60000], Loss: 0.0521\n",
      "Epoch [5/10], Step[40301/60000], Loss: 0.0327\n",
      "Epoch [5/10], Step[40401/60000], Loss: 0.0060\n",
      "Epoch [5/10], Step[40501/60000], Loss: 0.0085\n",
      "Epoch [5/10], Step[40601/60000], Loss: 0.0250\n",
      "Epoch [5/10], Step[40701/60000], Loss: 0.0348\n",
      "Epoch [5/10], Step[40801/60000], Loss: 0.0393\n",
      "Epoch [5/10], Step[40901/60000], Loss: 0.0470\n",
      "Epoch [5/10], Step[41001/60000], Loss: 0.0470\n",
      "Epoch [5/10], Step[41101/60000], Loss: 0.0602\n",
      "Epoch [5/10], Step[41201/60000], Loss: 0.0861\n",
      "Epoch [5/10], Step[41301/60000], Loss: 0.0688\n",
      "Epoch [5/10], Step[41401/60000], Loss: 0.0437\n",
      "Epoch [5/10], Step[41501/60000], Loss: 0.1188\n",
      "Epoch [5/10], Step[41601/60000], Loss: 0.0376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step[41701/60000], Loss: 0.0206\n",
      "Epoch [5/10], Step[41801/60000], Loss: 0.0541\n",
      "Epoch [5/10], Step[41901/60000], Loss: 0.0851\n",
      "Epoch [5/10], Step[42001/60000], Loss: 0.0240\n",
      "Epoch [5/10], Step[42101/60000], Loss: 0.0451\n",
      "Epoch [5/10], Step[42201/60000], Loss: 0.0164\n",
      "Epoch [5/10], Step[42301/60000], Loss: 0.0924\n",
      "Epoch [5/10], Step[42401/60000], Loss: 0.0432\n",
      "Epoch [5/10], Step[42501/60000], Loss: 0.1186\n",
      "Epoch [5/10], Step[42601/60000], Loss: 0.0209\n",
      "Epoch [5/10], Step[42701/60000], Loss: 0.0188\n",
      "Epoch [5/10], Step[42801/60000], Loss: 0.0576\n",
      "Epoch [5/10], Step[42901/60000], Loss: 0.0686\n",
      "Epoch [5/10], Step[43001/60000], Loss: 0.0812\n",
      "Epoch [5/10], Step[43101/60000], Loss: 0.0603\n",
      "Epoch [5/10], Step[43201/60000], Loss: 0.0175\n",
      "Epoch [5/10], Step[43301/60000], Loss: 0.0089\n",
      "Epoch [5/10], Step[43401/60000], Loss: 0.0503\n",
      "Epoch [5/10], Step[43501/60000], Loss: 0.0528\n",
      "Epoch [5/10], Step[43601/60000], Loss: 0.0720\n",
      "Epoch [5/10], Step[43701/60000], Loss: 0.0130\n",
      "Epoch [5/10], Step[43801/60000], Loss: 0.0768\n",
      "Epoch [5/10], Step[43901/60000], Loss: 0.0450\n",
      "Epoch [5/10], Step[44001/60000], Loss: 0.0712\n",
      "Epoch [5/10], Step[44101/60000], Loss: 0.0523\n",
      "Epoch [5/10], Step[44201/60000], Loss: 0.0894\n",
      "Epoch [5/10], Step[44301/60000], Loss: 0.0440\n",
      "Epoch [5/10], Step[44401/60000], Loss: 0.1517\n",
      "Epoch [5/10], Step[44501/60000], Loss: 0.0147\n",
      "Epoch [5/10], Step[44601/60000], Loss: 0.0262\n",
      "Epoch [5/10], Step[44701/60000], Loss: 0.0150\n",
      "Epoch [5/10], Step[44801/60000], Loss: 0.0771\n",
      "Epoch [5/10], Step[44901/60000], Loss: 0.3299\n",
      "Epoch [5/10], Step[45001/60000], Loss: 0.0369\n",
      "Epoch [5/10], Step[45101/60000], Loss: 0.0843\n",
      "Epoch [5/10], Step[45201/60000], Loss: 0.0498\n",
      "Epoch [5/10], Step[45301/60000], Loss: 0.0309\n",
      "Epoch [5/10], Step[45401/60000], Loss: 0.0199\n",
      "Epoch [5/10], Step[45501/60000], Loss: 0.0713\n",
      "Epoch [5/10], Step[45601/60000], Loss: 0.0821\n",
      "Epoch [5/10], Step[45701/60000], Loss: 0.0172\n",
      "Epoch [5/10], Step[45801/60000], Loss: 0.0386\n",
      "Epoch [5/10], Step[45901/60000], Loss: 0.0699\n",
      "Epoch [5/10], Step[46001/60000], Loss: 0.0836\n",
      "Epoch [5/10], Step[46101/60000], Loss: 0.0302\n",
      "Epoch [5/10], Step[46201/60000], Loss: 0.1324\n",
      "Epoch [5/10], Step[46301/60000], Loss: 0.0495\n",
      "Epoch [5/10], Step[46401/60000], Loss: 0.0419\n",
      "Epoch [5/10], Step[46501/60000], Loss: 0.0249\n",
      "Epoch [5/10], Step[46601/60000], Loss: 0.0148\n",
      "Epoch [5/10], Step[46701/60000], Loss: 0.0840\n",
      "Epoch [5/10], Step[46801/60000], Loss: 0.0635\n",
      "Epoch [5/10], Step[46901/60000], Loss: 0.0497\n",
      "Epoch [5/10], Step[47001/60000], Loss: 0.1069\n",
      "Epoch [5/10], Step[47101/60000], Loss: 0.0329\n",
      "Epoch [5/10], Step[47201/60000], Loss: 0.1113\n",
      "Epoch [5/10], Step[47301/60000], Loss: 0.1130\n",
      "Epoch [5/10], Step[47401/60000], Loss: 0.2280\n",
      "Epoch [5/10], Step[47501/60000], Loss: 0.0639\n",
      "Epoch [5/10], Step[47601/60000], Loss: 0.1161\n",
      "Epoch [5/10], Step[47701/60000], Loss: 0.0208\n",
      "Epoch [5/10], Step[47801/60000], Loss: 0.0238\n",
      "Epoch [5/10], Step[47901/60000], Loss: 0.0555\n",
      "Epoch [5/10], Step[48001/60000], Loss: 0.0184\n",
      "Epoch [5/10], Step[48101/60000], Loss: 0.0399\n",
      "Epoch [5/10], Step[48201/60000], Loss: 0.0236\n",
      "Epoch [5/10], Step[48301/60000], Loss: 0.0410\n",
      "Epoch [5/10], Step[48401/60000], Loss: 0.0073\n",
      "Epoch [5/10], Step[48501/60000], Loss: 0.0536\n",
      "Epoch [5/10], Step[48601/60000], Loss: 0.0327\n",
      "Epoch [5/10], Step[48701/60000], Loss: 0.0134\n",
      "Epoch [5/10], Step[48801/60000], Loss: 0.0719\n",
      "Epoch [5/10], Step[48901/60000], Loss: 0.1345\n",
      "Epoch [5/10], Step[49001/60000], Loss: 0.3946\n",
      "Epoch [5/10], Step[49101/60000], Loss: 0.0216\n",
      "Epoch [5/10], Step[49201/60000], Loss: 0.0596\n",
      "Epoch [5/10], Step[49301/60000], Loss: 0.0273\n",
      "Epoch [5/10], Step[49401/60000], Loss: 0.0515\n",
      "Epoch [5/10], Step[49501/60000], Loss: 0.1412\n",
      "Epoch [5/10], Step[49601/60000], Loss: 0.0690\n",
      "Epoch [5/10], Step[49701/60000], Loss: 0.0213\n",
      "Epoch [5/10], Step[49801/60000], Loss: 0.1005\n",
      "Epoch [5/10], Step[49901/60000], Loss: 0.0336\n",
      "Epoch [5/10], Step[50001/60000], Loss: 0.0541\n",
      "Epoch [5/10], Step[50101/60000], Loss: 0.0160\n",
      "Epoch [5/10], Step[50201/60000], Loss: 0.1671\n",
      "Epoch [5/10], Step[50301/60000], Loss: 0.0484\n",
      "Epoch [5/10], Step[50401/60000], Loss: 0.0718\n",
      "Epoch [5/10], Step[50501/60000], Loss: 0.0253\n",
      "Epoch [5/10], Step[50601/60000], Loss: 0.0264\n",
      "Epoch [5/10], Step[50701/60000], Loss: 0.0216\n",
      "Epoch [5/10], Step[50801/60000], Loss: 0.0473\n",
      "Epoch [5/10], Step[50901/60000], Loss: 0.0262\n",
      "Epoch [5/10], Step[51001/60000], Loss: 0.0115\n",
      "Epoch [5/10], Step[51101/60000], Loss: 0.0396\n",
      "Epoch [5/10], Step[51201/60000], Loss: 0.1097\n",
      "Epoch [5/10], Step[51301/60000], Loss: 0.0344\n",
      "Epoch [5/10], Step[51401/60000], Loss: 0.0851\n",
      "Epoch [5/10], Step[51501/60000], Loss: 0.0174\n",
      "Epoch [5/10], Step[51601/60000], Loss: 0.0383\n",
      "Epoch [5/10], Step[51701/60000], Loss: 0.0130\n",
      "Epoch [5/10], Step[51801/60000], Loss: 0.0170\n",
      "Epoch [5/10], Step[51901/60000], Loss: 0.0584\n",
      "Epoch [5/10], Step[52001/60000], Loss: 0.0347\n",
      "Epoch [5/10], Step[52101/60000], Loss: 0.0540\n",
      "Epoch [5/10], Step[52201/60000], Loss: 0.0685\n",
      "Epoch [5/10], Step[52301/60000], Loss: 0.0564\n",
      "Epoch [5/10], Step[52401/60000], Loss: 0.0099\n",
      "Epoch [5/10], Step[52501/60000], Loss: 0.0275\n",
      "Epoch [5/10], Step[52601/60000], Loss: 0.0402\n",
      "Epoch [5/10], Step[52701/60000], Loss: 0.0251\n",
      "Epoch [5/10], Step[52801/60000], Loss: 0.0520\n",
      "Epoch [5/10], Step[52901/60000], Loss: 0.0802\n",
      "Epoch [5/10], Step[53001/60000], Loss: 0.0323\n",
      "Epoch [5/10], Step[53101/60000], Loss: 0.0175\n",
      "Epoch [5/10], Step[53201/60000], Loss: 0.0809\n",
      "Epoch [5/10], Step[53301/60000], Loss: 0.0360\n",
      "Epoch [5/10], Step[53401/60000], Loss: 0.0394\n",
      "Epoch [5/10], Step[53501/60000], Loss: 0.0496\n",
      "Epoch [5/10], Step[53601/60000], Loss: 0.0639\n",
      "Epoch [5/10], Step[53701/60000], Loss: 0.0132\n",
      "Epoch [5/10], Step[53801/60000], Loss: 0.0149\n",
      "Epoch [5/10], Step[53901/60000], Loss: 0.0943\n",
      "Epoch [5/10], Step[54001/60000], Loss: 0.0485\n",
      "Epoch [5/10], Step[54101/60000], Loss: 0.0275\n",
      "Epoch [5/10], Step[54201/60000], Loss: 0.0495\n",
      "Epoch [5/10], Step[54301/60000], Loss: 0.0132\n",
      "Epoch [5/10], Step[54401/60000], Loss: 0.0337\n",
      "Epoch [5/10], Step[54501/60000], Loss: 0.0648\n",
      "Epoch [5/10], Step[54601/60000], Loss: 0.0210\n",
      "Epoch [5/10], Step[54701/60000], Loss: 0.0827\n",
      "Epoch [5/10], Step[54801/60000], Loss: 0.0573\n",
      "Epoch [5/10], Step[54901/60000], Loss: 0.0309\n",
      "Epoch [5/10], Step[55001/60000], Loss: 0.0306\n",
      "Epoch [5/10], Step[55101/60000], Loss: 0.0280\n",
      "Epoch [5/10], Step[55201/60000], Loss: 0.0425\n",
      "Epoch [5/10], Step[55301/60000], Loss: 0.0930\n",
      "Epoch [5/10], Step[55401/60000], Loss: 0.0299\n",
      "Epoch [5/10], Step[55501/60000], Loss: 0.0277\n",
      "Epoch [5/10], Step[55601/60000], Loss: 0.0973\n",
      "Epoch [5/10], Step[55701/60000], Loss: 0.0447\n",
      "Epoch [5/10], Step[55801/60000], Loss: 0.0332\n",
      "Epoch [5/10], Step[55901/60000], Loss: 0.0310\n",
      "Epoch [5/10], Step[56001/60000], Loss: 0.0931\n",
      "Epoch [5/10], Step[56101/60000], Loss: 0.0110\n",
      "Epoch [5/10], Step[56201/60000], Loss: 0.0930\n",
      "Epoch [5/10], Step[56301/60000], Loss: 0.0319\n",
      "Epoch [5/10], Step[56401/60000], Loss: 0.0744\n",
      "Epoch [5/10], Step[56501/60000], Loss: 0.0372\n",
      "Epoch [5/10], Step[56601/60000], Loss: 0.0301\n",
      "Epoch [5/10], Step[56701/60000], Loss: 0.0299\n",
      "Epoch [5/10], Step[56801/60000], Loss: 0.0458\n",
      "Epoch [5/10], Step[56901/60000], Loss: 0.0175\n",
      "Epoch [5/10], Step[57001/60000], Loss: 0.0228\n",
      "Epoch [5/10], Step[57101/60000], Loss: 0.0058\n",
      "Epoch [5/10], Step[57201/60000], Loss: 0.0262\n",
      "Epoch [5/10], Step[57301/60000], Loss: 0.0352\n",
      "Epoch [5/10], Step[57401/60000], Loss: 0.0347\n",
      "Epoch [5/10], Step[57501/60000], Loss: 0.0203\n",
      "Epoch [5/10], Step[57601/60000], Loss: 0.0549\n",
      "Epoch [5/10], Step[57701/60000], Loss: 0.0752\n",
      "Epoch [5/10], Step[57801/60000], Loss: 0.0258\n",
      "Epoch [5/10], Step[57901/60000], Loss: 0.0121\n",
      "Epoch [5/10], Step[58001/60000], Loss: 0.0560\n",
      "Epoch [5/10], Step[58101/60000], Loss: 0.0214\n",
      "Epoch [5/10], Step[58201/60000], Loss: 0.0146\n",
      "Epoch [5/10], Step[58301/60000], Loss: 0.0123\n",
      "Epoch [5/10], Step[58401/60000], Loss: 0.0113\n",
      "Epoch [5/10], Step[58501/60000], Loss: 0.0131\n",
      "Epoch [5/10], Step[58601/60000], Loss: 0.0410\n",
      "Epoch [5/10], Step[58701/60000], Loss: 0.0048\n",
      "Epoch [5/10], Step[58801/60000], Loss: 0.0364\n",
      "Epoch [5/10], Step[58901/60000], Loss: 0.0012\n",
      "Epoch [5/10], Step[59001/60000], Loss: 0.0049\n",
      "Epoch [5/10], Step[59101/60000], Loss: 0.0015\n",
      "Epoch [5/10], Step[59201/60000], Loss: 0.0075\n",
      "Epoch [5/10], Step[59301/60000], Loss: 0.0256\n",
      "Epoch [5/10], Step[59401/60000], Loss: 0.0137\n",
      "Epoch [5/10], Step[59501/60000], Loss: 0.0050\n",
      "Epoch [5/10], Step[59601/60000], Loss: 0.0139\n",
      "Epoch [5/10], Step[59701/60000], Loss: 0.2270\n",
      "Epoch [5/10], Step[59801/60000], Loss: 0.0018\n",
      "Epoch [5/10], Step[59901/60000], Loss: 0.2557\n",
      "Epoch [6/10], Step[1/60000], Loss: 0.0463\n",
      "Epoch [6/10], Step[101/60000], Loss: 0.1006\n",
      "Epoch [6/10], Step[201/60000], Loss: 0.0248\n",
      "Epoch [6/10], Step[301/60000], Loss: 0.0090\n",
      "Epoch [6/10], Step[401/60000], Loss: 0.0607\n",
      "Epoch [6/10], Step[501/60000], Loss: 0.0838\n",
      "Epoch [6/10], Step[601/60000], Loss: 0.4606\n",
      "Epoch [6/10], Step[701/60000], Loss: 0.0560\n",
      "Epoch [6/10], Step[801/60000], Loss: 0.0198\n",
      "Epoch [6/10], Step[901/60000], Loss: 0.0608\n",
      "Epoch [6/10], Step[1001/60000], Loss: 0.0971\n",
      "Epoch [6/10], Step[1101/60000], Loss: 0.0476\n",
      "Epoch [6/10], Step[1201/60000], Loss: 0.0883\n",
      "Epoch [6/10], Step[1301/60000], Loss: 0.0667\n",
      "Epoch [6/10], Step[1401/60000], Loss: 0.0342\n",
      "Epoch [6/10], Step[1501/60000], Loss: 0.0357\n",
      "Epoch [6/10], Step[1601/60000], Loss: 0.0230\n",
      "Epoch [6/10], Step[1701/60000], Loss: 0.0397\n",
      "Epoch [6/10], Step[1801/60000], Loss: 0.0159\n",
      "Epoch [6/10], Step[1901/60000], Loss: 0.0347\n",
      "Epoch [6/10], Step[2001/60000], Loss: 0.0328\n",
      "Epoch [6/10], Step[2101/60000], Loss: 0.0108\n",
      "Epoch [6/10], Step[2201/60000], Loss: 0.0181\n",
      "Epoch [6/10], Step[2301/60000], Loss: 0.0303\n",
      "Epoch [6/10], Step[2401/60000], Loss: 0.0148\n",
      "Epoch [6/10], Step[2501/60000], Loss: 0.0237\n",
      "Epoch [6/10], Step[2601/60000], Loss: 0.0952\n",
      "Epoch [6/10], Step[2701/60000], Loss: 0.0675\n",
      "Epoch [6/10], Step[2801/60000], Loss: 0.0094\n",
      "Epoch [6/10], Step[2901/60000], Loss: 0.0326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step[3001/60000], Loss: 0.0293\n",
      "Epoch [6/10], Step[3101/60000], Loss: 0.0061\n",
      "Epoch [6/10], Step[3201/60000], Loss: 0.4906\n",
      "Epoch [6/10], Step[3301/60000], Loss: 0.0176\n",
      "Epoch [6/10], Step[3401/60000], Loss: 0.0762\n",
      "Epoch [6/10], Step[3501/60000], Loss: 0.0285\n",
      "Epoch [6/10], Step[3601/60000], Loss: 0.0743\n",
      "Epoch [6/10], Step[3701/60000], Loss: 0.0142\n",
      "Epoch [6/10], Step[3801/60000], Loss: 0.0326\n",
      "Epoch [6/10], Step[3901/60000], Loss: 0.0130\n",
      "Epoch [6/10], Step[4001/60000], Loss: 0.0289\n",
      "Epoch [6/10], Step[4101/60000], Loss: 0.0173\n",
      "Epoch [6/10], Step[4201/60000], Loss: 0.0278\n",
      "Epoch [6/10], Step[4301/60000], Loss: 0.0161\n",
      "Epoch [6/10], Step[4401/60000], Loss: 0.0673\n",
      "Epoch [6/10], Step[4501/60000], Loss: 0.0073\n",
      "Epoch [6/10], Step[4601/60000], Loss: 0.0769\n",
      "Epoch [6/10], Step[4701/60000], Loss: 0.0050\n",
      "Epoch [6/10], Step[4801/60000], Loss: 0.0148\n",
      "Epoch [6/10], Step[4901/60000], Loss: 0.0574\n",
      "Epoch [6/10], Step[5001/60000], Loss: 0.0461\n",
      "Epoch [6/10], Step[5101/60000], Loss: 0.1436\n",
      "Epoch [6/10], Step[5201/60000], Loss: 0.0113\n",
      "Epoch [6/10], Step[5301/60000], Loss: 0.0294\n",
      "Epoch [6/10], Step[5401/60000], Loss: 0.0177\n",
      "Epoch [6/10], Step[5501/60000], Loss: 0.0276\n",
      "Epoch [6/10], Step[5601/60000], Loss: 0.0249\n",
      "Epoch [6/10], Step[5701/60000], Loss: 0.0907\n",
      "Epoch [6/10], Step[5801/60000], Loss: 0.1152\n",
      "Epoch [6/10], Step[5901/60000], Loss: 0.0189\n",
      "Epoch [6/10], Step[6001/60000], Loss: 0.0134\n",
      "Epoch [6/10], Step[6101/60000], Loss: 0.0235\n",
      "Epoch [6/10], Step[6201/60000], Loss: 0.0805\n",
      "Epoch [6/10], Step[6301/60000], Loss: 0.0325\n",
      "Epoch [6/10], Step[6401/60000], Loss: 0.0220\n",
      "Epoch [6/10], Step[6501/60000], Loss: 0.0056\n",
      "Epoch [6/10], Step[6601/60000], Loss: 0.0509\n",
      "Epoch [6/10], Step[6701/60000], Loss: 0.0178\n",
      "Epoch [6/10], Step[6801/60000], Loss: 0.2637\n",
      "Epoch [6/10], Step[6901/60000], Loss: 0.0325\n",
      "Epoch [6/10], Step[7001/60000], Loss: 0.0701\n",
      "Epoch [6/10], Step[7101/60000], Loss: 0.0180\n",
      "Epoch [6/10], Step[7201/60000], Loss: 0.1019\n",
      "Epoch [6/10], Step[7301/60000], Loss: 0.0537\n",
      "Epoch [6/10], Step[7401/60000], Loss: 0.0305\n",
      "Epoch [6/10], Step[7501/60000], Loss: 0.0346\n",
      "Epoch [6/10], Step[7601/60000], Loss: 0.0333\n",
      "Epoch [6/10], Step[7701/60000], Loss: 0.0409\n",
      "Epoch [6/10], Step[7801/60000], Loss: 0.0734\n",
      "Epoch [6/10], Step[7901/60000], Loss: 0.0352\n",
      "Epoch [6/10], Step[8001/60000], Loss: 0.0102\n",
      "Epoch [6/10], Step[8101/60000], Loss: 0.0394\n",
      "Epoch [6/10], Step[8201/60000], Loss: 0.1404\n",
      "Epoch [6/10], Step[8301/60000], Loss: 0.0442\n",
      "Epoch [6/10], Step[8401/60000], Loss: 0.0507\n",
      "Epoch [6/10], Step[8501/60000], Loss: 0.0107\n",
      "Epoch [6/10], Step[8601/60000], Loss: 0.0208\n",
      "Epoch [6/10], Step[8701/60000], Loss: 0.0567\n",
      "Epoch [6/10], Step[8801/60000], Loss: 0.1073\n",
      "Epoch [6/10], Step[8901/60000], Loss: 0.0350\n",
      "Epoch [6/10], Step[9001/60000], Loss: 0.0811\n",
      "Epoch [6/10], Step[9101/60000], Loss: 0.2573\n",
      "Epoch [6/10], Step[9201/60000], Loss: 0.0921\n",
      "Epoch [6/10], Step[9301/60000], Loss: 0.0216\n",
      "Epoch [6/10], Step[9401/60000], Loss: 0.0183\n",
      "Epoch [6/10], Step[9501/60000], Loss: 0.0379\n",
      "Epoch [6/10], Step[9601/60000], Loss: 0.0284\n",
      "Epoch [6/10], Step[9701/60000], Loss: 0.0464\n",
      "Epoch [6/10], Step[9801/60000], Loss: 0.0100\n",
      "Epoch [6/10], Step[9901/60000], Loss: 0.0125\n",
      "Epoch [6/10], Step[10001/60000], Loss: 0.0329\n",
      "Epoch [6/10], Step[10101/60000], Loss: 0.0268\n",
      "Epoch [6/10], Step[10201/60000], Loss: 0.0695\n",
      "Epoch [6/10], Step[10301/60000], Loss: 0.0311\n",
      "Epoch [6/10], Step[10401/60000], Loss: 0.0053\n",
      "Epoch [6/10], Step[10501/60000], Loss: 0.0042\n",
      "Epoch [6/10], Step[10601/60000], Loss: 0.0044\n",
      "Epoch [6/10], Step[10701/60000], Loss: 0.0193\n",
      "Epoch [6/10], Step[10801/60000], Loss: 0.0411\n",
      "Epoch [6/10], Step[10901/60000], Loss: 0.0684\n",
      "Epoch [6/10], Step[11001/60000], Loss: 0.0069\n",
      "Epoch [6/10], Step[11101/60000], Loss: 0.0112\n",
      "Epoch [6/10], Step[11201/60000], Loss: 0.0380\n",
      "Epoch [6/10], Step[11301/60000], Loss: 0.0086\n",
      "Epoch [6/10], Step[11401/60000], Loss: 0.0127\n",
      "Epoch [6/10], Step[11501/60000], Loss: 0.0342\n",
      "Epoch [6/10], Step[11601/60000], Loss: 0.2887\n",
      "Epoch [6/10], Step[11701/60000], Loss: 0.0239\n",
      "Epoch [6/10], Step[11801/60000], Loss: 0.0250\n",
      "Epoch [6/10], Step[11901/60000], Loss: 0.0423\n",
      "Epoch [6/10], Step[12001/60000], Loss: 0.0337\n",
      "Epoch [6/10], Step[12101/60000], Loss: 0.0034\n",
      "Epoch [6/10], Step[12201/60000], Loss: 0.0426\n",
      "Epoch [6/10], Step[12301/60000], Loss: 0.0186\n",
      "Epoch [6/10], Step[12401/60000], Loss: 0.1461\n",
      "Epoch [6/10], Step[12501/60000], Loss: 0.0934\n",
      "Epoch [6/10], Step[12601/60000], Loss: 0.0594\n",
      "Epoch [6/10], Step[12701/60000], Loss: 0.0191\n",
      "Epoch [6/10], Step[12801/60000], Loss: 0.0403\n",
      "Epoch [6/10], Step[12901/60000], Loss: 0.0216\n",
      "Epoch [6/10], Step[13001/60000], Loss: 0.0673\n",
      "Epoch [6/10], Step[13101/60000], Loss: 0.0218\n",
      "Epoch [6/10], Step[13201/60000], Loss: 0.0046\n",
      "Epoch [6/10], Step[13301/60000], Loss: 0.0380\n",
      "Epoch [6/10], Step[13401/60000], Loss: 0.0226\n",
      "Epoch [6/10], Step[13501/60000], Loss: 0.0251\n",
      "Epoch [6/10], Step[13601/60000], Loss: 0.0295\n",
      "Epoch [6/10], Step[13701/60000], Loss: 0.0221\n",
      "Epoch [6/10], Step[13801/60000], Loss: 0.0272\n",
      "Epoch [6/10], Step[13901/60000], Loss: 0.0466\n",
      "Epoch [6/10], Step[14001/60000], Loss: 0.0281\n",
      "Epoch [6/10], Step[14101/60000], Loss: 0.0314\n",
      "Epoch [6/10], Step[14201/60000], Loss: 0.0211\n",
      "Epoch [6/10], Step[14301/60000], Loss: 0.0494\n",
      "Epoch [6/10], Step[14401/60000], Loss: 0.0133\n",
      "Epoch [6/10], Step[14501/60000], Loss: 0.0297\n",
      "Epoch [6/10], Step[14601/60000], Loss: 0.2032\n",
      "Epoch [6/10], Step[14701/60000], Loss: 0.0741\n",
      "Epoch [6/10], Step[14801/60000], Loss: 0.0128\n",
      "Epoch [6/10], Step[14901/60000], Loss: 0.0089\n",
      "Epoch [6/10], Step[15001/60000], Loss: 0.0288\n",
      "Epoch [6/10], Step[15101/60000], Loss: 0.0236\n",
      "Epoch [6/10], Step[15201/60000], Loss: 0.0853\n",
      "Epoch [6/10], Step[15301/60000], Loss: 0.0181\n",
      "Epoch [6/10], Step[15401/60000], Loss: 0.0245\n",
      "Epoch [6/10], Step[15501/60000], Loss: 0.0283\n",
      "Epoch [6/10], Step[15601/60000], Loss: 0.0106\n",
      "Epoch [6/10], Step[15701/60000], Loss: 0.0628\n",
      "Epoch [6/10], Step[15801/60000], Loss: 0.0655\n",
      "Epoch [6/10], Step[15901/60000], Loss: 0.0331\n",
      "Epoch [6/10], Step[16001/60000], Loss: 0.0343\n",
      "Epoch [6/10], Step[16101/60000], Loss: 0.0428\n",
      "Epoch [6/10], Step[16201/60000], Loss: 0.0160\n",
      "Epoch [6/10], Step[16301/60000], Loss: 0.0485\n",
      "Epoch [6/10], Step[16401/60000], Loss: 0.0440\n",
      "Epoch [6/10], Step[16501/60000], Loss: 0.0273\n",
      "Epoch [6/10], Step[16601/60000], Loss: 0.0422\n",
      "Epoch [6/10], Step[16701/60000], Loss: 0.0540\n",
      "Epoch [6/10], Step[16801/60000], Loss: 0.1053\n",
      "Epoch [6/10], Step[16901/60000], Loss: 0.0352\n",
      "Epoch [6/10], Step[17001/60000], Loss: 0.0219\n",
      "Epoch [6/10], Step[17101/60000], Loss: 0.0510\n",
      "Epoch [6/10], Step[17201/60000], Loss: 0.1011\n",
      "Epoch [6/10], Step[17301/60000], Loss: 0.0161\n",
      "Epoch [6/10], Step[17401/60000], Loss: 0.0187\n",
      "Epoch [6/10], Step[17501/60000], Loss: 0.0477\n",
      "Epoch [6/10], Step[17601/60000], Loss: 0.0293\n",
      "Epoch [6/10], Step[17701/60000], Loss: 0.0766\n",
      "Epoch [6/10], Step[17801/60000], Loss: 0.0372\n",
      "Epoch [6/10], Step[17901/60000], Loss: 0.0130\n",
      "Epoch [6/10], Step[18001/60000], Loss: 0.0408\n",
      "Epoch [6/10], Step[18101/60000], Loss: 0.0210\n",
      "Epoch [6/10], Step[18201/60000], Loss: 0.0307\n",
      "Epoch [6/10], Step[18301/60000], Loss: 0.0474\n",
      "Epoch [6/10], Step[18401/60000], Loss: 0.0094\n",
      "Epoch [6/10], Step[18501/60000], Loss: 0.0144\n",
      "Epoch [6/10], Step[18601/60000], Loss: 0.0072\n",
      "Epoch [6/10], Step[18701/60000], Loss: 0.0426\n",
      "Epoch [6/10], Step[18801/60000], Loss: 0.0097\n",
      "Epoch [6/10], Step[18901/60000], Loss: 0.0164\n",
      "Epoch [6/10], Step[19001/60000], Loss: 0.0319\n",
      "Epoch [6/10], Step[19101/60000], Loss: 0.0688\n",
      "Epoch [6/10], Step[19201/60000], Loss: 0.0135\n",
      "Epoch [6/10], Step[19301/60000], Loss: 0.0687\n",
      "Epoch [6/10], Step[19401/60000], Loss: 0.0231\n",
      "Epoch [6/10], Step[19501/60000], Loss: 0.0319\n",
      "Epoch [6/10], Step[19601/60000], Loss: 0.0038\n",
      "Epoch [6/10], Step[19701/60000], Loss: 0.0081\n",
      "Epoch [6/10], Step[19801/60000], Loss: 0.0390\n",
      "Epoch [6/10], Step[19901/60000], Loss: 0.0179\n",
      "Epoch [6/10], Step[20001/60000], Loss: 0.0674\n",
      "Epoch [6/10], Step[20101/60000], Loss: 0.0552\n",
      "Epoch [6/10], Step[20201/60000], Loss: 0.0243\n",
      "Epoch [6/10], Step[20301/60000], Loss: 0.0474\n",
      "Epoch [6/10], Step[20401/60000], Loss: 0.0059\n",
      "Epoch [6/10], Step[20501/60000], Loss: 0.0143\n",
      "Epoch [6/10], Step[20601/60000], Loss: 0.0598\n",
      "Epoch [6/10], Step[20701/60000], Loss: 0.1063\n",
      "Epoch [6/10], Step[20801/60000], Loss: 0.0367\n",
      "Epoch [6/10], Step[20901/60000], Loss: 0.0482\n",
      "Epoch [6/10], Step[21001/60000], Loss: 0.0672\n",
      "Epoch [6/10], Step[21101/60000], Loss: 0.0588\n",
      "Epoch [6/10], Step[21201/60000], Loss: 0.0076\n",
      "Epoch [6/10], Step[21301/60000], Loss: 0.0396\n",
      "Epoch [6/10], Step[21401/60000], Loss: 0.0386\n",
      "Epoch [6/10], Step[21501/60000], Loss: 0.0202\n",
      "Epoch [6/10], Step[21601/60000], Loss: 0.0723\n",
      "Epoch [6/10], Step[21701/60000], Loss: 0.0058\n",
      "Epoch [6/10], Step[21801/60000], Loss: 0.1368\n",
      "Epoch [6/10], Step[21901/60000], Loss: 0.0617\n",
      "Epoch [6/10], Step[22001/60000], Loss: 0.0134\n",
      "Epoch [6/10], Step[22101/60000], Loss: 0.0412\n",
      "Epoch [6/10], Step[22201/60000], Loss: 0.0208\n",
      "Epoch [6/10], Step[22301/60000], Loss: 0.0076\n",
      "Epoch [6/10], Step[22401/60000], Loss: 0.0648\n",
      "Epoch [6/10], Step[22501/60000], Loss: 0.0524\n",
      "Epoch [6/10], Step[22601/60000], Loss: 0.0189\n",
      "Epoch [6/10], Step[22701/60000], Loss: 0.0271\n",
      "Epoch [6/10], Step[22801/60000], Loss: 0.0587\n",
      "Epoch [6/10], Step[22901/60000], Loss: 0.0085\n",
      "Epoch [6/10], Step[23001/60000], Loss: 0.0174\n",
      "Epoch [6/10], Step[23101/60000], Loss: 0.0170\n",
      "Epoch [6/10], Step[23201/60000], Loss: 0.1854\n",
      "Epoch [6/10], Step[23301/60000], Loss: 0.0187\n",
      "Epoch [6/10], Step[23401/60000], Loss: 0.0108\n",
      "Epoch [6/10], Step[23501/60000], Loss: 0.0548\n",
      "Epoch [6/10], Step[23601/60000], Loss: 0.0225\n",
      "Epoch [6/10], Step[23701/60000], Loss: 0.0152\n",
      "Epoch [6/10], Step[23801/60000], Loss: 0.0364\n",
      "Epoch [6/10], Step[23901/60000], Loss: 0.0607\n",
      "Epoch [6/10], Step[24001/60000], Loss: 0.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step[24101/60000], Loss: 0.0148\n",
      "Epoch [6/10], Step[24201/60000], Loss: 0.0385\n",
      "Epoch [6/10], Step[24301/60000], Loss: 0.0310\n",
      "Epoch [6/10], Step[24401/60000], Loss: 0.0049\n",
      "Epoch [6/10], Step[24501/60000], Loss: 0.0470\n",
      "Epoch [6/10], Step[24601/60000], Loss: 0.0229\n",
      "Epoch [6/10], Step[24701/60000], Loss: 0.0093\n",
      "Epoch [6/10], Step[24801/60000], Loss: 0.0253\n",
      "Epoch [6/10], Step[24901/60000], Loss: 0.0254\n",
      "Epoch [6/10], Step[25001/60000], Loss: 0.0158\n",
      "Epoch [6/10], Step[25101/60000], Loss: 0.0373\n",
      "Epoch [6/10], Step[25201/60000], Loss: 0.0274\n",
      "Epoch [6/10], Step[25301/60000], Loss: 0.0133\n",
      "Epoch [6/10], Step[25401/60000], Loss: 0.0224\n",
      "Epoch [6/10], Step[25501/60000], Loss: 0.1389\n",
      "Epoch [6/10], Step[25601/60000], Loss: 0.0292\n",
      "Epoch [6/10], Step[25701/60000], Loss: 0.0587\n",
      "Epoch [6/10], Step[25801/60000], Loss: 0.0371\n",
      "Epoch [6/10], Step[25901/60000], Loss: 0.0169\n",
      "Epoch [6/10], Step[26001/60000], Loss: 0.0214\n",
      "Epoch [6/10], Step[26101/60000], Loss: 0.0134\n",
      "Epoch [6/10], Step[26201/60000], Loss: 0.0189\n",
      "Epoch [6/10], Step[26301/60000], Loss: 0.0233\n",
      "Epoch [6/10], Step[26401/60000], Loss: 0.0387\n",
      "Epoch [6/10], Step[26501/60000], Loss: 0.1159\n",
      "Epoch [6/10], Step[26601/60000], Loss: 0.0534\n",
      "Epoch [6/10], Step[26701/60000], Loss: 0.1086\n",
      "Epoch [6/10], Step[26801/60000], Loss: 0.2070\n",
      "Epoch [6/10], Step[26901/60000], Loss: 0.0386\n",
      "Epoch [6/10], Step[27001/60000], Loss: 0.0183\n",
      "Epoch [6/10], Step[27101/60000], Loss: 0.0564\n",
      "Epoch [6/10], Step[27201/60000], Loss: 0.0882\n",
      "Epoch [6/10], Step[27301/60000], Loss: 0.0149\n",
      "Epoch [6/10], Step[27401/60000], Loss: 0.0204\n",
      "Epoch [6/10], Step[27501/60000], Loss: 0.0360\n",
      "Epoch [6/10], Step[27601/60000], Loss: 0.0202\n",
      "Epoch [6/10], Step[27701/60000], Loss: 0.0174\n",
      "Epoch [6/10], Step[27801/60000], Loss: 0.1924\n",
      "Epoch [6/10], Step[27901/60000], Loss: 0.0103\n",
      "Epoch [6/10], Step[28001/60000], Loss: 0.0096\n",
      "Epoch [6/10], Step[28101/60000], Loss: 0.0214\n",
      "Epoch [6/10], Step[28201/60000], Loss: 0.0205\n",
      "Epoch [6/10], Step[28301/60000], Loss: 0.0705\n",
      "Epoch [6/10], Step[28401/60000], Loss: 0.0135\n",
      "Epoch [6/10], Step[28501/60000], Loss: 0.0168\n",
      "Epoch [6/10], Step[28601/60000], Loss: 0.0489\n",
      "Epoch [6/10], Step[28701/60000], Loss: 0.0479\n",
      "Epoch [6/10], Step[28801/60000], Loss: 0.0087\n",
      "Epoch [6/10], Step[28901/60000], Loss: 0.0380\n",
      "Epoch [6/10], Step[29001/60000], Loss: 0.0252\n",
      "Epoch [6/10], Step[29101/60000], Loss: 0.0243\n",
      "Epoch [6/10], Step[29201/60000], Loss: 0.0350\n",
      "Epoch [6/10], Step[29301/60000], Loss: 0.0250\n",
      "Epoch [6/10], Step[29401/60000], Loss: 0.0376\n",
      "Epoch [6/10], Step[29501/60000], Loss: 0.2109\n",
      "Epoch [6/10], Step[29601/60000], Loss: 0.0167\n",
      "Epoch [6/10], Step[29701/60000], Loss: 0.0332\n",
      "Epoch [6/10], Step[29801/60000], Loss: 0.0339\n",
      "Epoch [6/10], Step[29901/60000], Loss: 0.0294\n",
      "Epoch [6/10], Step[30001/60000], Loss: 0.0206\n",
      "Epoch [6/10], Step[30101/60000], Loss: 0.0303\n",
      "Epoch [6/10], Step[30201/60000], Loss: 0.0041\n",
      "Epoch [6/10], Step[30301/60000], Loss: 0.0288\n",
      "Epoch [6/10], Step[30401/60000], Loss: 0.0225\n",
      "Epoch [6/10], Step[30501/60000], Loss: 0.0160\n",
      "Epoch [6/10], Step[30601/60000], Loss: 0.0220\n",
      "Epoch [6/10], Step[30701/60000], Loss: 0.0289\n",
      "Epoch [6/10], Step[30801/60000], Loss: 0.0098\n",
      "Epoch [6/10], Step[30901/60000], Loss: 0.0370\n",
      "Epoch [6/10], Step[31001/60000], Loss: 0.0194\n",
      "Epoch [6/10], Step[31101/60000], Loss: 0.1578\n",
      "Epoch [6/10], Step[31201/60000], Loss: 0.0132\n",
      "Epoch [6/10], Step[31301/60000], Loss: 0.0260\n",
      "Epoch [6/10], Step[31401/60000], Loss: 0.0198\n",
      "Epoch [6/10], Step[31501/60000], Loss: 0.0633\n",
      "Epoch [6/10], Step[31601/60000], Loss: 0.1716\n",
      "Epoch [6/10], Step[31701/60000], Loss: 0.0606\n",
      "Epoch [6/10], Step[31801/60000], Loss: 0.0216\n",
      "Epoch [6/10], Step[31901/60000], Loss: 0.0395\n",
      "Epoch [6/10], Step[32001/60000], Loss: 0.0175\n",
      "Epoch [6/10], Step[32101/60000], Loss: 0.0168\n",
      "Epoch [6/10], Step[32201/60000], Loss: 0.0403\n",
      "Epoch [6/10], Step[32301/60000], Loss: 0.0342\n",
      "Epoch [6/10], Step[32401/60000], Loss: 0.1442\n",
      "Epoch [6/10], Step[32501/60000], Loss: 0.0398\n",
      "Epoch [6/10], Step[32601/60000], Loss: 0.0187\n",
      "Epoch [6/10], Step[32701/60000], Loss: 0.0632\n",
      "Epoch [6/10], Step[32801/60000], Loss: 0.0126\n",
      "Epoch [6/10], Step[32901/60000], Loss: 0.0245\n",
      "Epoch [6/10], Step[33001/60000], Loss: 0.0056\n",
      "Epoch [6/10], Step[33101/60000], Loss: 0.0293\n",
      "Epoch [6/10], Step[33201/60000], Loss: 0.0147\n",
      "Epoch [6/10], Step[33301/60000], Loss: 0.0218\n",
      "Epoch [6/10], Step[33401/60000], Loss: 0.0352\n",
      "Epoch [6/10], Step[33501/60000], Loss: 0.0169\n",
      "Epoch [6/10], Step[33601/60000], Loss: 0.0399\n",
      "Epoch [6/10], Step[33701/60000], Loss: 0.1053\n",
      "Epoch [6/10], Step[33801/60000], Loss: 0.0029\n",
      "Epoch [6/10], Step[33901/60000], Loss: 0.0105\n",
      "Epoch [6/10], Step[34001/60000], Loss: 0.0787\n",
      "Epoch [6/10], Step[34101/60000], Loss: 0.0188\n",
      "Epoch [6/10], Step[34201/60000], Loss: 0.0033\n",
      "Epoch [6/10], Step[34301/60000], Loss: 0.0166\n",
      "Epoch [6/10], Step[34401/60000], Loss: 0.1123\n",
      "Epoch [6/10], Step[34501/60000], Loss: 0.0490\n",
      "Epoch [6/10], Step[34601/60000], Loss: 0.0436\n",
      "Epoch [6/10], Step[34701/60000], Loss: 0.0529\n",
      "Epoch [6/10], Step[34801/60000], Loss: 0.0318\n",
      "Epoch [6/10], Step[34901/60000], Loss: 0.0295\n",
      "Epoch [6/10], Step[35001/60000], Loss: 0.0280\n",
      "Epoch [6/10], Step[35101/60000], Loss: 0.0301\n",
      "Epoch [6/10], Step[35201/60000], Loss: 0.0663\n",
      "Epoch [6/10], Step[35301/60000], Loss: 0.0388\n",
      "Epoch [6/10], Step[35401/60000], Loss: 0.1206\n",
      "Epoch [6/10], Step[35501/60000], Loss: 0.0114\n",
      "Epoch [6/10], Step[35601/60000], Loss: 0.1111\n",
      "Epoch [6/10], Step[35701/60000], Loss: 0.0066\n",
      "Epoch [6/10], Step[35801/60000], Loss: 0.0173\n",
      "Epoch [6/10], Step[35901/60000], Loss: 0.0374\n",
      "Epoch [6/10], Step[36001/60000], Loss: 0.0466\n",
      "Epoch [6/10], Step[36101/60000], Loss: 0.1153\n",
      "Epoch [6/10], Step[36201/60000], Loss: 0.0078\n",
      "Epoch [6/10], Step[36301/60000], Loss: 0.0169\n",
      "Epoch [6/10], Step[36401/60000], Loss: 0.0805\n",
      "Epoch [6/10], Step[36501/60000], Loss: 0.0163\n",
      "Epoch [6/10], Step[36601/60000], Loss: 0.0103\n",
      "Epoch [6/10], Step[36701/60000], Loss: 0.0587\n",
      "Epoch [6/10], Step[36801/60000], Loss: 0.0370\n",
      "Epoch [6/10], Step[36901/60000], Loss: 0.0468\n",
      "Epoch [6/10], Step[37001/60000], Loss: 0.0665\n",
      "Epoch [6/10], Step[37101/60000], Loss: 0.0226\n",
      "Epoch [6/10], Step[37201/60000], Loss: 0.1388\n",
      "Epoch [6/10], Step[37301/60000], Loss: 0.0421\n",
      "Epoch [6/10], Step[37401/60000], Loss: 0.0868\n",
      "Epoch [6/10], Step[37501/60000], Loss: 0.0367\n",
      "Epoch [6/10], Step[37601/60000], Loss: 0.0205\n",
      "Epoch [6/10], Step[37701/60000], Loss: 0.5345\n",
      "Epoch [6/10], Step[37801/60000], Loss: 0.2810\n",
      "Epoch [6/10], Step[37901/60000], Loss: 0.0141\n",
      "Epoch [6/10], Step[38001/60000], Loss: 0.0168\n",
      "Epoch [6/10], Step[38101/60000], Loss: 0.0078\n",
      "Epoch [6/10], Step[38201/60000], Loss: 0.0195\n",
      "Epoch [6/10], Step[38301/60000], Loss: 0.0709\n",
      "Epoch [6/10], Step[38401/60000], Loss: 0.0121\n",
      "Epoch [6/10], Step[38501/60000], Loss: 0.0359\n",
      "Epoch [6/10], Step[38601/60000], Loss: 0.0498\n",
      "Epoch [6/10], Step[38701/60000], Loss: 0.0364\n",
      "Epoch [6/10], Step[38801/60000], Loss: 0.0270\n",
      "Epoch [6/10], Step[38901/60000], Loss: 0.0379\n",
      "Epoch [6/10], Step[39001/60000], Loss: 0.0132\n",
      "Epoch [6/10], Step[39101/60000], Loss: 0.0310\n",
      "Epoch [6/10], Step[39201/60000], Loss: 0.0121\n",
      "Epoch [6/10], Step[39301/60000], Loss: 0.0852\n",
      "Epoch [6/10], Step[39401/60000], Loss: 0.0665\n",
      "Epoch [6/10], Step[39501/60000], Loss: 0.0144\n",
      "Epoch [6/10], Step[39601/60000], Loss: 0.0712\n",
      "Epoch [6/10], Step[39701/60000], Loss: 0.0131\n",
      "Epoch [6/10], Step[39801/60000], Loss: 0.0684\n",
      "Epoch [6/10], Step[39901/60000], Loss: 0.0230\n",
      "Epoch [6/10], Step[40001/60000], Loss: 0.0338\n",
      "Epoch [6/10], Step[40101/60000], Loss: 0.1284\n",
      "Epoch [6/10], Step[40201/60000], Loss: 0.0310\n",
      "Epoch [6/10], Step[40301/60000], Loss: 0.0196\n",
      "Epoch [6/10], Step[40401/60000], Loss: 0.0035\n",
      "Epoch [6/10], Step[40501/60000], Loss: 0.0047\n",
      "Epoch [6/10], Step[40601/60000], Loss: 0.0246\n",
      "Epoch [6/10], Step[40701/60000], Loss: 0.0324\n",
      "Epoch [6/10], Step[40801/60000], Loss: 0.0334\n",
      "Epoch [6/10], Step[40901/60000], Loss: 0.0260\n",
      "Epoch [6/10], Step[41001/60000], Loss: 0.0519\n",
      "Epoch [6/10], Step[41101/60000], Loss: 0.0509\n",
      "Epoch [6/10], Step[41201/60000], Loss: 0.0592\n",
      "Epoch [6/10], Step[41301/60000], Loss: 0.0608\n",
      "Epoch [6/10], Step[41401/60000], Loss: 0.0338\n",
      "Epoch [6/10], Step[41501/60000], Loss: 0.1119\n",
      "Epoch [6/10], Step[41601/60000], Loss: 0.0185\n",
      "Epoch [6/10], Step[41701/60000], Loss: 0.0117\n",
      "Epoch [6/10], Step[41801/60000], Loss: 0.0372\n",
      "Epoch [6/10], Step[41901/60000], Loss: 0.0718\n",
      "Epoch [6/10], Step[42001/60000], Loss: 0.0229\n",
      "Epoch [6/10], Step[42101/60000], Loss: 0.0337\n",
      "Epoch [6/10], Step[42201/60000], Loss: 0.0120\n",
      "Epoch [6/10], Step[42301/60000], Loss: 0.0358\n",
      "Epoch [6/10], Step[42401/60000], Loss: 0.0278\n",
      "Epoch [6/10], Step[42501/60000], Loss: 0.0824\n",
      "Epoch [6/10], Step[42601/60000], Loss: 0.0235\n",
      "Epoch [6/10], Step[42701/60000], Loss: 0.0121\n",
      "Epoch [6/10], Step[42801/60000], Loss: 0.0251\n",
      "Epoch [6/10], Step[42901/60000], Loss: 0.0443\n",
      "Epoch [6/10], Step[43001/60000], Loss: 0.0749\n",
      "Epoch [6/10], Step[43101/60000], Loss: 0.0585\n",
      "Epoch [6/10], Step[43201/60000], Loss: 0.0107\n",
      "Epoch [6/10], Step[43301/60000], Loss: 0.0044\n",
      "Epoch [6/10], Step[43401/60000], Loss: 0.0487\n",
      "Epoch [6/10], Step[43501/60000], Loss: 0.0262\n",
      "Epoch [6/10], Step[43601/60000], Loss: 0.0518\n",
      "Epoch [6/10], Step[43701/60000], Loss: 0.0682\n",
      "Epoch [6/10], Step[43801/60000], Loss: 0.0434\n",
      "Epoch [6/10], Step[43901/60000], Loss: 0.0367\n",
      "Epoch [6/10], Step[44001/60000], Loss: 0.0826\n",
      "Epoch [6/10], Step[44101/60000], Loss: 0.0451\n",
      "Epoch [6/10], Step[44201/60000], Loss: 0.1125\n",
      "Epoch [6/10], Step[44301/60000], Loss: 0.0288\n",
      "Epoch [6/10], Step[44401/60000], Loss: 0.1146\n",
      "Epoch [6/10], Step[44501/60000], Loss: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step[44601/60000], Loss: 0.0167\n",
      "Epoch [6/10], Step[44701/60000], Loss: 0.0113\n",
      "Epoch [6/10], Step[44801/60000], Loss: 0.0532\n",
      "Epoch [6/10], Step[44901/60000], Loss: 0.0600\n",
      "Epoch [6/10], Step[45001/60000], Loss: 0.0412\n",
      "Epoch [6/10], Step[45101/60000], Loss: 0.7925\n",
      "Epoch [6/10], Step[45201/60000], Loss: 0.0323\n",
      "Epoch [6/10], Step[45301/60000], Loss: 0.0398\n",
      "Epoch [6/10], Step[45401/60000], Loss: 0.0145\n",
      "Epoch [6/10], Step[45501/60000], Loss: 0.0527\n",
      "Epoch [6/10], Step[45601/60000], Loss: 0.1610\n",
      "Epoch [6/10], Step[45701/60000], Loss: 0.0164\n",
      "Epoch [6/10], Step[45801/60000], Loss: 0.0321\n",
      "Epoch [6/10], Step[45901/60000], Loss: 0.0519\n",
      "Epoch [6/10], Step[46001/60000], Loss: 0.0898\n",
      "Epoch [6/10], Step[46101/60000], Loss: 0.0205\n",
      "Epoch [6/10], Step[46201/60000], Loss: 0.0701\n",
      "Epoch [6/10], Step[46301/60000], Loss: 0.0372\n",
      "Epoch [6/10], Step[46401/60000], Loss: 0.0499\n",
      "Epoch [6/10], Step[46501/60000], Loss: 0.0162\n",
      "Epoch [6/10], Step[46601/60000], Loss: 0.0077\n",
      "Epoch [6/10], Step[46701/60000], Loss: 0.0592\n",
      "Epoch [6/10], Step[46801/60000], Loss: 0.0581\n",
      "Epoch [6/10], Step[46901/60000], Loss: 0.0430\n",
      "Epoch [6/10], Step[47001/60000], Loss: 0.0612\n",
      "Epoch [6/10], Step[47101/60000], Loss: 0.0274\n",
      "Epoch [6/10], Step[47201/60000], Loss: 0.1074\n",
      "Epoch [6/10], Step[47301/60000], Loss: 0.0890\n",
      "Epoch [6/10], Step[47401/60000], Loss: 0.2137\n",
      "Epoch [6/10], Step[47501/60000], Loss: 0.0525\n",
      "Epoch [6/10], Step[47601/60000], Loss: 0.0882\n",
      "Epoch [6/10], Step[47701/60000], Loss: 0.0076\n",
      "Epoch [6/10], Step[47801/60000], Loss: 0.0123\n",
      "Epoch [6/10], Step[47901/60000], Loss: 0.0380\n",
      "Epoch [6/10], Step[48001/60000], Loss: 0.0132\n",
      "Epoch [6/10], Step[48101/60000], Loss: 0.0146\n",
      "Epoch [6/10], Step[48201/60000], Loss: 0.0131\n",
      "Epoch [6/10], Step[48301/60000], Loss: 0.0826\n",
      "Epoch [6/10], Step[48401/60000], Loss: 0.0118\n",
      "Epoch [6/10], Step[48501/60000], Loss: 0.0255\n",
      "Epoch [6/10], Step[48601/60000], Loss: 0.0216\n",
      "Epoch [6/10], Step[48701/60000], Loss: 0.0095\n",
      "Epoch [6/10], Step[48801/60000], Loss: 0.0456\n",
      "Epoch [6/10], Step[48901/60000], Loss: 0.1315\n",
      "Epoch [6/10], Step[49001/60000], Loss: 0.1551\n",
      "Epoch [6/10], Step[49101/60000], Loss: 0.0258\n",
      "Epoch [6/10], Step[49201/60000], Loss: 0.0346\n",
      "Epoch [6/10], Step[49301/60000], Loss: 0.0172\n",
      "Epoch [6/10], Step[49401/60000], Loss: 0.0459\n",
      "Epoch [6/10], Step[49501/60000], Loss: 0.1177\n",
      "Epoch [6/10], Step[49601/60000], Loss: 0.0391\n",
      "Epoch [6/10], Step[49701/60000], Loss: 0.0389\n",
      "Epoch [6/10], Step[49801/60000], Loss: 0.0592\n",
      "Epoch [6/10], Step[49901/60000], Loss: 0.0206\n",
      "Epoch [6/10], Step[50001/60000], Loss: 0.0397\n",
      "Epoch [6/10], Step[50101/60000], Loss: 0.0114\n",
      "Epoch [6/10], Step[50201/60000], Loss: 0.1065\n",
      "Epoch [6/10], Step[50301/60000], Loss: 0.0314\n",
      "Epoch [6/10], Step[50401/60000], Loss: 0.0674\n",
      "Epoch [6/10], Step[50501/60000], Loss: 0.0241\n",
      "Epoch [6/10], Step[50601/60000], Loss: 0.0190\n",
      "Epoch [6/10], Step[50701/60000], Loss: 0.0206\n",
      "Epoch [6/10], Step[50801/60000], Loss: 0.0340\n",
      "Epoch [6/10], Step[50901/60000], Loss: 0.0261\n",
      "Epoch [6/10], Step[51001/60000], Loss: 0.0109\n",
      "Epoch [6/10], Step[51101/60000], Loss: 0.0277\n",
      "Epoch [6/10], Step[51201/60000], Loss: 0.1006\n",
      "Epoch [6/10], Step[51301/60000], Loss: 0.0294\n",
      "Epoch [6/10], Step[51401/60000], Loss: 0.0438\n",
      "Epoch [6/10], Step[51501/60000], Loss: 0.0089\n",
      "Epoch [6/10], Step[51601/60000], Loss: 0.0446\n",
      "Epoch [6/10], Step[51701/60000], Loss: 0.0390\n",
      "Epoch [6/10], Step[51801/60000], Loss: 0.0141\n",
      "Epoch [6/10], Step[51901/60000], Loss: 0.0494\n",
      "Epoch [6/10], Step[52001/60000], Loss: 0.0309\n",
      "Epoch [6/10], Step[52101/60000], Loss: 0.0357\n",
      "Epoch [6/10], Step[52201/60000], Loss: 0.0617\n",
      "Epoch [6/10], Step[52301/60000], Loss: 0.0518\n",
      "Epoch [6/10], Step[52401/60000], Loss: 0.0071\n",
      "Epoch [6/10], Step[52501/60000], Loss: 0.0139\n",
      "Epoch [6/10], Step[52601/60000], Loss: 0.0305\n",
      "Epoch [6/10], Step[52701/60000], Loss: 0.0139\n",
      "Epoch [6/10], Step[52801/60000], Loss: 0.0259\n",
      "Epoch [6/10], Step[52901/60000], Loss: 0.0233\n",
      "Epoch [6/10], Step[53001/60000], Loss: 0.0186\n",
      "Epoch [6/10], Step[53101/60000], Loss: 0.0133\n",
      "Epoch [6/10], Step[53201/60000], Loss: 0.0544\n",
      "Epoch [6/10], Step[53301/60000], Loss: 0.0294\n",
      "Epoch [6/10], Step[53401/60000], Loss: 0.0228\n",
      "Epoch [6/10], Step[53501/60000], Loss: 0.0397\n",
      "Epoch [6/10], Step[53601/60000], Loss: 0.0663\n",
      "Epoch [6/10], Step[53701/60000], Loss: 0.0292\n",
      "Epoch [6/10], Step[53801/60000], Loss: 0.0072\n",
      "Epoch [6/10], Step[53901/60000], Loss: 0.0993\n",
      "Epoch [6/10], Step[54001/60000], Loss: 0.1576\n",
      "Epoch [6/10], Step[54101/60000], Loss: 0.0120\n",
      "Epoch [6/10], Step[54201/60000], Loss: 0.0318\n",
      "Epoch [6/10], Step[54301/60000], Loss: 0.0075\n",
      "Epoch [6/10], Step[54401/60000], Loss: 0.0348\n",
      "Epoch [6/10], Step[54501/60000], Loss: 0.0484\n",
      "Epoch [6/10], Step[54601/60000], Loss: 0.0142\n",
      "Epoch [6/10], Step[54701/60000], Loss: 0.0181\n",
      "Epoch [6/10], Step[54801/60000], Loss: 0.4800\n",
      "Epoch [6/10], Step[54901/60000], Loss: 0.0314\n",
      "Epoch [6/10], Step[55001/60000], Loss: 0.0182\n",
      "Epoch [6/10], Step[55101/60000], Loss: 0.0183\n",
      "Epoch [6/10], Step[55201/60000], Loss: 0.0326\n",
      "Epoch [6/10], Step[55301/60000], Loss: 0.0752\n",
      "Epoch [6/10], Step[55401/60000], Loss: 0.0136\n",
      "Epoch [6/10], Step[55501/60000], Loss: 0.0200\n",
      "Epoch [6/10], Step[55601/60000], Loss: 0.0145\n",
      "Epoch [6/10], Step[55701/60000], Loss: 0.0302\n",
      "Epoch [6/10], Step[55801/60000], Loss: 0.0242\n",
      "Epoch [6/10], Step[55901/60000], Loss: 0.0180\n",
      "Epoch [6/10], Step[56001/60000], Loss: 0.0335\n",
      "Epoch [6/10], Step[56101/60000], Loss: 0.0093\n",
      "Epoch [6/10], Step[56201/60000], Loss: 0.0697\n",
      "Epoch [6/10], Step[56301/60000], Loss: 0.0333\n",
      "Epoch [6/10], Step[56401/60000], Loss: 0.0963\n",
      "Epoch [6/10], Step[56501/60000], Loss: 0.0305\n",
      "Epoch [6/10], Step[56601/60000], Loss: 0.0193\n",
      "Epoch [6/10], Step[56701/60000], Loss: 0.0250\n",
      "Epoch [6/10], Step[56801/60000], Loss: 0.0113\n",
      "Epoch [6/10], Step[56901/60000], Loss: 0.0112\n",
      "Epoch [6/10], Step[57001/60000], Loss: 0.0128\n",
      "Epoch [6/10], Step[57101/60000], Loss: 0.0106\n",
      "Epoch [6/10], Step[57201/60000], Loss: 0.0130\n",
      "Epoch [6/10], Step[57301/60000], Loss: 0.0261\n",
      "Epoch [6/10], Step[57401/60000], Loss: 0.0347\n",
      "Epoch [6/10], Step[57501/60000], Loss: 0.0185\n",
      "Epoch [6/10], Step[57601/60000], Loss: 0.0590\n",
      "Epoch [6/10], Step[57701/60000], Loss: 0.0478\n",
      "Epoch [6/10], Step[57801/60000], Loss: 0.0298\n",
      "Epoch [6/10], Step[57901/60000], Loss: 0.0093\n",
      "Epoch [6/10], Step[58001/60000], Loss: 0.0385\n",
      "Epoch [6/10], Step[58101/60000], Loss: 0.0141\n",
      "Epoch [6/10], Step[58201/60000], Loss: 0.0104\n",
      "Epoch [6/10], Step[58301/60000], Loss: 0.0134\n",
      "Epoch [6/10], Step[58401/60000], Loss: 0.0068\n",
      "Epoch [6/10], Step[58501/60000], Loss: 0.0166\n",
      "Epoch [6/10], Step[58601/60000], Loss: 0.0390\n",
      "Epoch [6/10], Step[58701/60000], Loss: 0.0057\n",
      "Epoch [6/10], Step[58801/60000], Loss: 0.0185\n",
      "Epoch [6/10], Step[58901/60000], Loss: 0.0015\n",
      "Epoch [6/10], Step[59001/60000], Loss: 0.0106\n",
      "Epoch [6/10], Step[59101/60000], Loss: 0.0023\n",
      "Epoch [6/10], Step[59201/60000], Loss: 0.0042\n",
      "Epoch [6/10], Step[59301/60000], Loss: 0.0201\n",
      "Epoch [6/10], Step[59401/60000], Loss: 0.0097\n",
      "Epoch [6/10], Step[59501/60000], Loss: 0.0068\n",
      "Epoch [6/10], Step[59601/60000], Loss: 0.0102\n",
      "Epoch [6/10], Step[59701/60000], Loss: 0.1392\n",
      "Epoch [6/10], Step[59801/60000], Loss: 0.0040\n",
      "Epoch [6/10], Step[59901/60000], Loss: 0.1930\n",
      "Epoch [7/10], Step[1/60000], Loss: 0.0215\n",
      "Epoch [7/10], Step[101/60000], Loss: 0.1254\n",
      "Epoch [7/10], Step[201/60000], Loss: 0.0145\n",
      "Epoch [7/10], Step[301/60000], Loss: 0.0052\n",
      "Epoch [7/10], Step[401/60000], Loss: 0.0631\n",
      "Epoch [7/10], Step[501/60000], Loss: 0.0459\n",
      "Epoch [7/10], Step[601/60000], Loss: 0.0366\n",
      "Epoch [7/10], Step[701/60000], Loss: 0.0459\n",
      "Epoch [7/10], Step[801/60000], Loss: 0.0139\n",
      "Epoch [7/10], Step[901/60000], Loss: 0.0157\n",
      "Epoch [7/10], Step[1001/60000], Loss: 0.0557\n",
      "Epoch [7/10], Step[1101/60000], Loss: 0.0327\n",
      "Epoch [7/10], Step[1201/60000], Loss: 0.0746\n",
      "Epoch [7/10], Step[1301/60000], Loss: 0.0292\n",
      "Epoch [7/10], Step[1401/60000], Loss: 0.0351\n",
      "Epoch [7/10], Step[1501/60000], Loss: 0.0250\n",
      "Epoch [7/10], Step[1601/60000], Loss: 0.0124\n",
      "Epoch [7/10], Step[1701/60000], Loss: 0.0245\n",
      "Epoch [7/10], Step[1801/60000], Loss: 0.0104\n",
      "Epoch [7/10], Step[1901/60000], Loss: 0.0326\n",
      "Epoch [7/10], Step[2001/60000], Loss: 0.0162\n",
      "Epoch [7/10], Step[2101/60000], Loss: 0.0112\n",
      "Epoch [7/10], Step[2201/60000], Loss: 0.0144\n",
      "Epoch [7/10], Step[2301/60000], Loss: 0.0126\n",
      "Epoch [7/10], Step[2401/60000], Loss: 0.0105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step[2501/60000], Loss: 0.0211\n",
      "Epoch [7/10], Step[2601/60000], Loss: 0.0647\n",
      "Epoch [7/10], Step[2701/60000], Loss: 0.0508\n",
      "Epoch [7/10], Step[2801/60000], Loss: 0.0069\n",
      "Epoch [7/10], Step[2901/60000], Loss: 0.0098\n",
      "Epoch [7/10], Step[3001/60000], Loss: 0.0190\n",
      "Epoch [7/10], Step[3101/60000], Loss: 0.0026\n",
      "Epoch [7/10], Step[3201/60000], Loss: 0.0763\n",
      "Epoch [7/10], Step[3301/60000], Loss: 0.0164\n",
      "Epoch [7/10], Step[3401/60000], Loss: 0.0075\n",
      "Epoch [7/10], Step[3501/60000], Loss: 0.0196\n",
      "Epoch [7/10], Step[3601/60000], Loss: 0.0538\n",
      "Epoch [7/10], Step[3701/60000], Loss: 0.0087\n",
      "Epoch [7/10], Step[3801/60000], Loss: 0.0304\n",
      "Epoch [7/10], Step[3901/60000], Loss: 0.0060\n",
      "Epoch [7/10], Step[4001/60000], Loss: 0.0155\n",
      "Epoch [7/10], Step[4101/60000], Loss: 0.1870\n",
      "Epoch [7/10], Step[4201/60000], Loss: 0.0107\n",
      "Epoch [7/10], Step[4301/60000], Loss: 0.0153\n",
      "Epoch [7/10], Step[4401/60000], Loss: 0.0519\n",
      "Epoch [7/10], Step[4501/60000], Loss: 0.0093\n",
      "Epoch [7/10], Step[4601/60000], Loss: 0.0676\n",
      "Epoch [7/10], Step[4701/60000], Loss: 0.0122\n",
      "Epoch [7/10], Step[4801/60000], Loss: 0.0075\n",
      "Epoch [7/10], Step[4901/60000], Loss: 0.0365\n",
      "Epoch [7/10], Step[5001/60000], Loss: 0.0304\n",
      "Epoch [7/10], Step[5101/60000], Loss: 0.1666\n",
      "Epoch [7/10], Step[5201/60000], Loss: 0.0121\n",
      "Epoch [7/10], Step[5301/60000], Loss: 0.0223\n",
      "Epoch [7/10], Step[5401/60000], Loss: 0.0163\n",
      "Epoch [7/10], Step[5501/60000], Loss: 0.0141\n",
      "Epoch [7/10], Step[5601/60000], Loss: 0.0154\n",
      "Epoch [7/10], Step[5701/60000], Loss: 0.0848\n",
      "Epoch [7/10], Step[5801/60000], Loss: 0.0792\n",
      "Epoch [7/10], Step[5901/60000], Loss: 0.0140\n",
      "Epoch [7/10], Step[6001/60000], Loss: 0.0090\n",
      "Epoch [7/10], Step[6101/60000], Loss: 0.0361\n",
      "Epoch [7/10], Step[6201/60000], Loss: 0.0748\n",
      "Epoch [7/10], Step[6301/60000], Loss: 0.0293\n",
      "Epoch [7/10], Step[6401/60000], Loss: 0.0247\n",
      "Epoch [7/10], Step[6501/60000], Loss: 0.0040\n",
      "Epoch [7/10], Step[6601/60000], Loss: 0.0310\n",
      "Epoch [7/10], Step[6701/60000], Loss: 0.0166\n",
      "Epoch [7/10], Step[6801/60000], Loss: 0.1574\n",
      "Epoch [7/10], Step[6901/60000], Loss: 0.0339\n",
      "Epoch [7/10], Step[7001/60000], Loss: 0.0457\n",
      "Epoch [7/10], Step[7101/60000], Loss: 0.0206\n",
      "Epoch [7/10], Step[7201/60000], Loss: 0.0757\n",
      "Epoch [7/10], Step[7301/60000], Loss: 0.0490\n",
      "Epoch [7/10], Step[7401/60000], Loss: 0.0245\n",
      "Epoch [7/10], Step[7501/60000], Loss: 0.0224\n",
      "Epoch [7/10], Step[7601/60000], Loss: 0.0345\n",
      "Epoch [7/10], Step[7701/60000], Loss: 0.0410\n",
      "Epoch [7/10], Step[7801/60000], Loss: 0.0414\n",
      "Epoch [7/10], Step[7901/60000], Loss: 0.0273\n",
      "Epoch [7/10], Step[8001/60000], Loss: 0.0151\n",
      "Epoch [7/10], Step[8101/60000], Loss: 0.0142\n",
      "Epoch [7/10], Step[8201/60000], Loss: 0.0992\n",
      "Epoch [7/10], Step[8301/60000], Loss: 0.0322\n",
      "Epoch [7/10], Step[8401/60000], Loss: 0.0429\n",
      "Epoch [7/10], Step[8501/60000], Loss: 0.0082\n",
      "Epoch [7/10], Step[8601/60000], Loss: 0.0143\n",
      "Epoch [7/10], Step[8701/60000], Loss: 0.0245\n",
      "Epoch [7/10], Step[8801/60000], Loss: 0.0531\n",
      "Epoch [7/10], Step[8901/60000], Loss: 0.0173\n",
      "Epoch [7/10], Step[9001/60000], Loss: 0.0647\n",
      "Epoch [7/10], Step[9101/60000], Loss: 0.0158\n",
      "Epoch [7/10], Step[9201/60000], Loss: 0.0547\n",
      "Epoch [7/10], Step[9301/60000], Loss: 0.0103\n",
      "Epoch [7/10], Step[9401/60000], Loss: 0.0142\n",
      "Epoch [7/10], Step[9501/60000], Loss: 0.0157\n",
      "Epoch [7/10], Step[9601/60000], Loss: 0.0072\n",
      "Epoch [7/10], Step[9701/60000], Loss: 0.0405\n",
      "Epoch [7/10], Step[9801/60000], Loss: 0.0060\n",
      "Epoch [7/10], Step[9901/60000], Loss: 0.0059\n",
      "Epoch [7/10], Step[10001/60000], Loss: 0.0224\n",
      "Epoch [7/10], Step[10101/60000], Loss: 0.0133\n",
      "Epoch [7/10], Step[10201/60000], Loss: 0.0476\n",
      "Epoch [7/10], Step[10301/60000], Loss: 0.0208\n",
      "Epoch [7/10], Step[10401/60000], Loss: 0.0034\n",
      "Epoch [7/10], Step[10501/60000], Loss: 0.0033\n",
      "Epoch [7/10], Step[10601/60000], Loss: 0.0032\n",
      "Epoch [7/10], Step[10701/60000], Loss: 0.0152\n",
      "Epoch [7/10], Step[10801/60000], Loss: 0.0842\n",
      "Epoch [7/10], Step[10901/60000], Loss: 0.0705\n",
      "Epoch [7/10], Step[11001/60000], Loss: 0.0057\n",
      "Epoch [7/10], Step[11101/60000], Loss: 0.0052\n",
      "Epoch [7/10], Step[11201/60000], Loss: 0.0208\n",
      "Epoch [7/10], Step[11301/60000], Loss: 0.0091\n",
      "Epoch [7/10], Step[11401/60000], Loss: 0.0058\n",
      "Epoch [7/10], Step[11501/60000], Loss: 0.0220\n",
      "Epoch [7/10], Step[11601/60000], Loss: 0.2308\n",
      "Epoch [7/10], Step[11701/60000], Loss: 0.0294\n",
      "Epoch [7/10], Step[11801/60000], Loss: 0.0153\n",
      "Epoch [7/10], Step[11901/60000], Loss: 0.0407\n",
      "Epoch [7/10], Step[12001/60000], Loss: 0.0151\n",
      "Epoch [7/10], Step[12101/60000], Loss: 0.0027\n",
      "Epoch [7/10], Step[12201/60000], Loss: 0.0072\n",
      "Epoch [7/10], Step[12301/60000], Loss: 0.0072\n",
      "Epoch [7/10], Step[12401/60000], Loss: 0.1370\n",
      "Epoch [7/10], Step[12501/60000], Loss: 0.0616\n",
      "Epoch [7/10], Step[12601/60000], Loss: 0.0364\n",
      "Epoch [7/10], Step[12701/60000], Loss: 0.0156\n",
      "Epoch [7/10], Step[12801/60000], Loss: 0.0321\n",
      "Epoch [7/10], Step[12901/60000], Loss: 0.0181\n",
      "Epoch [7/10], Step[13001/60000], Loss: 0.0423\n",
      "Epoch [7/10], Step[13101/60000], Loss: 0.0094\n",
      "Epoch [7/10], Step[13201/60000], Loss: 0.0041\n",
      "Epoch [7/10], Step[13301/60000], Loss: 0.0302\n",
      "Epoch [7/10], Step[13401/60000], Loss: 0.0142\n",
      "Epoch [7/10], Step[13501/60000], Loss: 0.0137\n",
      "Epoch [7/10], Step[13601/60000], Loss: 0.0194\n",
      "Epoch [7/10], Step[13701/60000], Loss: 0.0124\n",
      "Epoch [7/10], Step[13801/60000], Loss: 0.0248\n",
      "Epoch [7/10], Step[13901/60000], Loss: 0.0229\n",
      "Epoch [7/10], Step[14001/60000], Loss: 0.0210\n",
      "Epoch [7/10], Step[14101/60000], Loss: 0.0220\n",
      "Epoch [7/10], Step[14201/60000], Loss: 0.0140\n",
      "Epoch [7/10], Step[14301/60000], Loss: 0.0303\n",
      "Epoch [7/10], Step[14401/60000], Loss: 0.0142\n",
      "Epoch [7/10], Step[14501/60000], Loss: 0.0182\n",
      "Epoch [7/10], Step[14601/60000], Loss: 0.2200\n",
      "Epoch [7/10], Step[14701/60000], Loss: 0.0358\n",
      "Epoch [7/10], Step[14801/60000], Loss: 0.0090\n",
      "Epoch [7/10], Step[14901/60000], Loss: 0.0099\n",
      "Epoch [7/10], Step[15001/60000], Loss: 0.0166\n",
      "Epoch [7/10], Step[15101/60000], Loss: 0.0763\n",
      "Epoch [7/10], Step[15201/60000], Loss: 0.2474\n",
      "Epoch [7/10], Step[15301/60000], Loss: 0.0095\n",
      "Epoch [7/10], Step[15401/60000], Loss: 0.0171\n",
      "Epoch [7/10], Step[15501/60000], Loss: 0.0209\n",
      "Epoch [7/10], Step[15601/60000], Loss: 0.0083\n",
      "Epoch [7/10], Step[15701/60000], Loss: 0.0476\n",
      "Epoch [7/10], Step[15801/60000], Loss: 0.0348\n",
      "Epoch [7/10], Step[15901/60000], Loss: 0.0126\n",
      "Epoch [7/10], Step[16001/60000], Loss: 0.0308\n",
      "Epoch [7/10], Step[16101/60000], Loss: 0.0360\n",
      "Epoch [7/10], Step[16201/60000], Loss: 0.0067\n",
      "Epoch [7/10], Step[16301/60000], Loss: 0.0103\n",
      "Epoch [7/10], Step[16401/60000], Loss: 0.0357\n",
      "Epoch [7/10], Step[16501/60000], Loss: 0.0297\n",
      "Epoch [7/10], Step[16601/60000], Loss: 0.0266\n",
      "Epoch [7/10], Step[16701/60000], Loss: 0.0390\n",
      "Epoch [7/10], Step[16801/60000], Loss: 0.0106\n",
      "Epoch [7/10], Step[16901/60000], Loss: 0.0270\n",
      "Epoch [7/10], Step[17001/60000], Loss: 0.0255\n",
      "Epoch [7/10], Step[17101/60000], Loss: 0.0388\n",
      "Epoch [7/10], Step[17201/60000], Loss: 0.0281\n",
      "Epoch [7/10], Step[17301/60000], Loss: 0.6484\n",
      "Epoch [7/10], Step[17401/60000], Loss: 0.0256\n",
      "Epoch [7/10], Step[17501/60000], Loss: 0.0191\n",
      "Epoch [7/10], Step[17601/60000], Loss: 0.0072\n",
      "Epoch [7/10], Step[17701/60000], Loss: 0.0586\n",
      "Epoch [7/10], Step[17801/60000], Loss: 0.0195\n",
      "Epoch [7/10], Step[17901/60000], Loss: 0.0092\n",
      "Epoch [7/10], Step[18001/60000], Loss: 0.0346\n",
      "Epoch [7/10], Step[18101/60000], Loss: 0.0234\n",
      "Epoch [7/10], Step[18201/60000], Loss: 0.0242\n",
      "Epoch [7/10], Step[18301/60000], Loss: 0.0191\n",
      "Epoch [7/10], Step[18401/60000], Loss: 0.0081\n",
      "Epoch [7/10], Step[18501/60000], Loss: 0.0127\n",
      "Epoch [7/10], Step[18601/60000], Loss: 0.0058\n",
      "Epoch [7/10], Step[18701/60000], Loss: 0.0401\n",
      "Epoch [7/10], Step[18801/60000], Loss: 0.0115\n",
      "Epoch [7/10], Step[18901/60000], Loss: 0.0093\n",
      "Epoch [7/10], Step[19001/60000], Loss: 0.0527\n",
      "Epoch [7/10], Step[19101/60000], Loss: 0.0479\n",
      "Epoch [7/10], Step[19201/60000], Loss: 0.0316\n",
      "Epoch [7/10], Step[19301/60000], Loss: 0.0342\n",
      "Epoch [7/10], Step[19401/60000], Loss: 0.0301\n",
      "Epoch [7/10], Step[19501/60000], Loss: 0.0248\n",
      "Epoch [7/10], Step[19601/60000], Loss: 0.0041\n",
      "Epoch [7/10], Step[19701/60000], Loss: 0.0062\n",
      "Epoch [7/10], Step[19801/60000], Loss: 0.0250\n",
      "Epoch [7/10], Step[19901/60000], Loss: 0.0151\n",
      "Epoch [7/10], Step[20001/60000], Loss: 0.0577\n",
      "Epoch [7/10], Step[20101/60000], Loss: 0.0323\n",
      "Epoch [7/10], Step[20201/60000], Loss: 0.0214\n",
      "Epoch [7/10], Step[20301/60000], Loss: 0.0348\n",
      "Epoch [7/10], Step[20401/60000], Loss: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step[20501/60000], Loss: 0.0053\n",
      "Epoch [7/10], Step[20601/60000], Loss: 0.0208\n",
      "Epoch [7/10], Step[20701/60000], Loss: 0.0792\n",
      "Epoch [7/10], Step[20801/60000], Loss: 0.0169\n",
      "Epoch [7/10], Step[20901/60000], Loss: 0.0214\n",
      "Epoch [7/10], Step[21001/60000], Loss: 0.0476\n",
      "Epoch [7/10], Step[21101/60000], Loss: 0.0315\n",
      "Epoch [7/10], Step[21201/60000], Loss: 0.0050\n",
      "Epoch [7/10], Step[21301/60000], Loss: 0.0283\n",
      "Epoch [7/10], Step[21401/60000], Loss: 0.0230\n",
      "Epoch [7/10], Step[21501/60000], Loss: 0.0212\n",
      "Epoch [7/10], Step[21601/60000], Loss: 0.0563\n",
      "Epoch [7/10], Step[21701/60000], Loss: 0.0048\n",
      "Epoch [7/10], Step[21801/60000], Loss: 0.0759\n",
      "Epoch [7/10], Step[21901/60000], Loss: 0.0500\n",
      "Epoch [7/10], Step[22001/60000], Loss: 0.0098\n",
      "Epoch [7/10], Step[22101/60000], Loss: 0.0236\n",
      "Epoch [7/10], Step[22201/60000], Loss: 0.0140\n",
      "Epoch [7/10], Step[22301/60000], Loss: 0.0060\n",
      "Epoch [7/10], Step[22401/60000], Loss: 0.0419\n",
      "Epoch [7/10], Step[22501/60000], Loss: 0.0355\n",
      "Epoch [7/10], Step[22601/60000], Loss: 0.0128\n",
      "Epoch [7/10], Step[22701/60000], Loss: 0.1720\n",
      "Epoch [7/10], Step[22801/60000], Loss: 0.0109\n",
      "Epoch [7/10], Step[22901/60000], Loss: 0.0041\n",
      "Epoch [7/10], Step[23001/60000], Loss: 0.0107\n",
      "Epoch [7/10], Step[23101/60000], Loss: 0.0842\n",
      "Epoch [7/10], Step[23201/60000], Loss: 0.3194\n",
      "Epoch [7/10], Step[23301/60000], Loss: 0.0120\n",
      "Epoch [7/10], Step[23401/60000], Loss: 0.0121\n",
      "Epoch [7/10], Step[23501/60000], Loss: 0.0439\n",
      "Epoch [7/10], Step[23601/60000], Loss: 0.0211\n",
      "Epoch [7/10], Step[23701/60000], Loss: 0.0121\n",
      "Epoch [7/10], Step[23801/60000], Loss: 0.0228\n",
      "Epoch [7/10], Step[23901/60000], Loss: 0.0381\n",
      "Epoch [7/10], Step[24001/60000], Loss: 0.0177\n",
      "Epoch [7/10], Step[24101/60000], Loss: 0.0125\n",
      "Epoch [7/10], Step[24201/60000], Loss: 0.0176\n",
      "Epoch [7/10], Step[24301/60000], Loss: 0.0120\n",
      "Epoch [7/10], Step[24401/60000], Loss: 0.0064\n",
      "Epoch [7/10], Step[24501/60000], Loss: 0.0491\n",
      "Epoch [7/10], Step[24601/60000], Loss: 0.0113\n",
      "Epoch [7/10], Step[24701/60000], Loss: 0.0092\n",
      "Epoch [7/10], Step[24801/60000], Loss: 0.0191\n",
      "Epoch [7/10], Step[24901/60000], Loss: 0.0131\n",
      "Epoch [7/10], Step[25001/60000], Loss: 0.0199\n",
      "Epoch [7/10], Step[25101/60000], Loss: 0.0228\n",
      "Epoch [7/10], Step[25201/60000], Loss: 0.0165\n",
      "Epoch [7/10], Step[25301/60000], Loss: 0.0103\n",
      "Epoch [7/10], Step[25401/60000], Loss: 0.0183\n",
      "Epoch [7/10], Step[25501/60000], Loss: 0.0742\n",
      "Epoch [7/10], Step[25601/60000], Loss: 0.0243\n",
      "Epoch [7/10], Step[25701/60000], Loss: 0.0339\n",
      "Epoch [7/10], Step[25801/60000], Loss: 0.0241\n",
      "Epoch [7/10], Step[25901/60000], Loss: 0.0085\n",
      "Epoch [7/10], Step[26001/60000], Loss: 0.0230\n",
      "Epoch [7/10], Step[26101/60000], Loss: 0.0054\n",
      "Epoch [7/10], Step[26201/60000], Loss: 0.0255\n",
      "Epoch [7/10], Step[26301/60000], Loss: 0.0234\n",
      "Epoch [7/10], Step[26401/60000], Loss: 0.0354\n",
      "Epoch [7/10], Step[26501/60000], Loss: 0.0980\n",
      "Epoch [7/10], Step[26601/60000], Loss: 0.0528\n",
      "Epoch [7/10], Step[26701/60000], Loss: 0.0588\n",
      "Epoch [7/10], Step[26801/60000], Loss: 0.0997\n",
      "Epoch [7/10], Step[26901/60000], Loss: 0.0348\n",
      "Epoch [7/10], Step[27001/60000], Loss: 0.0119\n",
      "Epoch [7/10], Step[27101/60000], Loss: 0.0409\n",
      "Epoch [7/10], Step[27201/60000], Loss: 0.0720\n",
      "Epoch [7/10], Step[27301/60000], Loss: 0.0102\n",
      "Epoch [7/10], Step[27401/60000], Loss: 0.0192\n",
      "Epoch [7/10], Step[27501/60000], Loss: 0.0196\n",
      "Epoch [7/10], Step[27601/60000], Loss: 0.0163\n",
      "Epoch [7/10], Step[27701/60000], Loss: 0.0150\n",
      "Epoch [7/10], Step[27801/60000], Loss: 0.0687\n",
      "Epoch [7/10], Step[27901/60000], Loss: 0.0087\n",
      "Epoch [7/10], Step[28001/60000], Loss: 0.0062\n",
      "Epoch [7/10], Step[28101/60000], Loss: 0.0191\n",
      "Epoch [7/10], Step[28201/60000], Loss: 0.0107\n",
      "Epoch [7/10], Step[28301/60000], Loss: 0.0544\n",
      "Epoch [7/10], Step[28401/60000], Loss: 0.0138\n",
      "Epoch [7/10], Step[28501/60000], Loss: 0.0107\n",
      "Epoch [7/10], Step[28601/60000], Loss: 0.0196\n",
      "Epoch [7/10], Step[28701/60000], Loss: 0.0297\n",
      "Epoch [7/10], Step[28801/60000], Loss: 0.0060\n",
      "Epoch [7/10], Step[28901/60000], Loss: 0.0300\n",
      "Epoch [7/10], Step[29001/60000], Loss: 0.0202\n",
      "Epoch [7/10], Step[29101/60000], Loss: 0.0181\n",
      "Epoch [7/10], Step[29201/60000], Loss: 0.0300\n",
      "Epoch [7/10], Step[29301/60000], Loss: 0.0141\n",
      "Epoch [7/10], Step[29401/60000], Loss: 0.0206\n",
      "Epoch [7/10], Step[29501/60000], Loss: 0.0044\n",
      "Epoch [7/10], Step[29601/60000], Loss: 0.0110\n",
      "Epoch [7/10], Step[29701/60000], Loss: 0.0317\n",
      "Epoch [7/10], Step[29801/60000], Loss: 0.0229\n",
      "Epoch [7/10], Step[29901/60000], Loss: 0.0347\n",
      "Epoch [7/10], Step[30001/60000], Loss: 0.0126\n",
      "Epoch [7/10], Step[30101/60000], Loss: 0.0247\n",
      "Epoch [7/10], Step[30201/60000], Loss: 0.0035\n",
      "Epoch [7/10], Step[30301/60000], Loss: 0.0159\n",
      "Epoch [7/10], Step[30401/60000], Loss: 0.0175\n",
      "Epoch [7/10], Step[30501/60000], Loss: 0.0143\n",
      "Epoch [7/10], Step[30601/60000], Loss: 0.0153\n",
      "Epoch [7/10], Step[30701/60000], Loss: 0.0213\n",
      "Epoch [7/10], Step[30801/60000], Loss: 0.0082\n",
      "Epoch [7/10], Step[30901/60000], Loss: 0.0215\n",
      "Epoch [7/10], Step[31001/60000], Loss: 0.0210\n",
      "Epoch [7/10], Step[31101/60000], Loss: 0.1197\n",
      "Epoch [7/10], Step[31201/60000], Loss: 0.0094\n",
      "Epoch [7/10], Step[31301/60000], Loss: 0.0209\n",
      "Epoch [7/10], Step[31401/60000], Loss: 0.0167\n",
      "Epoch [7/10], Step[31501/60000], Loss: 0.0444\n",
      "Epoch [7/10], Step[31601/60000], Loss: 0.0488\n",
      "Epoch [7/10], Step[31701/60000], Loss: 0.0416\n",
      "Epoch [7/10], Step[31801/60000], Loss: 0.0109\n",
      "Epoch [7/10], Step[31901/60000], Loss: 0.0270\n",
      "Epoch [7/10], Step[32001/60000], Loss: 0.0127\n",
      "Epoch [7/10], Step[32101/60000], Loss: 0.0097\n",
      "Epoch [7/10], Step[32201/60000], Loss: 0.0332\n",
      "Epoch [7/10], Step[32301/60000], Loss: 0.0244\n",
      "Epoch [7/10], Step[32401/60000], Loss: 0.0549\n",
      "Epoch [7/10], Step[32501/60000], Loss: 0.0290\n",
      "Epoch [7/10], Step[32601/60000], Loss: 0.0108\n",
      "Epoch [7/10], Step[32701/60000], Loss: 0.0519\n",
      "Epoch [7/10], Step[32801/60000], Loss: 0.0109\n",
      "Epoch [7/10], Step[32901/60000], Loss: 0.0140\n",
      "Epoch [7/10], Step[33001/60000], Loss: 0.0051\n",
      "Epoch [7/10], Step[33101/60000], Loss: 0.0127\n",
      "Epoch [7/10], Step[33201/60000], Loss: 0.0112\n",
      "Epoch [7/10], Step[33301/60000], Loss: 0.0121\n",
      "Epoch [7/10], Step[33401/60000], Loss: 0.0203\n",
      "Epoch [7/10], Step[33501/60000], Loss: 0.0269\n",
      "Epoch [7/10], Step[33601/60000], Loss: 0.0201\n",
      "Epoch [7/10], Step[33701/60000], Loss: 0.0574\n",
      "Epoch [7/10], Step[33801/60000], Loss: 0.0018\n",
      "Epoch [7/10], Step[33901/60000], Loss: 0.0110\n",
      "Epoch [7/10], Step[34001/60000], Loss: 0.0509\n",
      "Epoch [7/10], Step[34101/60000], Loss: 0.0081\n",
      "Epoch [7/10], Step[34201/60000], Loss: 0.0043\n",
      "Epoch [7/10], Step[34301/60000], Loss: 0.0149\n",
      "Epoch [7/10], Step[34401/60000], Loss: 0.0773\n",
      "Epoch [7/10], Step[34501/60000], Loss: 0.0332\n",
      "Epoch [7/10], Step[34601/60000], Loss: 0.0303\n",
      "Epoch [7/10], Step[34701/60000], Loss: 0.0310\n",
      "Epoch [7/10], Step[34801/60000], Loss: 0.0336\n",
      "Epoch [7/10], Step[34901/60000], Loss: 0.0130\n",
      "Epoch [7/10], Step[35001/60000], Loss: 0.0251\n",
      "Epoch [7/10], Step[35101/60000], Loss: 0.0139\n",
      "Epoch [7/10], Step[35201/60000], Loss: 0.0561\n",
      "Epoch [7/10], Step[35301/60000], Loss: 0.0418\n",
      "Epoch [7/10], Step[35401/60000], Loss: 0.0985\n",
      "Epoch [7/10], Step[35501/60000], Loss: 0.0078\n",
      "Epoch [7/10], Step[35601/60000], Loss: 0.0915\n",
      "Epoch [7/10], Step[35701/60000], Loss: 0.0053\n",
      "Epoch [7/10], Step[35801/60000], Loss: 0.0095\n",
      "Epoch [7/10], Step[35901/60000], Loss: 0.0266\n",
      "Epoch [7/10], Step[36001/60000], Loss: 0.0398\n",
      "Epoch [7/10], Step[36101/60000], Loss: 0.1175\n",
      "Epoch [7/10], Step[36201/60000], Loss: 0.0063\n",
      "Epoch [7/10], Step[36301/60000], Loss: 0.0182\n",
      "Epoch [7/10], Step[36401/60000], Loss: 0.0640\n",
      "Epoch [7/10], Step[36501/60000], Loss: 0.0066\n",
      "Epoch [7/10], Step[36601/60000], Loss: 0.0057\n",
      "Epoch [7/10], Step[36701/60000], Loss: 0.0214\n",
      "Epoch [7/10], Step[36801/60000], Loss: 0.0212\n",
      "Epoch [7/10], Step[36901/60000], Loss: 0.0273\n",
      "Epoch [7/10], Step[37001/60000], Loss: 0.0506\n",
      "Epoch [7/10], Step[37101/60000], Loss: 0.0154\n",
      "Epoch [7/10], Step[37201/60000], Loss: 0.0487\n",
      "Epoch [7/10], Step[37301/60000], Loss: 0.0300\n",
      "Epoch [7/10], Step[37401/60000], Loss: 0.0535\n",
      "Epoch [7/10], Step[37501/60000], Loss: 0.0259\n",
      "Epoch [7/10], Step[37601/60000], Loss: 0.0401\n",
      "Epoch [7/10], Step[37701/60000], Loss: 0.1346\n",
      "Epoch [7/10], Step[37801/60000], Loss: 0.1390\n",
      "Epoch [7/10], Step[37901/60000], Loss: 0.0063\n",
      "Epoch [7/10], Step[38001/60000], Loss: 0.0143\n",
      "Epoch [7/10], Step[38101/60000], Loss: 0.0063\n",
      "Epoch [7/10], Step[38201/60000], Loss: 0.0036\n",
      "Epoch [7/10], Step[38301/60000], Loss: 0.0439\n",
      "Epoch [7/10], Step[38401/60000], Loss: 0.0056\n",
      "Epoch [7/10], Step[38501/60000], Loss: 0.0298\n",
      "Epoch [7/10], Step[38601/60000], Loss: 0.0408\n",
      "Epoch [7/10], Step[38701/60000], Loss: 0.0366\n",
      "Epoch [7/10], Step[38801/60000], Loss: 0.0039\n",
      "Epoch [7/10], Step[38901/60000], Loss: 0.0193\n",
      "Epoch [7/10], Step[39001/60000], Loss: 0.0083\n",
      "Epoch [7/10], Step[39101/60000], Loss: 0.0097\n",
      "Epoch [7/10], Step[39201/60000], Loss: 0.0143\n",
      "Epoch [7/10], Step[39301/60000], Loss: 0.0592\n",
      "Epoch [7/10], Step[39401/60000], Loss: 0.0329\n",
      "Epoch [7/10], Step[39501/60000], Loss: 0.0158\n",
      "Epoch [7/10], Step[39601/60000], Loss: 0.0607\n",
      "Epoch [7/10], Step[39701/60000], Loss: 0.0085\n",
      "Epoch [7/10], Step[39801/60000], Loss: 0.0429\n",
      "Epoch [7/10], Step[39901/60000], Loss: 0.0063\n",
      "Epoch [7/10], Step[40001/60000], Loss: 0.0180\n",
      "Epoch [7/10], Step[40101/60000], Loss: 0.0160\n",
      "Epoch [7/10], Step[40201/60000], Loss: 0.0176\n",
      "Epoch [7/10], Step[40301/60000], Loss: 0.0093\n",
      "Epoch [7/10], Step[40401/60000], Loss: 0.0032\n",
      "Epoch [7/10], Step[40501/60000], Loss: 0.0036\n",
      "Epoch [7/10], Step[40601/60000], Loss: 0.0354\n",
      "Epoch [7/10], Step[40701/60000], Loss: 0.0298\n",
      "Epoch [7/10], Step[40801/60000], Loss: 0.0207\n",
      "Epoch [7/10], Step[40901/60000], Loss: 0.0179\n",
      "Epoch [7/10], Step[41001/60000], Loss: 0.0448\n",
      "Epoch [7/10], Step[41101/60000], Loss: 0.0265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step[41201/60000], Loss: 0.0375\n",
      "Epoch [7/10], Step[41301/60000], Loss: 0.0476\n",
      "Epoch [7/10], Step[41401/60000], Loss: 0.0536\n",
      "Epoch [7/10], Step[41501/60000], Loss: 0.1012\n",
      "Epoch [7/10], Step[41601/60000], Loss: 0.0126\n",
      "Epoch [7/10], Step[41701/60000], Loss: 0.0104\n",
      "Epoch [7/10], Step[41801/60000], Loss: 0.0278\n",
      "Epoch [7/10], Step[41901/60000], Loss: 0.0465\n",
      "Epoch [7/10], Step[42001/60000], Loss: 0.0140\n",
      "Epoch [7/10], Step[42101/60000], Loss: 0.0413\n",
      "Epoch [7/10], Step[42201/60000], Loss: 0.0114\n",
      "Epoch [7/10], Step[42301/60000], Loss: 0.0200\n",
      "Epoch [7/10], Step[42401/60000], Loss: 0.0148\n",
      "Epoch [7/10], Step[42501/60000], Loss: 0.0741\n",
      "Epoch [7/10], Step[42601/60000], Loss: 0.0357\n",
      "Epoch [7/10], Step[42701/60000], Loss: 0.0759\n",
      "Epoch [7/10], Step[42801/60000], Loss: 0.0223\n",
      "Epoch [7/10], Step[42901/60000], Loss: 0.0240\n",
      "Epoch [7/10], Step[43001/60000], Loss: 0.0578\n",
      "Epoch [7/10], Step[43101/60000], Loss: 0.0537\n",
      "Epoch [7/10], Step[43201/60000], Loss: 0.0145\n",
      "Epoch [7/10], Step[43301/60000], Loss: 0.0029\n",
      "Epoch [7/10], Step[43401/60000], Loss: 0.0525\n",
      "Epoch [7/10], Step[43501/60000], Loss: 0.0114\n",
      "Epoch [7/10], Step[43601/60000], Loss: 0.1965\n",
      "Epoch [7/10], Step[43701/60000], Loss: 0.5521\n",
      "Epoch [7/10], Step[43801/60000], Loss: 0.0191\n",
      "Epoch [7/10], Step[43901/60000], Loss: 0.0345\n",
      "Epoch [7/10], Step[44001/60000], Loss: 0.0763\n",
      "Epoch [7/10], Step[44101/60000], Loss: 0.0375\n",
      "Epoch [7/10], Step[44201/60000], Loss: 0.0359\n",
      "Epoch [7/10], Step[44301/60000], Loss: 0.0186\n",
      "Epoch [7/10], Step[44401/60000], Loss: 0.0551\n",
      "Epoch [7/10], Step[44501/60000], Loss: 0.0091\n",
      "Epoch [7/10], Step[44601/60000], Loss: 0.0132\n",
      "Epoch [7/10], Step[44701/60000], Loss: 0.0110\n",
      "Epoch [7/10], Step[44801/60000], Loss: 0.0294\n",
      "Epoch [7/10], Step[44901/60000], Loss: 0.0082\n",
      "Epoch [7/10], Step[45001/60000], Loss: 0.0453\n",
      "Epoch [7/10], Step[45101/60000], Loss: 0.0847\n",
      "Epoch [7/10], Step[45201/60000], Loss: 0.0184\n",
      "Epoch [7/10], Step[45301/60000], Loss: 0.0321\n",
      "Epoch [7/10], Step[45401/60000], Loss: 0.0137\n",
      "Epoch [7/10], Step[45501/60000], Loss: 0.0322\n",
      "Epoch [7/10], Step[45601/60000], Loss: 0.0242\n",
      "Epoch [7/10], Step[45701/60000], Loss: 0.0098\n",
      "Epoch [7/10], Step[45801/60000], Loss: 0.0220\n",
      "Epoch [7/10], Step[45901/60000], Loss: 0.0308\n",
      "Epoch [7/10], Step[46001/60000], Loss: 0.4364\n",
      "Epoch [7/10], Step[46101/60000], Loss: 0.0138\n",
      "Epoch [7/10], Step[46201/60000], Loss: 0.0806\n",
      "Epoch [7/10], Step[46301/60000], Loss: 0.0149\n",
      "Epoch [7/10], Step[46401/60000], Loss: 0.0156\n",
      "Epoch [7/10], Step[46501/60000], Loss: 0.0082\n",
      "Epoch [7/10], Step[46601/60000], Loss: 0.0069\n",
      "Epoch [7/10], Step[46701/60000], Loss: 0.0279\n",
      "Epoch [7/10], Step[46801/60000], Loss: 0.0468\n",
      "Epoch [7/10], Step[46901/60000], Loss: 0.0289\n",
      "Epoch [7/10], Step[47001/60000], Loss: 0.0439\n",
      "Epoch [7/10], Step[47101/60000], Loss: 0.0096\n",
      "Epoch [7/10], Step[47201/60000], Loss: 0.0808\n",
      "Epoch [7/10], Step[47301/60000], Loss: 0.0570\n",
      "Epoch [7/10], Step[47401/60000], Loss: 0.2352\n",
      "Epoch [7/10], Step[47501/60000], Loss: 0.0396\n",
      "Epoch [7/10], Step[47601/60000], Loss: 0.0845\n",
      "Epoch [7/10], Step[47701/60000], Loss: 0.0065\n",
      "Epoch [7/10], Step[47801/60000], Loss: 0.0101\n",
      "Epoch [7/10], Step[47901/60000], Loss: 0.0226\n",
      "Epoch [7/10], Step[48001/60000], Loss: 0.0126\n",
      "Epoch [7/10], Step[48101/60000], Loss: 0.0087\n",
      "Epoch [7/10], Step[48201/60000], Loss: 0.0056\n",
      "Epoch [7/10], Step[48301/60000], Loss: 0.0244\n",
      "Epoch [7/10], Step[48401/60000], Loss: 0.0042\n",
      "Epoch [7/10], Step[48501/60000], Loss: 0.0199\n",
      "Epoch [7/10], Step[48601/60000], Loss: 0.0121\n",
      "Epoch [7/10], Step[48701/60000], Loss: 0.0072\n",
      "Epoch [7/10], Step[48801/60000], Loss: 0.0184\n",
      "Epoch [7/10], Step[48901/60000], Loss: 0.0610\n",
      "Epoch [7/10], Step[49001/60000], Loss: 0.3327\n",
      "Epoch [7/10], Step[49101/60000], Loss: 0.0096\n",
      "Epoch [7/10], Step[49201/60000], Loss: 0.0253\n",
      "Epoch [7/10], Step[49301/60000], Loss: 0.0104\n",
      "Epoch [7/10], Step[49401/60000], Loss: 0.0358\n",
      "Epoch [7/10], Step[49501/60000], Loss: 0.0548\n",
      "Epoch [7/10], Step[49601/60000], Loss: 0.0278\n",
      "Epoch [7/10], Step[49701/60000], Loss: 0.0129\n",
      "Epoch [7/10], Step[49801/60000], Loss: 0.0342\n",
      "Epoch [7/10], Step[49901/60000], Loss: 0.0138\n",
      "Epoch [7/10], Step[50001/60000], Loss: 0.0178\n",
      "Epoch [7/10], Step[50101/60000], Loss: 0.0071\n",
      "Epoch [7/10], Step[50201/60000], Loss: 0.0424\n",
      "Epoch [7/10], Step[50301/60000], Loss: 0.0240\n",
      "Epoch [7/10], Step[50401/60000], Loss: 0.0414\n",
      "Epoch [7/10], Step[50501/60000], Loss: 0.0183\n",
      "Epoch [7/10], Step[50601/60000], Loss: 0.0183\n",
      "Epoch [7/10], Step[50701/60000], Loss: 0.0215\n",
      "Epoch [7/10], Step[50801/60000], Loss: 0.0287\n",
      "Epoch [7/10], Step[50901/60000], Loss: 0.0198\n",
      "Epoch [7/10], Step[51001/60000], Loss: 0.0076\n",
      "Epoch [7/10], Step[51101/60000], Loss: 0.0182\n",
      "Epoch [7/10], Step[51201/60000], Loss: 0.0850\n",
      "Epoch [7/10], Step[51301/60000], Loss: 0.0156\n",
      "Epoch [7/10], Step[51401/60000], Loss: 0.2141\n",
      "Epoch [7/10], Step[51501/60000], Loss: 0.0048\n",
      "Epoch [7/10], Step[51601/60000], Loss: 0.0106\n",
      "Epoch [7/10], Step[51701/60000], Loss: 0.0100\n",
      "Epoch [7/10], Step[51801/60000], Loss: 0.0097\n",
      "Epoch [7/10], Step[51901/60000], Loss: 0.0607\n",
      "Epoch [7/10], Step[52001/60000], Loss: 0.0753\n",
      "Epoch [7/10], Step[52101/60000], Loss: 0.0675\n",
      "Epoch [7/10], Step[52201/60000], Loss: 0.0513\n",
      "Epoch [7/10], Step[52301/60000], Loss: 0.0331\n",
      "Epoch [7/10], Step[52401/60000], Loss: 0.0146\n",
      "Epoch [7/10], Step[52501/60000], Loss: 0.1415\n",
      "Epoch [7/10], Step[52601/60000], Loss: 0.0156\n",
      "Epoch [7/10], Step[52701/60000], Loss: 0.0075\n",
      "Epoch [7/10], Step[52801/60000], Loss: 0.0152\n",
      "Epoch [7/10], Step[52901/60000], Loss: 0.0173\n",
      "Epoch [7/10], Step[53001/60000], Loss: 0.0122\n",
      "Epoch [7/10], Step[53101/60000], Loss: 0.0103\n",
      "Epoch [7/10], Step[53201/60000], Loss: 0.0340\n",
      "Epoch [7/10], Step[53301/60000], Loss: 0.0239\n",
      "Epoch [7/10], Step[53401/60000], Loss: 0.0131\n",
      "Epoch [7/10], Step[53501/60000], Loss: 0.0174\n",
      "Epoch [7/10], Step[53601/60000], Loss: 0.0467\n",
      "Epoch [7/10], Step[53701/60000], Loss: 0.0397\n",
      "Epoch [7/10], Step[53801/60000], Loss: 0.0042\n",
      "Epoch [7/10], Step[53901/60000], Loss: 0.1383\n",
      "Epoch [7/10], Step[54001/60000], Loss: 0.0854\n",
      "Epoch [7/10], Step[54101/60000], Loss: 0.0097\n",
      "Epoch [7/10], Step[54201/60000], Loss: 0.0260\n",
      "Epoch [7/10], Step[54301/60000], Loss: 0.0056\n",
      "Epoch [7/10], Step[54401/60000], Loss: 0.0180\n",
      "Epoch [7/10], Step[54501/60000], Loss: 0.0320\n",
      "Epoch [7/10], Step[54601/60000], Loss: 0.0134\n",
      "Epoch [7/10], Step[54701/60000], Loss: 0.0140\n",
      "Epoch [7/10], Step[54801/60000], Loss: 0.2679\n",
      "Epoch [7/10], Step[54901/60000], Loss: 0.0173\n",
      "Epoch [7/10], Step[55001/60000], Loss: 0.0123\n",
      "Epoch [7/10], Step[55101/60000], Loss: 0.0130\n",
      "Epoch [7/10], Step[55201/60000], Loss: 0.0241\n",
      "Epoch [7/10], Step[55301/60000], Loss: 0.0680\n",
      "Epoch [7/10], Step[55401/60000], Loss: 0.0194\n",
      "Epoch [7/10], Step[55501/60000], Loss: 0.0129\n",
      "Epoch [7/10], Step[55601/60000], Loss: 0.0209\n",
      "Epoch [7/10], Step[55701/60000], Loss: 0.0640\n",
      "Epoch [7/10], Step[55801/60000], Loss: 0.0138\n",
      "Epoch [7/10], Step[55901/60000], Loss: 0.0139\n",
      "Epoch [7/10], Step[56001/60000], Loss: 0.0220\n",
      "Epoch [7/10], Step[56101/60000], Loss: 0.0070\n",
      "Epoch [7/10], Step[56201/60000], Loss: 0.0583\n",
      "Epoch [7/10], Step[56301/60000], Loss: 0.0232\n",
      "Epoch [7/10], Step[56401/60000], Loss: 0.0337\n",
      "Epoch [7/10], Step[56501/60000], Loss: 0.0220\n",
      "Epoch [7/10], Step[56601/60000], Loss: 0.0129\n",
      "Epoch [7/10], Step[56701/60000], Loss: 0.0230\n",
      "Epoch [7/10], Step[56801/60000], Loss: 0.0059\n",
      "Epoch [7/10], Step[56901/60000], Loss: 0.0066\n",
      "Epoch [7/10], Step[57001/60000], Loss: 0.0123\n",
      "Epoch [7/10], Step[57101/60000], Loss: 0.0071\n",
      "Epoch [7/10], Step[57201/60000], Loss: 0.0145\n",
      "Epoch [7/10], Step[57301/60000], Loss: 0.0222\n",
      "Epoch [7/10], Step[57401/60000], Loss: 0.0170\n",
      "Epoch [7/10], Step[57501/60000], Loss: 0.0124\n",
      "Epoch [7/10], Step[57601/60000], Loss: 0.1117\n",
      "Epoch [7/10], Step[57701/60000], Loss: 0.0147\n",
      "Epoch [7/10], Step[57801/60000], Loss: 0.0353\n",
      "Epoch [7/10], Step[57901/60000], Loss: 0.0092\n",
      "Epoch [7/10], Step[58001/60000], Loss: 0.0308\n",
      "Epoch [7/10], Step[58101/60000], Loss: 0.0137\n",
      "Epoch [7/10], Step[58201/60000], Loss: 0.0041\n",
      "Epoch [7/10], Step[58301/60000], Loss: 0.0098\n",
      "Epoch [7/10], Step[58401/60000], Loss: 0.0045\n",
      "Epoch [7/10], Step[58501/60000], Loss: 0.0096\n",
      "Epoch [7/10], Step[58601/60000], Loss: 0.0338\n",
      "Epoch [7/10], Step[58701/60000], Loss: 0.0032\n",
      "Epoch [7/10], Step[58801/60000], Loss: 0.0067\n",
      "Epoch [7/10], Step[58901/60000], Loss: 0.0014\n",
      "Epoch [7/10], Step[59001/60000], Loss: 0.0047\n",
      "Epoch [7/10], Step[59101/60000], Loss: 0.0010\n",
      "Epoch [7/10], Step[59201/60000], Loss: 0.0029\n",
      "Epoch [7/10], Step[59301/60000], Loss: 0.0139\n",
      "Epoch [7/10], Step[59401/60000], Loss: 0.0050\n",
      "Epoch [7/10], Step[59501/60000], Loss: 0.0011\n",
      "Epoch [7/10], Step[59601/60000], Loss: 0.0047\n",
      "Epoch [7/10], Step[59701/60000], Loss: 0.0534\n",
      "Epoch [7/10], Step[59801/60000], Loss: 0.0014\n",
      "Epoch [7/10], Step[59901/60000], Loss: 0.2519\n",
      "Epoch [8/10], Step[1/60000], Loss: 0.0148\n",
      "Epoch [8/10], Step[101/60000], Loss: 0.1012\n",
      "Epoch [8/10], Step[201/60000], Loss: 0.0161\n",
      "Epoch [8/10], Step[301/60000], Loss: 0.0051\n",
      "Epoch [8/10], Step[401/60000], Loss: 0.0348\n",
      "Epoch [8/10], Step[501/60000], Loss: 0.0404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step[601/60000], Loss: 0.0545\n",
      "Epoch [8/10], Step[701/60000], Loss: 0.0400\n",
      "Epoch [8/10], Step[801/60000], Loss: 0.1118\n",
      "Epoch [8/10], Step[901/60000], Loss: 0.0093\n",
      "Epoch [8/10], Step[1001/60000], Loss: 0.0511\n",
      "Epoch [8/10], Step[1101/60000], Loss: 0.0471\n",
      "Epoch [8/10], Step[1201/60000], Loss: 0.0598\n",
      "Epoch [8/10], Step[1301/60000], Loss: 0.0209\n",
      "Epoch [8/10], Step[1401/60000], Loss: 0.0180\n",
      "Epoch [8/10], Step[1501/60000], Loss: 0.0135\n",
      "Epoch [8/10], Step[1601/60000], Loss: 0.0062\n",
      "Epoch [8/10], Step[1701/60000], Loss: 0.0092\n",
      "Epoch [8/10], Step[1801/60000], Loss: 0.0059\n",
      "Epoch [8/10], Step[1901/60000], Loss: 0.0230\n",
      "Epoch [8/10], Step[2001/60000], Loss: 0.0133\n",
      "Epoch [8/10], Step[2101/60000], Loss: 0.0735\n",
      "Epoch [8/10], Step[2201/60000], Loss: 0.0079\n",
      "Epoch [8/10], Step[2301/60000], Loss: 0.0068\n",
      "Epoch [8/10], Step[2401/60000], Loss: 0.0091\n",
      "Epoch [8/10], Step[2501/60000], Loss: 0.0197\n",
      "Epoch [8/10], Step[2601/60000], Loss: 0.0445\n",
      "Epoch [8/10], Step[2701/60000], Loss: 0.0482\n",
      "Epoch [8/10], Step[2801/60000], Loss: 0.0064\n",
      "Epoch [8/10], Step[2901/60000], Loss: 0.0074\n",
      "Epoch [8/10], Step[3001/60000], Loss: 0.0097\n",
      "Epoch [8/10], Step[3101/60000], Loss: 0.0025\n",
      "Epoch [8/10], Step[3201/60000], Loss: 0.1416\n",
      "Epoch [8/10], Step[3301/60000], Loss: 0.0143\n",
      "Epoch [8/10], Step[3401/60000], Loss: 0.0756\n",
      "Epoch [8/10], Step[3501/60000], Loss: 0.0698\n",
      "Epoch [8/10], Step[3601/60000], Loss: 0.0408\n",
      "Epoch [8/10], Step[3701/60000], Loss: 0.0082\n",
      "Epoch [8/10], Step[3801/60000], Loss: 0.0252\n",
      "Epoch [8/10], Step[3901/60000], Loss: 0.0029\n",
      "Epoch [8/10], Step[4001/60000], Loss: 0.0161\n",
      "Epoch [8/10], Step[4101/60000], Loss: 0.0086\n",
      "Epoch [8/10], Step[4201/60000], Loss: 0.0126\n",
      "Epoch [8/10], Step[4301/60000], Loss: 0.0135\n",
      "Epoch [8/10], Step[4401/60000], Loss: 0.0581\n",
      "Epoch [8/10], Step[4501/60000], Loss: 0.0054\n",
      "Epoch [8/10], Step[4601/60000], Loss: 0.0523\n",
      "Epoch [8/10], Step[4701/60000], Loss: 0.0060\n",
      "Epoch [8/10], Step[4801/60000], Loss: 0.0057\n",
      "Epoch [8/10], Step[4901/60000], Loss: 0.0389\n",
      "Epoch [8/10], Step[5001/60000], Loss: 0.0183\n",
      "Epoch [8/10], Step[5101/60000], Loss: 0.0744\n",
      "Epoch [8/10], Step[5201/60000], Loss: 0.0120\n",
      "Epoch [8/10], Step[5301/60000], Loss: 0.0179\n",
      "Epoch [8/10], Step[5401/60000], Loss: 0.0092\n",
      "Epoch [8/10], Step[5501/60000], Loss: 0.0102\n",
      "Epoch [8/10], Step[5601/60000], Loss: 0.0180\n",
      "Epoch [8/10], Step[5701/60000], Loss: 0.0497\n",
      "Epoch [8/10], Step[5801/60000], Loss: 0.0415\n",
      "Epoch [8/10], Step[5901/60000], Loss: 0.0160\n",
      "Epoch [8/10], Step[6001/60000], Loss: 0.0064\n",
      "Epoch [8/10], Step[6101/60000], Loss: 0.0127\n",
      "Epoch [8/10], Step[6201/60000], Loss: 0.0499\n",
      "Epoch [8/10], Step[6301/60000], Loss: 0.0203\n",
      "Epoch [8/10], Step[6401/60000], Loss: 0.0252\n",
      "Epoch [8/10], Step[6501/60000], Loss: 0.0021\n",
      "Epoch [8/10], Step[6601/60000], Loss: 0.0181\n",
      "Epoch [8/10], Step[6701/60000], Loss: 0.0096\n",
      "Epoch [8/10], Step[6801/60000], Loss: 0.1186\n",
      "Epoch [8/10], Step[6901/60000], Loss: 0.0270\n",
      "Epoch [8/10], Step[7001/60000], Loss: 0.0405\n",
      "Epoch [8/10], Step[7101/60000], Loss: 0.0099\n",
      "Epoch [8/10], Step[7201/60000], Loss: 0.0603\n",
      "Epoch [8/10], Step[7301/60000], Loss: 0.0358\n",
      "Epoch [8/10], Step[7401/60000], Loss: 0.0147\n",
      "Epoch [8/10], Step[7501/60000], Loss: 0.0174\n",
      "Epoch [8/10], Step[7601/60000], Loss: 0.0265\n",
      "Epoch [8/10], Step[7701/60000], Loss: 0.0235\n",
      "Epoch [8/10], Step[7801/60000], Loss: 0.0271\n",
      "Epoch [8/10], Step[7901/60000], Loss: 0.0770\n",
      "Epoch [8/10], Step[8001/60000], Loss: 0.1080\n",
      "Epoch [8/10], Step[8101/60000], Loss: 0.0240\n",
      "Epoch [8/10], Step[8201/60000], Loss: 0.0720\n",
      "Epoch [8/10], Step[8301/60000], Loss: 0.0242\n",
      "Epoch [8/10], Step[8401/60000], Loss: 0.0400\n",
      "Epoch [8/10], Step[8501/60000], Loss: 0.0059\n",
      "Epoch [8/10], Step[8601/60000], Loss: 0.0088\n",
      "Epoch [8/10], Step[8701/60000], Loss: 0.0177\n",
      "Epoch [8/10], Step[8801/60000], Loss: 0.0335\n",
      "Epoch [8/10], Step[8901/60000], Loss: 0.0184\n",
      "Epoch [8/10], Step[9001/60000], Loss: 0.0693\n",
      "Epoch [8/10], Step[9101/60000], Loss: 0.0100\n",
      "Epoch [8/10], Step[9201/60000], Loss: 0.0189\n",
      "Epoch [8/10], Step[9301/60000], Loss: 0.0077\n",
      "Epoch [8/10], Step[9401/60000], Loss: 0.0061\n",
      "Epoch [8/10], Step[9501/60000], Loss: 0.0142\n",
      "Epoch [8/10], Step[9601/60000], Loss: 0.0041\n",
      "Epoch [8/10], Step[9701/60000], Loss: 0.0269\n",
      "Epoch [8/10], Step[9801/60000], Loss: 0.0036\n",
      "Epoch [8/10], Step[9901/60000], Loss: 0.0030\n",
      "Epoch [8/10], Step[10001/60000], Loss: 0.0364\n",
      "Epoch [8/10], Step[10101/60000], Loss: 0.0124\n",
      "Epoch [8/10], Step[10201/60000], Loss: 0.0442\n",
      "Epoch [8/10], Step[10301/60000], Loss: 0.0113\n",
      "Epoch [8/10], Step[10401/60000], Loss: 0.0025\n",
      "Epoch [8/10], Step[10501/60000], Loss: 0.0037\n",
      "Epoch [8/10], Step[10601/60000], Loss: 0.0025\n",
      "Epoch [8/10], Step[10701/60000], Loss: 0.0094\n",
      "Epoch [8/10], Step[10801/60000], Loss: 0.1656\n",
      "Epoch [8/10], Step[10901/60000], Loss: 0.0633\n",
      "Epoch [8/10], Step[11001/60000], Loss: 0.0047\n",
      "Epoch [8/10], Step[11101/60000], Loss: 0.0046\n",
      "Epoch [8/10], Step[11201/60000], Loss: 0.0092\n",
      "Epoch [8/10], Step[11301/60000], Loss: 0.0050\n",
      "Epoch [8/10], Step[11401/60000], Loss: 0.0063\n",
      "Epoch [8/10], Step[11501/60000], Loss: 0.0163\n",
      "Epoch [8/10], Step[11601/60000], Loss: 0.3499\n",
      "Epoch [8/10], Step[11701/60000], Loss: 0.2066\n",
      "Epoch [8/10], Step[11801/60000], Loss: 0.0145\n",
      "Epoch [8/10], Step[11901/60000], Loss: 0.0337\n",
      "Epoch [8/10], Step[12001/60000], Loss: 0.0101\n",
      "Epoch [8/10], Step[12101/60000], Loss: 0.0032\n",
      "Epoch [8/10], Step[12201/60000], Loss: 0.0052\n",
      "Epoch [8/10], Step[12301/60000], Loss: 0.0065\n",
      "Epoch [8/10], Step[12401/60000], Loss: 0.0474\n",
      "Epoch [8/10], Step[12501/60000], Loss: 0.0399\n",
      "Epoch [8/10], Step[12601/60000], Loss: 0.0264\n",
      "Epoch [8/10], Step[12701/60000], Loss: 0.0068\n",
      "Epoch [8/10], Step[12801/60000], Loss: 0.0249\n",
      "Epoch [8/10], Step[12901/60000], Loss: 0.0479\n",
      "Epoch [8/10], Step[13001/60000], Loss: 0.0238\n",
      "Epoch [8/10], Step[13101/60000], Loss: 0.0144\n",
      "Epoch [8/10], Step[13201/60000], Loss: 0.0036\n",
      "Epoch [8/10], Step[13301/60000], Loss: 0.0259\n",
      "Epoch [8/10], Step[13401/60000], Loss: 0.0400\n",
      "Epoch [8/10], Step[13501/60000], Loss: 0.0091\n",
      "Epoch [8/10], Step[13601/60000], Loss: 0.0228\n",
      "Epoch [8/10], Step[13701/60000], Loss: 0.0073\n",
      "Epoch [8/10], Step[13801/60000], Loss: 0.0189\n",
      "Epoch [8/10], Step[13901/60000], Loss: 0.0133\n",
      "Epoch [8/10], Step[14001/60000], Loss: 0.0153\n",
      "Epoch [8/10], Step[14101/60000], Loss: 0.0142\n",
      "Epoch [8/10], Step[14201/60000], Loss: 0.0109\n",
      "Epoch [8/10], Step[14301/60000], Loss: 0.0159\n",
      "Epoch [8/10], Step[14401/60000], Loss: 0.0079\n",
      "Epoch [8/10], Step[14501/60000], Loss: 0.0075\n",
      "Epoch [8/10], Step[14601/60000], Loss: 0.1778\n",
      "Epoch [8/10], Step[14701/60000], Loss: 0.0175\n",
      "Epoch [8/10], Step[14801/60000], Loss: 0.0072\n",
      "Epoch [8/10], Step[14901/60000], Loss: 0.0044\n",
      "Epoch [8/10], Step[15001/60000], Loss: 0.0128\n",
      "Epoch [8/10], Step[15101/60000], Loss: 0.1805\n",
      "Epoch [8/10], Step[15201/60000], Loss: 0.5148\n",
      "Epoch [8/10], Step[15301/60000], Loss: 0.0061\n",
      "Epoch [8/10], Step[15401/60000], Loss: 0.0127\n",
      "Epoch [8/10], Step[15501/60000], Loss: 0.0151\n",
      "Epoch [8/10], Step[15601/60000], Loss: 0.0062\n",
      "Epoch [8/10], Step[15701/60000], Loss: 0.0257\n",
      "Epoch [8/10], Step[15801/60000], Loss: 0.0206\n",
      "Epoch [8/10], Step[15901/60000], Loss: 0.0175\n",
      "Epoch [8/10], Step[16001/60000], Loss: 0.0193\n",
      "Epoch [8/10], Step[16101/60000], Loss: 0.0211\n",
      "Epoch [8/10], Step[16201/60000], Loss: 0.0066\n",
      "Epoch [8/10], Step[16301/60000], Loss: 0.0054\n",
      "Epoch [8/10], Step[16401/60000], Loss: 0.0285\n",
      "Epoch [8/10], Step[16501/60000], Loss: 0.0084\n",
      "Epoch [8/10], Step[16601/60000], Loss: 0.0186\n",
      "Epoch [8/10], Step[16701/60000], Loss: 0.1301\n",
      "Epoch [8/10], Step[16801/60000], Loss: 0.0157\n",
      "Epoch [8/10], Step[16901/60000], Loss: 0.0146\n",
      "Epoch [8/10], Step[17001/60000], Loss: 0.0152\n",
      "Epoch [8/10], Step[17101/60000], Loss: 0.0235\n",
      "Epoch [8/10], Step[17201/60000], Loss: 0.0217\n",
      "Epoch [8/10], Step[17301/60000], Loss: 0.3131\n",
      "Epoch [8/10], Step[17401/60000], Loss: 0.0278\n",
      "Epoch [8/10], Step[17501/60000], Loss: 0.0086\n",
      "Epoch [8/10], Step[17601/60000], Loss: 0.0059\n",
      "Epoch [8/10], Step[17701/60000], Loss: 0.0439\n",
      "Epoch [8/10], Step[17801/60000], Loss: 0.0209\n",
      "Epoch [8/10], Step[17901/60000], Loss: 0.0086\n",
      "Epoch [8/10], Step[18001/60000], Loss: 0.0631\n",
      "Epoch [8/10], Step[18101/60000], Loss: 0.0111\n",
      "Epoch [8/10], Step[18201/60000], Loss: 0.0158\n",
      "Epoch [8/10], Step[18301/60000], Loss: 0.0128\n",
      "Epoch [8/10], Step[18401/60000], Loss: 0.0074\n",
      "Epoch [8/10], Step[18501/60000], Loss: 0.0877\n",
      "Epoch [8/10], Step[18601/60000], Loss: 0.0042\n",
      "Epoch [8/10], Step[18701/60000], Loss: 0.0265\n",
      "Epoch [8/10], Step[18801/60000], Loss: 0.0064\n",
      "Epoch [8/10], Step[18901/60000], Loss: 0.0144\n",
      "Epoch [8/10], Step[19001/60000], Loss: 0.0205\n",
      "Epoch [8/10], Step[19101/60000], Loss: 0.0322\n",
      "Epoch [8/10], Step[19201/60000], Loss: 0.0110\n",
      "Epoch [8/10], Step[19301/60000], Loss: 0.0124\n",
      "Epoch [8/10], Step[19401/60000], Loss: 0.0362\n",
      "Epoch [8/10], Step[19501/60000], Loss: 0.0149\n",
      "Epoch [8/10], Step[19601/60000], Loss: 0.0024\n",
      "Epoch [8/10], Step[19701/60000], Loss: 0.0067\n",
      "Epoch [8/10], Step[19801/60000], Loss: 0.0110\n",
      "Epoch [8/10], Step[19901/60000], Loss: 0.0079\n",
      "Epoch [8/10], Step[20001/60000], Loss: 0.0423\n",
      "Epoch [8/10], Step[20101/60000], Loss: 0.0282\n",
      "Epoch [8/10], Step[20201/60000], Loss: 0.0213\n",
      "Epoch [8/10], Step[20301/60000], Loss: 0.0320\n",
      "Epoch [8/10], Step[20401/60000], Loss: 0.0039\n",
      "Epoch [8/10], Step[20501/60000], Loss: 0.0344\n",
      "Epoch [8/10], Step[20601/60000], Loss: 0.0100\n",
      "Epoch [8/10], Step[20701/60000], Loss: 0.0499\n",
      "Epoch [8/10], Step[20801/60000], Loss: 0.0057\n",
      "Epoch [8/10], Step[20901/60000], Loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step[21001/60000], Loss: 0.0391\n",
      "Epoch [8/10], Step[21101/60000], Loss: 0.0241\n",
      "Epoch [8/10], Step[21201/60000], Loss: 0.0038\n",
      "Epoch [8/10], Step[21301/60000], Loss: 0.0084\n",
      "Epoch [8/10], Step[21401/60000], Loss: 0.0168\n",
      "Epoch [8/10], Step[21501/60000], Loss: 0.0159\n",
      "Epoch [8/10], Step[21601/60000], Loss: 0.0470\n",
      "Epoch [8/10], Step[21701/60000], Loss: 0.0041\n",
      "Epoch [8/10], Step[21801/60000], Loss: 0.1154\n",
      "Epoch [8/10], Step[21901/60000], Loss: 0.0358\n",
      "Epoch [8/10], Step[22001/60000], Loss: 0.0130\n",
      "Epoch [8/10], Step[22101/60000], Loss: 0.0144\n",
      "Epoch [8/10], Step[22201/60000], Loss: 0.0073\n",
      "Epoch [8/10], Step[22301/60000], Loss: 0.0033\n",
      "Epoch [8/10], Step[22401/60000], Loss: 0.2017\n",
      "Epoch [8/10], Step[22501/60000], Loss: 0.1894\n",
      "Epoch [8/10], Step[22601/60000], Loss: 0.0046\n",
      "Epoch [8/10], Step[22701/60000], Loss: 0.0090\n",
      "Epoch [8/10], Step[22801/60000], Loss: 0.0093\n",
      "Epoch [8/10], Step[22901/60000], Loss: 0.0031\n",
      "Epoch [8/10], Step[23001/60000], Loss: 0.0112\n",
      "Epoch [8/10], Step[23101/60000], Loss: 0.0536\n",
      "Epoch [8/10], Step[23201/60000], Loss: 0.3077\n",
      "Epoch [8/10], Step[23301/60000], Loss: 0.0353\n",
      "Epoch [8/10], Step[23401/60000], Loss: 0.0064\n",
      "Epoch [8/10], Step[23501/60000], Loss: 0.0352\n",
      "Epoch [8/10], Step[23601/60000], Loss: 0.0228\n",
      "Epoch [8/10], Step[23701/60000], Loss: 0.0152\n",
      "Epoch [8/10], Step[23801/60000], Loss: 0.0240\n",
      "Epoch [8/10], Step[23901/60000], Loss: 0.0382\n",
      "Epoch [8/10], Step[24001/60000], Loss: 0.0560\n",
      "Epoch [8/10], Step[24101/60000], Loss: 0.0133\n",
      "Epoch [8/10], Step[24201/60000], Loss: 0.0190\n",
      "Epoch [8/10], Step[24301/60000], Loss: 0.0134\n",
      "Epoch [8/10], Step[24401/60000], Loss: 0.0097\n",
      "Epoch [8/10], Step[24501/60000], Loss: 0.0219\n",
      "Epoch [8/10], Step[24601/60000], Loss: 0.0136\n",
      "Epoch [8/10], Step[24701/60000], Loss: 0.0141\n",
      "Epoch [8/10], Step[24801/60000], Loss: 0.0215\n",
      "Epoch [8/10], Step[24901/60000], Loss: 0.0101\n",
      "Epoch [8/10], Step[25001/60000], Loss: 0.0073\n",
      "Epoch [8/10], Step[25101/60000], Loss: 0.0184\n",
      "Epoch [8/10], Step[25201/60000], Loss: 0.0202\n",
      "Epoch [8/10], Step[25301/60000], Loss: 0.0071\n",
      "Epoch [8/10], Step[25401/60000], Loss: 0.0134\n",
      "Epoch [8/10], Step[25501/60000], Loss: 0.0324\n",
      "Epoch [8/10], Step[25601/60000], Loss: 0.0212\n",
      "Epoch [8/10], Step[25701/60000], Loss: 0.0297\n",
      "Epoch [8/10], Step[25801/60000], Loss: 0.0125\n",
      "Epoch [8/10], Step[25901/60000], Loss: 0.0060\n",
      "Epoch [8/10], Step[26001/60000], Loss: 0.0080\n",
      "Epoch [8/10], Step[26101/60000], Loss: 0.0039\n",
      "Epoch [8/10], Step[26201/60000], Loss: 0.0176\n",
      "Epoch [8/10], Step[26301/60000], Loss: 0.0194\n",
      "Epoch [8/10], Step[26401/60000], Loss: 0.0324\n",
      "Epoch [8/10], Step[26501/60000], Loss: 0.0770\n",
      "Epoch [8/10], Step[26601/60000], Loss: 0.0405\n",
      "Epoch [8/10], Step[26701/60000], Loss: 0.0652\n",
      "Epoch [8/10], Step[26801/60000], Loss: 0.0621\n",
      "Epoch [8/10], Step[26901/60000], Loss: 0.0193\n",
      "Epoch [8/10], Step[27001/60000], Loss: 0.0084\n",
      "Epoch [8/10], Step[27101/60000], Loss: 0.0306\n",
      "Epoch [8/10], Step[27201/60000], Loss: 0.0764\n",
      "Epoch [8/10], Step[27301/60000], Loss: 0.0117\n",
      "Epoch [8/10], Step[27401/60000], Loss: 0.0172\n",
      "Epoch [8/10], Step[27501/60000], Loss: 0.0126\n",
      "Epoch [8/10], Step[27601/60000], Loss: 0.0183\n",
      "Epoch [8/10], Step[27701/60000], Loss: 0.0152\n",
      "Epoch [8/10], Step[27801/60000], Loss: 0.0370\n",
      "Epoch [8/10], Step[27901/60000], Loss: 0.0075\n",
      "Epoch [8/10], Step[28001/60000], Loss: 0.0062\n",
      "Epoch [8/10], Step[28101/60000], Loss: 0.0198\n",
      "Epoch [8/10], Step[28201/60000], Loss: 0.0103\n",
      "Epoch [8/10], Step[28301/60000], Loss: 0.0416\n",
      "Epoch [8/10], Step[28401/60000], Loss: 0.0082\n",
      "Epoch [8/10], Step[28501/60000], Loss: 0.0078\n",
      "Epoch [8/10], Step[28601/60000], Loss: 0.0100\n",
      "Epoch [8/10], Step[28701/60000], Loss: 0.0162\n",
      "Epoch [8/10], Step[28801/60000], Loss: 0.0032\n",
      "Epoch [8/10], Step[28901/60000], Loss: 0.0163\n",
      "Epoch [8/10], Step[29001/60000], Loss: 0.0180\n",
      "Epoch [8/10], Step[29101/60000], Loss: 0.0174\n",
      "Epoch [8/10], Step[29201/60000], Loss: 0.0208\n",
      "Epoch [8/10], Step[29301/60000], Loss: 0.0189\n",
      "Epoch [8/10], Step[29401/60000], Loss: 0.0147\n",
      "Epoch [8/10], Step[29501/60000], Loss: 0.0014\n",
      "Epoch [8/10], Step[29601/60000], Loss: 0.0161\n",
      "Epoch [8/10], Step[29701/60000], Loss: 0.0953\n",
      "Epoch [8/10], Step[29801/60000], Loss: 0.0253\n",
      "Epoch [8/10], Step[29901/60000], Loss: 0.1956\n",
      "Epoch [8/10], Step[30001/60000], Loss: 0.0294\n",
      "Epoch [8/10], Step[30101/60000], Loss: 0.0101\n",
      "Epoch [8/10], Step[30201/60000], Loss: 0.0043\n",
      "Epoch [8/10], Step[30301/60000], Loss: 0.0077\n",
      "Epoch [8/10], Step[30401/60000], Loss: 0.0092\n",
      "Epoch [8/10], Step[30501/60000], Loss: 0.0102\n",
      "Epoch [8/10], Step[30601/60000], Loss: 0.0187\n",
      "Epoch [8/10], Step[30701/60000], Loss: 0.0219\n",
      "Epoch [8/10], Step[30801/60000], Loss: 0.0096\n",
      "Epoch [8/10], Step[30901/60000], Loss: 0.0121\n",
      "Epoch [8/10], Step[31001/60000], Loss: 0.0118\n",
      "Epoch [8/10], Step[31101/60000], Loss: 0.0160\n",
      "Epoch [8/10], Step[31201/60000], Loss: 0.0052\n",
      "Epoch [8/10], Step[31301/60000], Loss: 0.0271\n",
      "Epoch [8/10], Step[31401/60000], Loss: 0.0165\n",
      "Epoch [8/10], Step[31501/60000], Loss: 0.0339\n",
      "Epoch [8/10], Step[31601/60000], Loss: 0.3631\n",
      "Epoch [8/10], Step[31701/60000], Loss: 0.0427\n",
      "Epoch [8/10], Step[31801/60000], Loss: 0.0087\n",
      "Epoch [8/10], Step[31901/60000], Loss: 0.0165\n",
      "Epoch [8/10], Step[32001/60000], Loss: 0.0047\n",
      "Epoch [8/10], Step[32101/60000], Loss: 0.0084\n",
      "Epoch [8/10], Step[32201/60000], Loss: 0.0247\n",
      "Epoch [8/10], Step[32301/60000], Loss: 0.2870\n",
      "Epoch [8/10], Step[32401/60000], Loss: 0.0321\n",
      "Epoch [8/10], Step[32501/60000], Loss: 0.0161\n",
      "Epoch [8/10], Step[32601/60000], Loss: 0.6735\n",
      "Epoch [8/10], Step[32701/60000], Loss: 0.0232\n",
      "Epoch [8/10], Step[32801/60000], Loss: 0.0107\n",
      "Epoch [8/10], Step[32901/60000], Loss: 0.0234\n",
      "Epoch [8/10], Step[33001/60000], Loss: 0.0388\n",
      "Epoch [8/10], Step[33101/60000], Loss: 0.0238\n",
      "Epoch [8/10], Step[33201/60000], Loss: 0.0119\n",
      "Epoch [8/10], Step[33301/60000], Loss: 0.0150\n",
      "Epoch [8/10], Step[33401/60000], Loss: 0.0125\n",
      "Epoch [8/10], Step[33501/60000], Loss: 0.0311\n",
      "Epoch [8/10], Step[33601/60000], Loss: 0.0190\n",
      "Epoch [8/10], Step[33701/60000], Loss: 0.1769\n",
      "Epoch [8/10], Step[33801/60000], Loss: 0.0082\n",
      "Epoch [8/10], Step[33901/60000], Loss: 0.0039\n",
      "Epoch [8/10], Step[34001/60000], Loss: 0.0781\n",
      "Epoch [8/10], Step[34101/60000], Loss: 0.0099\n",
      "Epoch [8/10], Step[34201/60000], Loss: 0.0015\n",
      "Epoch [8/10], Step[34301/60000], Loss: 0.0092\n",
      "Epoch [8/10], Step[34401/60000], Loss: 0.0468\n",
      "Epoch [8/10], Step[34501/60000], Loss: 0.0351\n",
      "Epoch [8/10], Step[34601/60000], Loss: 0.0622\n",
      "Epoch [8/10], Step[34701/60000], Loss: 0.6134\n",
      "Epoch [8/10], Step[34801/60000], Loss: 0.0162\n",
      "Epoch [8/10], Step[34901/60000], Loss: 0.0072\n",
      "Epoch [8/10], Step[35001/60000], Loss: 0.0198\n",
      "Epoch [8/10], Step[35101/60000], Loss: 0.0095\n",
      "Epoch [8/10], Step[35201/60000], Loss: 0.0293\n",
      "Epoch [8/10], Step[35301/60000], Loss: 0.0328\n",
      "Epoch [8/10], Step[35401/60000], Loss: 0.0905\n",
      "Epoch [8/10], Step[35501/60000], Loss: 0.0103\n",
      "Epoch [8/10], Step[35601/60000], Loss: 0.1076\n",
      "Epoch [8/10], Step[35701/60000], Loss: 0.0045\n",
      "Epoch [8/10], Step[35801/60000], Loss: 0.0066\n",
      "Epoch [8/10], Step[35901/60000], Loss: 0.0197\n",
      "Epoch [8/10], Step[36001/60000], Loss: 0.0291\n",
      "Epoch [8/10], Step[36101/60000], Loss: 0.1107\n",
      "Epoch [8/10], Step[36201/60000], Loss: 0.0065\n",
      "Epoch [8/10], Step[36301/60000], Loss: 0.0143\n",
      "Epoch [8/10], Step[36401/60000], Loss: 0.0535\n",
      "Epoch [8/10], Step[36501/60000], Loss: 0.0073\n",
      "Epoch [8/10], Step[36601/60000], Loss: 0.0200\n",
      "Epoch [8/10], Step[36701/60000], Loss: 0.0122\n",
      "Epoch [8/10], Step[36801/60000], Loss: 0.0184\n",
      "Epoch [8/10], Step[36901/60000], Loss: 0.0259\n",
      "Epoch [8/10], Step[37001/60000], Loss: 0.0318\n",
      "Epoch [8/10], Step[37101/60000], Loss: 0.0158\n",
      "Epoch [8/10], Step[37201/60000], Loss: 0.0151\n",
      "Epoch [8/10], Step[37301/60000], Loss: 0.0311\n",
      "Epoch [8/10], Step[37401/60000], Loss: 0.0230\n",
      "Epoch [8/10], Step[37501/60000], Loss: 0.0199\n",
      "Epoch [8/10], Step[37601/60000], Loss: 0.0065\n",
      "Epoch [8/10], Step[37701/60000], Loss: 0.0112\n",
      "Epoch [8/10], Step[37801/60000], Loss: 0.1274\n",
      "Epoch [8/10], Step[37901/60000], Loss: 0.0088\n",
      "Epoch [8/10], Step[38001/60000], Loss: 0.0090\n",
      "Epoch [8/10], Step[38101/60000], Loss: 0.0070\n",
      "Epoch [8/10], Step[38201/60000], Loss: 0.0042\n",
      "Epoch [8/10], Step[38301/60000], Loss: 0.0368\n",
      "Epoch [8/10], Step[38401/60000], Loss: 0.0019\n",
      "Epoch [8/10], Step[38501/60000], Loss: 0.0114\n",
      "Epoch [8/10], Step[38601/60000], Loss: 0.0286\n",
      "Epoch [8/10], Step[38701/60000], Loss: 0.0336\n",
      "Epoch [8/10], Step[38801/60000], Loss: 0.0947\n",
      "Epoch [8/10], Step[38901/60000], Loss: 0.0090\n",
      "Epoch [8/10], Step[39001/60000], Loss: 0.0116\n",
      "Epoch [8/10], Step[39101/60000], Loss: 0.0055\n",
      "Epoch [8/10], Step[39201/60000], Loss: 0.0091\n",
      "Epoch [8/10], Step[39301/60000], Loss: 0.0553\n",
      "Epoch [8/10], Step[39401/60000], Loss: 0.2022\n",
      "Epoch [8/10], Step[39501/60000], Loss: 0.0217\n",
      "Epoch [8/10], Step[39601/60000], Loss: 0.0347\n",
      "Epoch [8/10], Step[39701/60000], Loss: 0.0081\n",
      "Epoch [8/10], Step[39801/60000], Loss: 0.0303\n",
      "Epoch [8/10], Step[39901/60000], Loss: 0.0068\n",
      "Epoch [8/10], Step[40001/60000], Loss: 0.0129\n",
      "Epoch [8/10], Step[40101/60000], Loss: 0.0187\n",
      "Epoch [8/10], Step[40201/60000], Loss: 0.0313\n",
      "Epoch [8/10], Step[40301/60000], Loss: 0.0169\n",
      "Epoch [8/10], Step[40401/60000], Loss: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step[40501/60000], Loss: 0.0073\n",
      "Epoch [8/10], Step[40601/60000], Loss: 0.0252\n",
      "Epoch [8/10], Step[40701/60000], Loss: 0.0092\n",
      "Epoch [8/10], Step[40801/60000], Loss: 0.0169\n",
      "Epoch [8/10], Step[40901/60000], Loss: 0.0241\n",
      "Epoch [8/10], Step[41001/60000], Loss: 0.0198\n",
      "Epoch [8/10], Step[41101/60000], Loss: 0.0249\n",
      "Epoch [8/10], Step[41201/60000], Loss: 0.0283\n",
      "Epoch [8/10], Step[41301/60000], Loss: 0.0581\n",
      "Epoch [8/10], Step[41401/60000], Loss: 0.4493\n",
      "Epoch [8/10], Step[41501/60000], Loss: 0.0766\n",
      "Epoch [8/10], Step[41601/60000], Loss: 0.0127\n",
      "Epoch [8/10], Step[41701/60000], Loss: 0.0068\n",
      "Epoch [8/10], Step[41801/60000], Loss: 0.0197\n",
      "Epoch [8/10], Step[41901/60000], Loss: 0.0293\n",
      "Epoch [8/10], Step[42001/60000], Loss: 0.1101\n",
      "Epoch [8/10], Step[42101/60000], Loss: 0.0294\n",
      "Epoch [8/10], Step[42201/60000], Loss: 0.0122\n",
      "Epoch [8/10], Step[42301/60000], Loss: 0.0196\n",
      "Epoch [8/10], Step[42401/60000], Loss: 0.0292\n",
      "Epoch [8/10], Step[42501/60000], Loss: 0.0797\n",
      "Epoch [8/10], Step[42601/60000], Loss: 0.0217\n",
      "Epoch [8/10], Step[42701/60000], Loss: 0.0564\n",
      "Epoch [8/10], Step[42801/60000], Loss: 0.0547\n",
      "Epoch [8/10], Step[42901/60000], Loss: 0.0243\n",
      "Epoch [8/10], Step[43001/60000], Loss: 0.0435\n",
      "Epoch [8/10], Step[43101/60000], Loss: 0.0490\n",
      "Epoch [8/10], Step[43201/60000], Loss: 0.0077\n",
      "Epoch [8/10], Step[43301/60000], Loss: 0.0052\n",
      "Epoch [8/10], Step[43401/60000], Loss: 0.0487\n",
      "Epoch [8/10], Step[43501/60000], Loss: 0.0089\n",
      "Epoch [8/10], Step[43601/60000], Loss: 0.0207\n",
      "Epoch [8/10], Step[43701/60000], Loss: 0.0078\n",
      "Epoch [8/10], Step[43801/60000], Loss: 0.0209\n",
      "Epoch [8/10], Step[43901/60000], Loss: 0.0746\n",
      "Epoch [8/10], Step[44001/60000], Loss: 0.0499\n",
      "Epoch [8/10], Step[44101/60000], Loss: 0.0524\n",
      "Epoch [8/10], Step[44201/60000], Loss: 0.0317\n",
      "Epoch [8/10], Step[44301/60000], Loss: 0.0269\n",
      "Epoch [8/10], Step[44401/60000], Loss: 0.1776\n",
      "Epoch [8/10], Step[44501/60000], Loss: 0.0103\n",
      "Epoch [8/10], Step[44601/60000], Loss: 0.0129\n",
      "Epoch [8/10], Step[44701/60000], Loss: 0.0055\n",
      "Epoch [8/10], Step[44801/60000], Loss: 0.0375\n",
      "Epoch [8/10], Step[44901/60000], Loss: 0.1091\n",
      "Epoch [8/10], Step[45001/60000], Loss: 0.0114\n",
      "Epoch [8/10], Step[45101/60000], Loss: 0.2128\n",
      "Epoch [8/10], Step[45201/60000], Loss: 0.0234\n",
      "Epoch [8/10], Step[45301/60000], Loss: 0.0683\n",
      "Epoch [8/10], Step[45401/60000], Loss: 0.0126\n",
      "Epoch [8/10], Step[45501/60000], Loss: 0.0407\n",
      "Epoch [8/10], Step[45601/60000], Loss: 0.0241\n",
      "Epoch [8/10], Step[45701/60000], Loss: 0.0059\n",
      "Epoch [8/10], Step[45801/60000], Loss: 0.0275\n",
      "Epoch [8/10], Step[45901/60000], Loss: 0.0321\n",
      "Epoch [8/10], Step[46001/60000], Loss: 0.1586\n",
      "Epoch [8/10], Step[46101/60000], Loss: 0.0162\n",
      "Epoch [8/10], Step[46201/60000], Loss: 0.0540\n",
      "Epoch [8/10], Step[46301/60000], Loss: 0.0116\n",
      "Epoch [8/10], Step[46401/60000], Loss: 0.0219\n",
      "Epoch [8/10], Step[46501/60000], Loss: 0.0073\n",
      "Epoch [8/10], Step[46601/60000], Loss: 0.0037\n",
      "Epoch [8/10], Step[46701/60000], Loss: 0.0148\n",
      "Epoch [8/10], Step[46801/60000], Loss: 0.0303\n",
      "Epoch [8/10], Step[46901/60000], Loss: 0.0209\n",
      "Epoch [8/10], Step[47001/60000], Loss: 0.0250\n",
      "Epoch [8/10], Step[47101/60000], Loss: 0.0046\n",
      "Epoch [8/10], Step[47201/60000], Loss: 0.0646\n",
      "Epoch [8/10], Step[47301/60000], Loss: 0.0463\n",
      "Epoch [8/10], Step[47401/60000], Loss: 0.0222\n",
      "Epoch [8/10], Step[47501/60000], Loss: 0.0190\n",
      "Epoch [8/10], Step[47601/60000], Loss: 0.0830\n",
      "Epoch [8/10], Step[47701/60000], Loss: 0.0055\n",
      "Epoch [8/10], Step[47801/60000], Loss: 0.0153\n",
      "Epoch [8/10], Step[47901/60000], Loss: 0.0203\n",
      "Epoch [8/10], Step[48001/60000], Loss: 0.0185\n",
      "Epoch [8/10], Step[48101/60000], Loss: 0.0121\n",
      "Epoch [8/10], Step[48201/60000], Loss: 0.0055\n",
      "Epoch [8/10], Step[48301/60000], Loss: 0.0253\n",
      "Epoch [8/10], Step[48401/60000], Loss: 0.0088\n",
      "Epoch [8/10], Step[48501/60000], Loss: 0.0154\n",
      "Epoch [8/10], Step[48601/60000], Loss: 0.0094\n",
      "Epoch [8/10], Step[48701/60000], Loss: 0.0075\n",
      "Epoch [8/10], Step[48801/60000], Loss: 0.0129\n",
      "Epoch [8/10], Step[48901/60000], Loss: 0.1129\n",
      "Epoch [8/10], Step[49001/60000], Loss: 0.1731\n",
      "Epoch [8/10], Step[49101/60000], Loss: 0.1570\n",
      "Epoch [8/10], Step[49201/60000], Loss: 0.0264\n",
      "Epoch [8/10], Step[49301/60000], Loss: 0.0051\n",
      "Epoch [8/10], Step[49401/60000], Loss: 0.0362\n",
      "Epoch [8/10], Step[49501/60000], Loss: 0.4232\n",
      "Epoch [8/10], Step[49601/60000], Loss: 0.0162\n",
      "Epoch [8/10], Step[49701/60000], Loss: 0.0191\n",
      "Epoch [8/10], Step[49801/60000], Loss: 0.0638\n",
      "Epoch [8/10], Step[49901/60000], Loss: 0.0135\n",
      "Epoch [8/10], Step[50001/60000], Loss: 0.0468\n",
      "Epoch [8/10], Step[50101/60000], Loss: 0.0072\n",
      "Epoch [8/10], Step[50201/60000], Loss: 0.0430\n",
      "Epoch [8/10], Step[50301/60000], Loss: 0.0305\n",
      "Epoch [8/10], Step[50401/60000], Loss: 0.0382\n",
      "Epoch [8/10], Step[50501/60000], Loss: 0.0150\n",
      "Epoch [8/10], Step[50601/60000], Loss: 0.0151\n",
      "Epoch [8/10], Step[50701/60000], Loss: 0.0235\n",
      "Epoch [8/10], Step[50801/60000], Loss: 0.0346\n",
      "Epoch [8/10], Step[50901/60000], Loss: 0.0328\n",
      "Epoch [8/10], Step[51001/60000], Loss: 0.0149\n",
      "Epoch [8/10], Step[51101/60000], Loss: 0.0641\n",
      "Epoch [8/10], Step[51201/60000], Loss: 0.0555\n",
      "Epoch [8/10], Step[51301/60000], Loss: 0.0071\n",
      "Epoch [8/10], Step[51401/60000], Loss: 0.0246\n",
      "Epoch [8/10], Step[51501/60000], Loss: 0.0095\n",
      "Epoch [8/10], Step[51601/60000], Loss: 0.0455\n",
      "Epoch [8/10], Step[51701/60000], Loss: 0.0082\n",
      "Epoch [8/10], Step[51801/60000], Loss: 0.0079\n",
      "Epoch [8/10], Step[51901/60000], Loss: 0.0395\n",
      "Epoch [8/10], Step[52001/60000], Loss: 0.0144\n",
      "Epoch [8/10], Step[52101/60000], Loss: 0.3471\n",
      "Epoch [8/10], Step[52201/60000], Loss: 0.0420\n",
      "Epoch [8/10], Step[52301/60000], Loss: 0.0484\n",
      "Epoch [8/10], Step[52401/60000], Loss: 0.0192\n",
      "Epoch [8/10], Step[52501/60000], Loss: 0.0041\n",
      "Epoch [8/10], Step[52601/60000], Loss: 0.0173\n",
      "Epoch [8/10], Step[52701/60000], Loss: 0.0089\n",
      "Epoch [8/10], Step[52801/60000], Loss: 0.0305\n",
      "Epoch [8/10], Step[52901/60000], Loss: 0.0285\n",
      "Epoch [8/10], Step[53001/60000], Loss: 0.0198\n",
      "Epoch [8/10], Step[53101/60000], Loss: 0.0060\n",
      "Epoch [8/10], Step[53201/60000], Loss: 0.0077\n",
      "Epoch [8/10], Step[53301/60000], Loss: 0.0245\n",
      "Epoch [8/10], Step[53401/60000], Loss: 0.0174\n",
      "Epoch [8/10], Step[53501/60000], Loss: 0.0142\n",
      "Epoch [8/10], Step[53601/60000], Loss: 0.0454\n",
      "Epoch [8/10], Step[53701/60000], Loss: 0.0343\n",
      "Epoch [8/10], Step[53801/60000], Loss: 0.0088\n",
      "Epoch [8/10], Step[53901/60000], Loss: 0.1487\n",
      "Epoch [8/10], Step[54001/60000], Loss: 0.1753\n",
      "Epoch [8/10], Step[54101/60000], Loss: 0.0108\n",
      "Epoch [8/10], Step[54201/60000], Loss: 0.0194\n",
      "Epoch [8/10], Step[54301/60000], Loss: 0.0077\n",
      "Epoch [8/10], Step[54401/60000], Loss: 0.0177\n",
      "Epoch [8/10], Step[54501/60000], Loss: 0.0177\n",
      "Epoch [8/10], Step[54601/60000], Loss: 0.0147\n",
      "Epoch [8/10], Step[54701/60000], Loss: 0.0200\n",
      "Epoch [8/10], Step[54801/60000], Loss: 0.0777\n",
      "Epoch [8/10], Step[54901/60000], Loss: 0.0144\n",
      "Epoch [8/10], Step[55001/60000], Loss: 0.0061\n",
      "Epoch [8/10], Step[55101/60000], Loss: 0.0083\n",
      "Epoch [8/10], Step[55201/60000], Loss: 0.0180\n",
      "Epoch [8/10], Step[55301/60000], Loss: 0.0559\n",
      "Epoch [8/10], Step[55401/60000], Loss: 0.0117\n",
      "Epoch [8/10], Step[55501/60000], Loss: 0.0122\n",
      "Epoch [8/10], Step[55601/60000], Loss: 0.0095\n",
      "Epoch [8/10], Step[55701/60000], Loss: 0.0290\n",
      "Epoch [8/10], Step[55801/60000], Loss: 0.0098\n",
      "Epoch [8/10], Step[55901/60000], Loss: 0.0081\n",
      "Epoch [8/10], Step[56001/60000], Loss: 0.0168\n",
      "Epoch [8/10], Step[56101/60000], Loss: 0.0051\n",
      "Epoch [8/10], Step[56201/60000], Loss: 0.0224\n",
      "Epoch [8/10], Step[56301/60000], Loss: 0.0239\n",
      "Epoch [8/10], Step[56401/60000], Loss: 0.0604\n",
      "Epoch [8/10], Step[56501/60000], Loss: 0.0163\n",
      "Epoch [8/10], Step[56601/60000], Loss: 0.0102\n",
      "Epoch [8/10], Step[56701/60000], Loss: 0.0128\n",
      "Epoch [8/10], Step[56801/60000], Loss: 0.0149\n",
      "Epoch [8/10], Step[56901/60000], Loss: 0.0060\n",
      "Epoch [8/10], Step[57001/60000], Loss: 0.0085\n",
      "Epoch [8/10], Step[57101/60000], Loss: 0.0079\n",
      "Epoch [8/10], Step[57201/60000], Loss: 0.0052\n",
      "Epoch [8/10], Step[57301/60000], Loss: 0.0170\n",
      "Epoch [8/10], Step[57401/60000], Loss: 0.0208\n",
      "Epoch [8/10], Step[57501/60000], Loss: 0.0080\n",
      "Epoch [8/10], Step[57601/60000], Loss: 0.2193\n",
      "Epoch [8/10], Step[57701/60000], Loss: 0.0237\n",
      "Epoch [8/10], Step[57801/60000], Loss: 0.0078\n",
      "Epoch [8/10], Step[57901/60000], Loss: 0.0034\n",
      "Epoch [8/10], Step[58001/60000], Loss: 0.0268\n",
      "Epoch [8/10], Step[58101/60000], Loss: 0.0043\n",
      "Epoch [8/10], Step[58201/60000], Loss: 0.0082\n",
      "Epoch [8/10], Step[58301/60000], Loss: 0.0110\n",
      "Epoch [8/10], Step[58401/60000], Loss: 0.0016\n",
      "Epoch [8/10], Step[58501/60000], Loss: 0.0060\n",
      "Epoch [8/10], Step[58601/60000], Loss: 0.0247\n",
      "Epoch [8/10], Step[58701/60000], Loss: 0.0678\n",
      "Epoch [8/10], Step[58801/60000], Loss: 0.0064\n",
      "Epoch [8/10], Step[58901/60000], Loss: 0.0004\n",
      "Epoch [8/10], Step[59001/60000], Loss: 0.0121\n",
      "Epoch [8/10], Step[59101/60000], Loss: 0.0023\n",
      "Epoch [8/10], Step[59201/60000], Loss: 0.0047\n",
      "Epoch [8/10], Step[59301/60000], Loss: 0.0075\n",
      "Epoch [8/10], Step[59401/60000], Loss: 0.0072\n",
      "Epoch [8/10], Step[59501/60000], Loss: 0.0013\n",
      "Epoch [8/10], Step[59601/60000], Loss: 0.0098\n",
      "Epoch [8/10], Step[59701/60000], Loss: 0.0450\n",
      "Epoch [8/10], Step[59801/60000], Loss: 0.0014\n",
      "Epoch [8/10], Step[59901/60000], Loss: 0.4808\n",
      "Epoch [9/10], Step[1/60000], Loss: 0.0181\n",
      "Epoch [9/10], Step[101/60000], Loss: 0.1134\n",
      "Epoch [9/10], Step[201/60000], Loss: 0.0258\n",
      "Epoch [9/10], Step[301/60000], Loss: 0.0062\n",
      "Epoch [9/10], Step[401/60000], Loss: 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step[501/60000], Loss: 0.0896\n",
      "Epoch [9/10], Step[601/60000], Loss: 0.0944\n",
      "Epoch [9/10], Step[701/60000], Loss: 0.0302\n",
      "Epoch [9/10], Step[801/60000], Loss: 0.2090\n",
      "Epoch [9/10], Step[901/60000], Loss: 0.0212\n",
      "Epoch [9/10], Step[1001/60000], Loss: 0.0551\n",
      "Epoch [9/10], Step[1101/60000], Loss: 0.0444\n",
      "Epoch [9/10], Step[1201/60000], Loss: 0.4113\n",
      "Epoch [9/10], Step[1301/60000], Loss: 0.0164\n",
      "Epoch [9/10], Step[1401/60000], Loss: 0.0123\n",
      "Epoch [9/10], Step[1501/60000], Loss: 0.0132\n",
      "Epoch [9/10], Step[1601/60000], Loss: 0.0392\n",
      "Epoch [9/10], Step[1701/60000], Loss: 0.0188\n",
      "Epoch [9/10], Step[1801/60000], Loss: 0.0294\n",
      "Epoch [9/10], Step[1901/60000], Loss: 0.0168\n",
      "Epoch [9/10], Step[2001/60000], Loss: 0.0152\n",
      "Epoch [9/10], Step[2101/60000], Loss: 0.0118\n",
      "Epoch [9/10], Step[2201/60000], Loss: 0.0080\n",
      "Epoch [9/10], Step[2301/60000], Loss: 0.0025\n",
      "Epoch [9/10], Step[2401/60000], Loss: 0.0109\n",
      "Epoch [9/10], Step[2501/60000], Loss: 0.0431\n",
      "Epoch [9/10], Step[2601/60000], Loss: 0.0197\n",
      "Epoch [9/10], Step[2701/60000], Loss: 0.0572\n",
      "Epoch [9/10], Step[2801/60000], Loss: 0.0035\n",
      "Epoch [9/10], Step[2901/60000], Loss: 0.0105\n",
      "Epoch [9/10], Step[3001/60000], Loss: 0.0678\n",
      "Epoch [9/10], Step[3101/60000], Loss: 0.0021\n",
      "Epoch [9/10], Step[3201/60000], Loss: 0.1920\n",
      "Epoch [9/10], Step[3301/60000], Loss: 0.0237\n",
      "Epoch [9/10], Step[3401/60000], Loss: 0.0067\n",
      "Epoch [9/10], Step[3501/60000], Loss: 0.0095\n",
      "Epoch [9/10], Step[3601/60000], Loss: 0.0805\n",
      "Epoch [9/10], Step[3701/60000], Loss: 0.0262\n",
      "Epoch [9/10], Step[3801/60000], Loss: 0.0095\n",
      "Epoch [9/10], Step[3901/60000], Loss: 0.0075\n",
      "Epoch [9/10], Step[4001/60000], Loss: 0.0096\n",
      "Epoch [9/10], Step[4101/60000], Loss: 0.2568\n",
      "Epoch [9/10], Step[4201/60000], Loss: 0.0211\n",
      "Epoch [9/10], Step[4301/60000], Loss: 0.0064\n",
      "Epoch [9/10], Step[4401/60000], Loss: 0.0550\n",
      "Epoch [9/10], Step[4501/60000], Loss: 0.0151\n",
      "Epoch [9/10], Step[4601/60000], Loss: 0.0239\n",
      "Epoch [9/10], Step[4701/60000], Loss: 0.0102\n",
      "Epoch [9/10], Step[4801/60000], Loss: 0.0035\n",
      "Epoch [9/10], Step[4901/60000], Loss: 0.0241\n",
      "Epoch [9/10], Step[5001/60000], Loss: 0.0179\n",
      "Epoch [9/10], Step[5101/60000], Loss: 0.0744\n",
      "Epoch [9/10], Step[5201/60000], Loss: 0.0111\n",
      "Epoch [9/10], Step[5301/60000], Loss: 0.0201\n",
      "Epoch [9/10], Step[5401/60000], Loss: 0.0103\n",
      "Epoch [9/10], Step[5501/60000], Loss: 0.0070\n",
      "Epoch [9/10], Step[5601/60000], Loss: 0.0116\n",
      "Epoch [9/10], Step[5701/60000], Loss: 0.0180\n",
      "Epoch [9/10], Step[5801/60000], Loss: 0.0346\n",
      "Epoch [9/10], Step[5901/60000], Loss: 0.0677\n",
      "Epoch [9/10], Step[6001/60000], Loss: 0.0083\n",
      "Epoch [9/10], Step[6101/60000], Loss: 0.0065\n",
      "Epoch [9/10], Step[6201/60000], Loss: 0.0307\n",
      "Epoch [9/10], Step[6301/60000], Loss: 0.0075\n",
      "Epoch [9/10], Step[6401/60000], Loss: 0.0080\n",
      "Epoch [9/10], Step[6501/60000], Loss: 0.0015\n",
      "Epoch [9/10], Step[6601/60000], Loss: 0.0132\n",
      "Epoch [9/10], Step[6701/60000], Loss: 0.0074\n",
      "Epoch [9/10], Step[6801/60000], Loss: 0.0824\n",
      "Epoch [9/10], Step[6901/60000], Loss: 0.0147\n",
      "Epoch [9/10], Step[7001/60000], Loss: 0.0358\n",
      "Epoch [9/10], Step[7101/60000], Loss: 0.0071\n",
      "Epoch [9/10], Step[7201/60000], Loss: 0.0482\n",
      "Epoch [9/10], Step[7301/60000], Loss: 0.0150\n",
      "Epoch [9/10], Step[7401/60000], Loss: 0.0088\n",
      "Epoch [9/10], Step[7501/60000], Loss: 0.0116\n",
      "Epoch [9/10], Step[7601/60000], Loss: 0.0186\n",
      "Epoch [9/10], Step[7701/60000], Loss: 0.0078\n",
      "Epoch [9/10], Step[7801/60000], Loss: 0.0269\n",
      "Epoch [9/10], Step[7901/60000], Loss: 0.0162\n",
      "Epoch [9/10], Step[8001/60000], Loss: 0.0062\n",
      "Epoch [9/10], Step[8101/60000], Loss: 0.0150\n",
      "Epoch [9/10], Step[8201/60000], Loss: 0.0629\n",
      "Epoch [9/10], Step[8301/60000], Loss: 0.0221\n",
      "Epoch [9/10], Step[8401/60000], Loss: 0.0211\n",
      "Epoch [9/10], Step[8501/60000], Loss: 0.0039\n",
      "Epoch [9/10], Step[8601/60000], Loss: 0.0095\n",
      "Epoch [9/10], Step[8701/60000], Loss: 0.2077\n",
      "Epoch [9/10], Step[8801/60000], Loss: 0.0395\n",
      "Epoch [9/10], Step[8901/60000], Loss: 0.0137\n",
      "Epoch [9/10], Step[9001/60000], Loss: 0.0401\n",
      "Epoch [9/10], Step[9101/60000], Loss: 0.0792\n",
      "Epoch [9/10], Step[9201/60000], Loss: 0.0182\n",
      "Epoch [9/10], Step[9301/60000], Loss: 0.0078\n",
      "Epoch [9/10], Step[9401/60000], Loss: 0.0181\n",
      "Epoch [9/10], Step[9501/60000], Loss: 0.0208\n",
      "Epoch [9/10], Step[9601/60000], Loss: 0.0058\n",
      "Epoch [9/10], Step[9701/60000], Loss: 0.0187\n",
      "Epoch [9/10], Step[9801/60000], Loss: 0.0038\n",
      "Epoch [9/10], Step[9901/60000], Loss: 0.0021\n",
      "Epoch [9/10], Step[10001/60000], Loss: 0.0166\n",
      "Epoch [9/10], Step[10101/60000], Loss: 0.0159\n",
      "Epoch [9/10], Step[10201/60000], Loss: 0.0501\n",
      "Epoch [9/10], Step[10301/60000], Loss: 0.0143\n",
      "Epoch [9/10], Step[10401/60000], Loss: 0.0024\n",
      "Epoch [9/10], Step[10501/60000], Loss: 0.0057\n",
      "Epoch [9/10], Step[10601/60000], Loss: 0.0021\n",
      "Epoch [9/10], Step[10701/60000], Loss: 0.0091\n",
      "Epoch [9/10], Step[10801/60000], Loss: 0.0304\n",
      "Epoch [9/10], Step[10901/60000], Loss: 0.0661\n",
      "Epoch [9/10], Step[11001/60000], Loss: 0.0036\n",
      "Epoch [9/10], Step[11101/60000], Loss: 0.0041\n",
      "Epoch [9/10], Step[11201/60000], Loss: 0.0106\n",
      "Epoch [9/10], Step[11301/60000], Loss: 0.0063\n",
      "Epoch [9/10], Step[11401/60000], Loss: 0.0063\n",
      "Epoch [9/10], Step[11501/60000], Loss: 0.0137\n",
      "Epoch [9/10], Step[11601/60000], Loss: 0.3824\n",
      "Epoch [9/10], Step[11701/60000], Loss: 0.0113\n",
      "Epoch [9/10], Step[11801/60000], Loss: 0.0120\n",
      "Epoch [9/10], Step[11901/60000], Loss: 0.0316\n",
      "Epoch [9/10], Step[12001/60000], Loss: 0.0163\n",
      "Epoch [9/10], Step[12101/60000], Loss: 0.0031\n",
      "Epoch [9/10], Step[12201/60000], Loss: 0.0197\n",
      "Epoch [9/10], Step[12301/60000], Loss: 0.0227\n",
      "Epoch [9/10], Step[12401/60000], Loss: 0.0503\n",
      "Epoch [9/10], Step[12501/60000], Loss: 0.0289\n",
      "Epoch [9/10], Step[12601/60000], Loss: 0.0434\n",
      "Epoch [9/10], Step[12701/60000], Loss: 0.0056\n",
      "Epoch [9/10], Step[12801/60000], Loss: 0.0120\n",
      "Epoch [9/10], Step[12901/60000], Loss: 0.0096\n",
      "Epoch [9/10], Step[13001/60000], Loss: 0.0383\n",
      "Epoch [9/10], Step[13101/60000], Loss: 0.0123\n",
      "Epoch [9/10], Step[13201/60000], Loss: 0.0023\n",
      "Epoch [9/10], Step[13301/60000], Loss: 0.0155\n",
      "Epoch [9/10], Step[13401/60000], Loss: 0.0110\n",
      "Epoch [9/10], Step[13501/60000], Loss: 0.0105\n",
      "Epoch [9/10], Step[13601/60000], Loss: 0.0716\n",
      "Epoch [9/10], Step[13701/60000], Loss: 0.0056\n",
      "Epoch [9/10], Step[13801/60000], Loss: 0.0150\n",
      "Epoch [9/10], Step[13901/60000], Loss: 0.0218\n",
      "Epoch [9/10], Step[14001/60000], Loss: 0.0166\n",
      "Epoch [9/10], Step[14101/60000], Loss: 0.0127\n",
      "Epoch [9/10], Step[14201/60000], Loss: 0.0099\n",
      "Epoch [9/10], Step[14301/60000], Loss: 0.0276\n",
      "Epoch [9/10], Step[14401/60000], Loss: 0.0134\n",
      "Epoch [9/10], Step[14501/60000], Loss: 0.0136\n",
      "Epoch [9/10], Step[14601/60000], Loss: 0.1082\n",
      "Epoch [9/10], Step[14701/60000], Loss: 0.0192\n",
      "Epoch [9/10], Step[14801/60000], Loss: 0.0082\n",
      "Epoch [9/10], Step[14901/60000], Loss: 0.0047\n",
      "Epoch [9/10], Step[15001/60000], Loss: 0.0138\n",
      "Epoch [9/10], Step[15101/60000], Loss: 0.1856\n",
      "Epoch [9/10], Step[15201/60000], Loss: 0.1407\n",
      "Epoch [9/10], Step[15301/60000], Loss: 0.0050\n",
      "Epoch [9/10], Step[15401/60000], Loss: 0.0081\n",
      "Epoch [9/10], Step[15501/60000], Loss: 0.0123\n",
      "Epoch [9/10], Step[15601/60000], Loss: 0.0053\n",
      "Epoch [9/10], Step[15701/60000], Loss: 0.0238\n",
      "Epoch [9/10], Step[15801/60000], Loss: 0.0221\n",
      "Epoch [9/10], Step[15901/60000], Loss: 0.0171\n",
      "Epoch [9/10], Step[16001/60000], Loss: 0.0203\n",
      "Epoch [9/10], Step[16101/60000], Loss: 0.0203\n",
      "Epoch [9/10], Step[16201/60000], Loss: 0.0102\n",
      "Epoch [9/10], Step[16301/60000], Loss: 0.0084\n",
      "Epoch [9/10], Step[16401/60000], Loss: 0.0126\n",
      "Epoch [9/10], Step[16501/60000], Loss: 0.0160\n",
      "Epoch [9/10], Step[16601/60000], Loss: 0.0209\n",
      "Epoch [9/10], Step[16701/60000], Loss: 0.0134\n",
      "Epoch [9/10], Step[16801/60000], Loss: 0.0168\n",
      "Epoch [9/10], Step[16901/60000], Loss: 0.0234\n",
      "Epoch [9/10], Step[17001/60000], Loss: 0.0172\n",
      "Epoch [9/10], Step[17101/60000], Loss: 0.0293\n",
      "Epoch [9/10], Step[17201/60000], Loss: 0.0116\n",
      "Epoch [9/10], Step[17301/60000], Loss: 0.2018\n",
      "Epoch [9/10], Step[17401/60000], Loss: 0.0261\n",
      "Epoch [9/10], Step[17501/60000], Loss: 0.0115\n",
      "Epoch [9/10], Step[17601/60000], Loss: 0.0216\n",
      "Epoch [9/10], Step[17701/60000], Loss: 0.0283\n",
      "Epoch [9/10], Step[17801/60000], Loss: 0.0117\n",
      "Epoch [9/10], Step[17901/60000], Loss: 0.0062\n",
      "Epoch [9/10], Step[18001/60000], Loss: 0.0084\n",
      "Epoch [9/10], Step[18101/60000], Loss: 0.0084\n",
      "Epoch [9/10], Step[18201/60000], Loss: 0.0096\n",
      "Epoch [9/10], Step[18301/60000], Loss: 0.0144\n",
      "Epoch [9/10], Step[18401/60000], Loss: 0.0052\n",
      "Epoch [9/10], Step[18501/60000], Loss: 0.0041\n",
      "Epoch [9/10], Step[18601/60000], Loss: 0.0028\n",
      "Epoch [9/10], Step[18701/60000], Loss: 0.0288\n",
      "Epoch [9/10], Step[18801/60000], Loss: 0.0064\n",
      "Epoch [9/10], Step[18901/60000], Loss: 0.0105\n",
      "Epoch [9/10], Step[19001/60000], Loss: 0.0197\n",
      "Epoch [9/10], Step[19101/60000], Loss: 0.0190\n",
      "Epoch [9/10], Step[19201/60000], Loss: 0.0045\n",
      "Epoch [9/10], Step[19301/60000], Loss: 0.0069\n",
      "Epoch [9/10], Step[19401/60000], Loss: 0.0228\n",
      "Epoch [9/10], Step[19501/60000], Loss: 0.0132\n",
      "Epoch [9/10], Step[19601/60000], Loss: 0.0016\n",
      "Epoch [9/10], Step[19701/60000], Loss: 0.0034\n",
      "Epoch [9/10], Step[19801/60000], Loss: 0.0169\n",
      "Epoch [9/10], Step[19901/60000], Loss: 0.0068\n",
      "Epoch [9/10], Step[20001/60000], Loss: 0.0316\n",
      "Epoch [9/10], Step[20101/60000], Loss: 0.0294\n",
      "Epoch [9/10], Step[20201/60000], Loss: 0.0185\n",
      "Epoch [9/10], Step[20301/60000], Loss: 0.0150\n",
      "Epoch [9/10], Step[20401/60000], Loss: 0.0018\n",
      "Epoch [9/10], Step[20501/60000], Loss: 0.0011\n",
      "Epoch [9/10], Step[20601/60000], Loss: 0.0141\n",
      "Epoch [9/10], Step[20701/60000], Loss: 0.0568\n",
      "Epoch [9/10], Step[20801/60000], Loss: 0.0073\n",
      "Epoch [9/10], Step[20901/60000], Loss: 0.0177\n",
      "Epoch [9/10], Step[21001/60000], Loss: 0.0214\n",
      "Epoch [9/10], Step[21101/60000], Loss: 0.0128\n",
      "Epoch [9/10], Step[21201/60000], Loss: 0.0027\n",
      "Epoch [9/10], Step[21301/60000], Loss: 0.0137\n",
      "Epoch [9/10], Step[21401/60000], Loss: 0.0167\n",
      "Epoch [9/10], Step[21501/60000], Loss: 0.0099\n",
      "Epoch [9/10], Step[21601/60000], Loss: 0.0370\n",
      "Epoch [9/10], Step[21701/60000], Loss: 0.0035\n",
      "Epoch [9/10], Step[21801/60000], Loss: 0.0054\n",
      "Epoch [9/10], Step[21901/60000], Loss: 0.0271\n",
      "Epoch [9/10], Step[22001/60000], Loss: 0.0092\n",
      "Epoch [9/10], Step[22101/60000], Loss: 0.0094\n",
      "Epoch [9/10], Step[22201/60000], Loss: 0.0081\n",
      "Epoch [9/10], Step[22301/60000], Loss: 0.0056\n",
      "Epoch [9/10], Step[22401/60000], Loss: 0.0201\n",
      "Epoch [9/10], Step[22501/60000], Loss: 0.1947\n",
      "Epoch [9/10], Step[22601/60000], Loss: 0.0041\n",
      "Epoch [9/10], Step[22701/60000], Loss: 0.0117\n",
      "Epoch [9/10], Step[22801/60000], Loss: 0.0051\n",
      "Epoch [9/10], Step[22901/60000], Loss: 0.0035\n",
      "Epoch [9/10], Step[23001/60000], Loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step[23101/60000], Loss: 0.0163\n",
      "Epoch [9/10], Step[23201/60000], Loss: 0.1489\n",
      "Epoch [9/10], Step[23301/60000], Loss: 0.0345\n",
      "Epoch [9/10], Step[23401/60000], Loss: 0.0034\n",
      "Epoch [9/10], Step[23501/60000], Loss: 0.0346\n",
      "Epoch [9/10], Step[23601/60000], Loss: 0.0076\n",
      "Epoch [9/10], Step[23701/60000], Loss: 0.0336\n",
      "Epoch [9/10], Step[23801/60000], Loss: 0.0413\n",
      "Epoch [9/10], Step[23901/60000], Loss: 0.0364\n",
      "Epoch [9/10], Step[24001/60000], Loss: 0.0451\n",
      "Epoch [9/10], Step[24101/60000], Loss: 0.0088\n",
      "Epoch [9/10], Step[24201/60000], Loss: 0.0146\n",
      "Epoch [9/10], Step[24301/60000], Loss: 0.0122\n",
      "Epoch [9/10], Step[24401/60000], Loss: 0.0038\n",
      "Epoch [9/10], Step[24501/60000], Loss: 0.0161\n",
      "Epoch [9/10], Step[24601/60000], Loss: 0.0101\n",
      "Epoch [9/10], Step[24701/60000], Loss: 0.0075\n",
      "Epoch [9/10], Step[24801/60000], Loss: 0.0093\n",
      "Epoch [9/10], Step[24901/60000], Loss: 0.0083\n",
      "Epoch [9/10], Step[25001/60000], Loss: 0.0073\n",
      "Epoch [9/10], Step[25101/60000], Loss: 0.0139\n",
      "Epoch [9/10], Step[25201/60000], Loss: 0.0105\n",
      "Epoch [9/10], Step[25301/60000], Loss: 0.0119\n",
      "Epoch [9/10], Step[25401/60000], Loss: 0.0134\n",
      "Epoch [9/10], Step[25501/60000], Loss: 0.0194\n",
      "Epoch [9/10], Step[25601/60000], Loss: 0.0040\n",
      "Epoch [9/10], Step[25701/60000], Loss: 0.0220\n",
      "Epoch [9/10], Step[25801/60000], Loss: 0.0147\n",
      "Epoch [9/10], Step[25901/60000], Loss: 0.0050\n",
      "Epoch [9/10], Step[26001/60000], Loss: 0.0091\n",
      "Epoch [9/10], Step[26101/60000], Loss: 0.2415\n",
      "Epoch [9/10], Step[26201/60000], Loss: 0.0165\n",
      "Epoch [9/10], Step[26301/60000], Loss: 0.0122\n",
      "Epoch [9/10], Step[26401/60000], Loss: 0.0283\n",
      "Epoch [9/10], Step[26501/60000], Loss: 0.0717\n",
      "Epoch [9/10], Step[26601/60000], Loss: 0.0274\n",
      "Epoch [9/10], Step[26701/60000], Loss: 0.0235\n",
      "Epoch [9/10], Step[26801/60000], Loss: 0.0227\n",
      "Epoch [9/10], Step[26901/60000], Loss: 0.0072\n",
      "Epoch [9/10], Step[27001/60000], Loss: 0.0073\n",
      "Epoch [9/10], Step[27101/60000], Loss: 0.0284\n",
      "Epoch [9/10], Step[27201/60000], Loss: 0.0702\n",
      "Epoch [9/10], Step[27301/60000], Loss: 0.0039\n",
      "Epoch [9/10], Step[27401/60000], Loss: 0.0136\n",
      "Epoch [9/10], Step[27501/60000], Loss: 0.0141\n",
      "Epoch [9/10], Step[27601/60000], Loss: 0.0134\n",
      "Epoch [9/10], Step[27701/60000], Loss: 0.0146\n",
      "Epoch [9/10], Step[27801/60000], Loss: 0.0390\n",
      "Epoch [9/10], Step[27901/60000], Loss: 0.0035\n",
      "Epoch [9/10], Step[28001/60000], Loss: 0.0037\n",
      "Epoch [9/10], Step[28101/60000], Loss: 0.0101\n",
      "Epoch [9/10], Step[28201/60000], Loss: 0.0057\n",
      "Epoch [9/10], Step[28301/60000], Loss: 0.0410\n",
      "Epoch [9/10], Step[28401/60000], Loss: 0.0093\n",
      "Epoch [9/10], Step[28501/60000], Loss: 0.0068\n",
      "Epoch [9/10], Step[28601/60000], Loss: 0.0097\n",
      "Epoch [9/10], Step[28701/60000], Loss: 0.0083\n",
      "Epoch [9/10], Step[28801/60000], Loss: 0.0019\n",
      "Epoch [9/10], Step[28901/60000], Loss: 0.0130\n",
      "Epoch [9/10], Step[29001/60000], Loss: 0.0228\n",
      "Epoch [9/10], Step[29101/60000], Loss: 0.0082\n",
      "Epoch [9/10], Step[29201/60000], Loss: 0.0145\n",
      "Epoch [9/10], Step[29301/60000], Loss: 0.0093\n",
      "Epoch [9/10], Step[29401/60000], Loss: 0.0106\n",
      "Epoch [9/10], Step[29501/60000], Loss: 0.0022\n",
      "Epoch [9/10], Step[29601/60000], Loss: 0.0071\n",
      "Epoch [9/10], Step[29701/60000], Loss: 0.0137\n",
      "Epoch [9/10], Step[29801/60000], Loss: 0.0168\n",
      "Epoch [9/10], Step[29901/60000], Loss: 0.0164\n",
      "Epoch [9/10], Step[30001/60000], Loss: 0.0104\n",
      "Epoch [9/10], Step[30101/60000], Loss: 0.0108\n",
      "Epoch [9/10], Step[30201/60000], Loss: 0.0029\n",
      "Epoch [9/10], Step[30301/60000], Loss: 0.0094\n",
      "Epoch [9/10], Step[30401/60000], Loss: 0.0065\n",
      "Epoch [9/10], Step[30501/60000], Loss: 0.0544\n",
      "Epoch [9/10], Step[30601/60000], Loss: 0.0154\n",
      "Epoch [9/10], Step[30701/60000], Loss: 0.0191\n",
      "Epoch [9/10], Step[30801/60000], Loss: 0.0047\n",
      "Epoch [9/10], Step[30901/60000], Loss: 0.0142\n",
      "Epoch [9/10], Step[31001/60000], Loss: 0.0080\n",
      "Epoch [9/10], Step[31101/60000], Loss: 0.0349\n",
      "Epoch [9/10], Step[31201/60000], Loss: 0.0041\n",
      "Epoch [9/10], Step[31301/60000], Loss: 0.0142\n",
      "Epoch [9/10], Step[31401/60000], Loss: 0.0134\n",
      "Epoch [9/10], Step[31501/60000], Loss: 0.0310\n",
      "Epoch [9/10], Step[31601/60000], Loss: 0.6196\n",
      "Epoch [9/10], Step[31701/60000], Loss: 0.0306\n",
      "Epoch [9/10], Step[31801/60000], Loss: 0.1042\n",
      "Epoch [9/10], Step[31901/60000], Loss: 0.0079\n",
      "Epoch [9/10], Step[32001/60000], Loss: 0.0059\n",
      "Epoch [9/10], Step[32101/60000], Loss: 0.0115\n",
      "Epoch [9/10], Step[32201/60000], Loss: 0.0573\n",
      "Epoch [9/10], Step[32301/60000], Loss: 0.8176\n",
      "Epoch [9/10], Step[32401/60000], Loss: 0.0371\n",
      "Epoch [9/10], Step[32501/60000], Loss: 0.0249\n",
      "Epoch [9/10], Step[32601/60000], Loss: 0.0132\n",
      "Epoch [9/10], Step[32701/60000], Loss: 0.0390\n",
      "Epoch [9/10], Step[32801/60000], Loss: 0.0168\n",
      "Epoch [9/10], Step[32901/60000], Loss: 0.0094\n",
      "Epoch [9/10], Step[33001/60000], Loss: 0.0207\n",
      "Epoch [9/10], Step[33101/60000], Loss: 0.0181\n",
      "Epoch [9/10], Step[33201/60000], Loss: 0.0077\n",
      "Epoch [9/10], Step[33301/60000], Loss: 0.0196\n",
      "Epoch [9/10], Step[33401/60000], Loss: 0.0130\n",
      "Epoch [9/10], Step[33501/60000], Loss: 0.0156\n",
      "Epoch [9/10], Step[33601/60000], Loss: 0.0101\n",
      "Epoch [9/10], Step[33701/60000], Loss: 0.1308\n",
      "Epoch [9/10], Step[33801/60000], Loss: 0.0026\n",
      "Epoch [9/10], Step[33901/60000], Loss: 0.0064\n",
      "Epoch [9/10], Step[34001/60000], Loss: 0.0197\n",
      "Epoch [9/10], Step[34101/60000], Loss: 0.0052\n",
      "Epoch [9/10], Step[34201/60000], Loss: 0.0010\n",
      "Epoch [9/10], Step[34301/60000], Loss: 0.0084\n",
      "Epoch [9/10], Step[34401/60000], Loss: 0.0488\n",
      "Epoch [9/10], Step[34501/60000], Loss: 0.0309\n",
      "Epoch [9/10], Step[34601/60000], Loss: 0.0178\n",
      "Epoch [9/10], Step[34701/60000], Loss: 0.2063\n",
      "Epoch [9/10], Step[34801/60000], Loss: 0.0127\n",
      "Epoch [9/10], Step[34901/60000], Loss: 0.0070\n",
      "Epoch [9/10], Step[35001/60000], Loss: 0.0209\n",
      "Epoch [9/10], Step[35101/60000], Loss: 0.0076\n",
      "Epoch [9/10], Step[35201/60000], Loss: 0.0206\n",
      "Epoch [9/10], Step[35301/60000], Loss: 0.0244\n",
      "Epoch [9/10], Step[35401/60000], Loss: 0.0602\n",
      "Epoch [9/10], Step[35501/60000], Loss: 0.0049\n",
      "Epoch [9/10], Step[35601/60000], Loss: 0.0525\n",
      "Epoch [9/10], Step[35701/60000], Loss: 0.0037\n",
      "Epoch [9/10], Step[35801/60000], Loss: 0.0064\n",
      "Epoch [9/10], Step[35901/60000], Loss: 0.0133\n",
      "Epoch [9/10], Step[36001/60000], Loss: 0.0129\n",
      "Epoch [9/10], Step[36101/60000], Loss: 0.0923\n",
      "Epoch [9/10], Step[36201/60000], Loss: 0.0199\n",
      "Epoch [9/10], Step[36301/60000], Loss: 0.0043\n",
      "Epoch [9/10], Step[36401/60000], Loss: 0.0384\n",
      "Epoch [9/10], Step[36501/60000], Loss: 0.0087\n",
      "Epoch [9/10], Step[36601/60000], Loss: 0.0034\n",
      "Epoch [9/10], Step[36701/60000], Loss: 0.0156\n",
      "Epoch [9/10], Step[36801/60000], Loss: 0.0055\n",
      "Epoch [9/10], Step[36901/60000], Loss: 0.0233\n",
      "Epoch [9/10], Step[37001/60000], Loss: 0.0178\n",
      "Epoch [9/10], Step[37101/60000], Loss: 0.0172\n",
      "Epoch [9/10], Step[37201/60000], Loss: 0.0835\n",
      "Epoch [9/10], Step[37301/60000], Loss: 0.0114\n",
      "Epoch [9/10], Step[37401/60000], Loss: 0.0309\n",
      "Epoch [9/10], Step[37501/60000], Loss: 0.0250\n",
      "Epoch [9/10], Step[37601/60000], Loss: 0.0035\n",
      "Epoch [9/10], Step[37701/60000], Loss: 0.2066\n",
      "Epoch [9/10], Step[37801/60000], Loss: 0.1228\n",
      "Epoch [9/10], Step[37901/60000], Loss: 0.0038\n",
      "Epoch [9/10], Step[38001/60000], Loss: 0.0045\n",
      "Epoch [9/10], Step[38101/60000], Loss: 0.0027\n",
      "Epoch [9/10], Step[38201/60000], Loss: 0.0049\n",
      "Epoch [9/10], Step[38301/60000], Loss: 0.0367\n",
      "Epoch [9/10], Step[38401/60000], Loss: 0.0012\n",
      "Epoch [9/10], Step[38501/60000], Loss: 0.0117\n",
      "Epoch [9/10], Step[38601/60000], Loss: 0.0266\n",
      "Epoch [9/10], Step[38701/60000], Loss: 0.0509\n",
      "Epoch [9/10], Step[38801/60000], Loss: 0.4777\n",
      "Epoch [9/10], Step[38901/60000], Loss: 0.0064\n",
      "Epoch [9/10], Step[39001/60000], Loss: 0.0097\n",
      "Epoch [9/10], Step[39101/60000], Loss: 0.0119\n",
      "Epoch [9/10], Step[39201/60000], Loss: 0.0209\n",
      "Epoch [9/10], Step[39301/60000], Loss: 0.0332\n",
      "Epoch [9/10], Step[39401/60000], Loss: 0.0182\n",
      "Epoch [9/10], Step[39501/60000], Loss: 0.0046\n",
      "Epoch [9/10], Step[39601/60000], Loss: 0.0295\n",
      "Epoch [9/10], Step[39701/60000], Loss: 0.0088\n",
      "Epoch [9/10], Step[39801/60000], Loss: 0.0150\n",
      "Epoch [9/10], Step[39901/60000], Loss: 0.0114\n",
      "Epoch [9/10], Step[40001/60000], Loss: 0.0120\n",
      "Epoch [9/10], Step[40101/60000], Loss: 0.0166\n",
      "Epoch [9/10], Step[40201/60000], Loss: 0.0124\n",
      "Epoch [9/10], Step[40301/60000], Loss: 0.0055\n",
      "Epoch [9/10], Step[40401/60000], Loss: 0.0023\n",
      "Epoch [9/10], Step[40501/60000], Loss: 0.0020\n",
      "Epoch [9/10], Step[40601/60000], Loss: 0.0179\n",
      "Epoch [9/10], Step[40701/60000], Loss: 0.0049\n",
      "Epoch [9/10], Step[40801/60000], Loss: 0.0127\n",
      "Epoch [9/10], Step[40901/60000], Loss: 0.0114\n",
      "Epoch [9/10], Step[41001/60000], Loss: 0.0968\n",
      "Epoch [9/10], Step[41101/60000], Loss: 0.0067\n",
      "Epoch [9/10], Step[41201/60000], Loss: 0.0303\n",
      "Epoch [9/10], Step[41301/60000], Loss: 0.0360\n",
      "Epoch [9/10], Step[41401/60000], Loss: 0.3041\n",
      "Epoch [9/10], Step[41501/60000], Loss: 0.0332\n",
      "Epoch [9/10], Step[41601/60000], Loss: 0.0138\n",
      "Epoch [9/10], Step[41701/60000], Loss: 0.0043\n",
      "Epoch [9/10], Step[41801/60000], Loss: 0.0185\n",
      "Epoch [9/10], Step[41901/60000], Loss: 0.0387\n",
      "Epoch [9/10], Step[42001/60000], Loss: 0.0116\n",
      "Epoch [9/10], Step[42101/60000], Loss: 0.0121\n",
      "Epoch [9/10], Step[42201/60000], Loss: 0.0036\n",
      "Epoch [9/10], Step[42301/60000], Loss: 0.0133\n",
      "Epoch [9/10], Step[42401/60000], Loss: 0.0113\n",
      "Epoch [9/10], Step[42501/60000], Loss: 0.0388\n",
      "Epoch [9/10], Step[42601/60000], Loss: 0.0145\n",
      "Epoch [9/10], Step[42701/60000], Loss: 1.1186\n",
      "Epoch [9/10], Step[42801/60000], Loss: 0.0216\n",
      "Epoch [9/10], Step[42901/60000], Loss: 0.0215\n",
      "Epoch [9/10], Step[43001/60000], Loss: 0.0197\n",
      "Epoch [9/10], Step[43101/60000], Loss: 0.0314\n",
      "Epoch [9/10], Step[43201/60000], Loss: 0.0057\n",
      "Epoch [9/10], Step[43301/60000], Loss: 0.0020\n",
      "Epoch [9/10], Step[43401/60000], Loss: 0.0206\n",
      "Epoch [9/10], Step[43501/60000], Loss: 0.0122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step[43601/60000], Loss: 0.0145\n",
      "Epoch [9/10], Step[43701/60000], Loss: 0.0038\n",
      "Epoch [9/10], Step[43801/60000], Loss: 0.0123\n",
      "Epoch [9/10], Step[43901/60000], Loss: 0.0138\n",
      "Epoch [9/10], Step[44001/60000], Loss: 0.1860\n",
      "Epoch [9/10], Step[44101/60000], Loss: 0.0369\n",
      "Epoch [9/10], Step[44201/60000], Loss: 0.1058\n",
      "Epoch [9/10], Step[44301/60000], Loss: 0.0142\n",
      "Epoch [9/10], Step[44401/60000], Loss: 0.0200\n",
      "Epoch [9/10], Step[44501/60000], Loss: 0.0033\n",
      "Epoch [9/10], Step[44601/60000], Loss: 0.0083\n",
      "Epoch [9/10], Step[44701/60000], Loss: 0.0071\n",
      "Epoch [9/10], Step[44801/60000], Loss: 0.0176\n",
      "Epoch [9/10], Step[44901/60000], Loss: 0.0120\n",
      "Epoch [9/10], Step[45001/60000], Loss: 0.0129\n",
      "Epoch [9/10], Step[45101/60000], Loss: 0.0271\n",
      "Epoch [9/10], Step[45201/60000], Loss: 0.0210\n",
      "Epoch [9/10], Step[45301/60000], Loss: 0.0227\n",
      "Epoch [9/10], Step[45401/60000], Loss: 0.0080\n",
      "Epoch [9/10], Step[45501/60000], Loss: 0.0174\n",
      "Epoch [9/10], Step[45601/60000], Loss: 0.0594\n",
      "Epoch [9/10], Step[45701/60000], Loss: 0.0063\n",
      "Epoch [9/10], Step[45801/60000], Loss: 0.0126\n",
      "Epoch [9/10], Step[45901/60000], Loss: 0.0213\n",
      "Epoch [9/10], Step[46001/60000], Loss: 0.0500\n",
      "Epoch [9/10], Step[46101/60000], Loss: 0.0137\n",
      "Epoch [9/10], Step[46201/60000], Loss: 0.0305\n",
      "Epoch [9/10], Step[46301/60000], Loss: 0.0232\n",
      "Epoch [9/10], Step[46401/60000], Loss: 0.0171\n",
      "Epoch [9/10], Step[46501/60000], Loss: 0.0045\n",
      "Epoch [9/10], Step[46601/60000], Loss: 0.0113\n",
      "Epoch [9/10], Step[46701/60000], Loss: 0.0051\n",
      "Epoch [9/10], Step[46801/60000], Loss: 0.0125\n",
      "Epoch [9/10], Step[46901/60000], Loss: 0.0150\n",
      "Epoch [9/10], Step[47001/60000], Loss: 0.0143\n",
      "Epoch [9/10], Step[47101/60000], Loss: 0.0217\n",
      "Epoch [9/10], Step[47201/60000], Loss: 0.0735\n",
      "Epoch [9/10], Step[47301/60000], Loss: 0.0304\n",
      "Epoch [9/10], Step[47401/60000], Loss: 0.0229\n",
      "Epoch [9/10], Step[47501/60000], Loss: 0.0278\n",
      "Epoch [9/10], Step[47601/60000], Loss: 0.0649\n",
      "Epoch [9/10], Step[47701/60000], Loss: 0.0036\n",
      "Epoch [9/10], Step[47801/60000], Loss: 0.0223\n",
      "Epoch [9/10], Step[47901/60000], Loss: 0.0140\n",
      "Epoch [9/10], Step[48001/60000], Loss: 0.0092\n",
      "Epoch [9/10], Step[48101/60000], Loss: 0.0117\n",
      "Epoch [9/10], Step[48201/60000], Loss: 0.0049\n",
      "Epoch [9/10], Step[48301/60000], Loss: 0.0098\n",
      "Epoch [9/10], Step[48401/60000], Loss: 0.0069\n",
      "Epoch [9/10], Step[48501/60000], Loss: 0.0137\n",
      "Epoch [9/10], Step[48601/60000], Loss: 0.0117\n",
      "Epoch [9/10], Step[48701/60000], Loss: 0.0035\n",
      "Epoch [9/10], Step[48801/60000], Loss: 0.0076\n",
      "Epoch [9/10], Step[48901/60000], Loss: 0.0251\n",
      "Epoch [9/10], Step[49001/60000], Loss: 0.3830\n",
      "Epoch [9/10], Step[49101/60000], Loss: 0.0046\n",
      "Epoch [9/10], Step[49201/60000], Loss: 0.0220\n",
      "Epoch [9/10], Step[49301/60000], Loss: 0.0048\n",
      "Epoch [9/10], Step[49401/60000], Loss: 0.0173\n",
      "Epoch [9/10], Step[49501/60000], Loss: 0.1211\n",
      "Epoch [9/10], Step[49601/60000], Loss: 0.0139\n",
      "Epoch [9/10], Step[49701/60000], Loss: 0.0030\n",
      "Epoch [9/10], Step[49801/60000], Loss: 0.0286\n",
      "Epoch [9/10], Step[49901/60000], Loss: 0.0096\n",
      "Epoch [9/10], Step[50001/60000], Loss: 0.0071\n",
      "Epoch [9/10], Step[50101/60000], Loss: 0.0039\n",
      "Epoch [9/10], Step[50201/60000], Loss: 0.0110\n",
      "Epoch [9/10], Step[50301/60000], Loss: 0.0244\n",
      "Epoch [9/10], Step[50401/60000], Loss: 0.0269\n",
      "Epoch [9/10], Step[50501/60000], Loss: 0.0176\n",
      "Epoch [9/10], Step[50601/60000], Loss: 0.0101\n",
      "Epoch [9/10], Step[50701/60000], Loss: 0.0114\n",
      "Epoch [9/10], Step[50801/60000], Loss: 0.0121\n",
      "Epoch [9/10], Step[50901/60000], Loss: 0.0107\n",
      "Epoch [9/10], Step[51001/60000], Loss: 0.0033\n",
      "Epoch [9/10], Step[51101/60000], Loss: 0.0076\n",
      "Epoch [9/10], Step[51201/60000], Loss: 0.0415\n",
      "Epoch [9/10], Step[51301/60000], Loss: 0.0102\n",
      "Epoch [9/10], Step[51401/60000], Loss: 0.0082\n",
      "Epoch [9/10], Step[51501/60000], Loss: 0.0044\n",
      "Epoch [9/10], Step[51601/60000], Loss: 0.0085\n",
      "Epoch [9/10], Step[51701/60000], Loss: 0.0063\n",
      "Epoch [9/10], Step[51801/60000], Loss: 0.0065\n",
      "Epoch [9/10], Step[51901/60000], Loss: 0.0627\n",
      "Epoch [9/10], Step[52001/60000], Loss: 0.0114\n",
      "Epoch [9/10], Step[52101/60000], Loss: 0.1494\n",
      "Epoch [9/10], Step[52201/60000], Loss: 0.0179\n",
      "Epoch [9/10], Step[52301/60000], Loss: 0.0146\n",
      "Epoch [9/10], Step[52401/60000], Loss: 0.0048\n",
      "Epoch [9/10], Step[52501/60000], Loss: 0.0040\n",
      "Epoch [9/10], Step[52601/60000], Loss: 0.0053\n",
      "Epoch [9/10], Step[52701/60000], Loss: 0.0055\n",
      "Epoch [9/10], Step[52801/60000], Loss: 0.0185\n",
      "Epoch [9/10], Step[52901/60000], Loss: 0.0098\n",
      "Epoch [9/10], Step[53001/60000], Loss: 0.0119\n",
      "Epoch [9/10], Step[53101/60000], Loss: 0.0045\n",
      "Epoch [9/10], Step[53201/60000], Loss: 0.0229\n",
      "Epoch [9/10], Step[53301/60000], Loss: 0.0062\n",
      "Epoch [9/10], Step[53401/60000], Loss: 0.0077\n",
      "Epoch [9/10], Step[53501/60000], Loss: 0.0112\n",
      "Epoch [9/10], Step[53601/60000], Loss: 0.1347\n",
      "Epoch [9/10], Step[53701/60000], Loss: 0.0208\n",
      "Epoch [9/10], Step[53801/60000], Loss: 0.0049\n",
      "Epoch [9/10], Step[53901/60000], Loss: 0.5371\n",
      "Epoch [9/10], Step[54001/60000], Loss: 0.1050\n",
      "Epoch [9/10], Step[54101/60000], Loss: 0.0074\n",
      "Epoch [9/10], Step[54201/60000], Loss: 0.0138\n",
      "Epoch [9/10], Step[54301/60000], Loss: 0.0031\n",
      "Epoch [9/10], Step[54401/60000], Loss: 0.0073\n",
      "Epoch [9/10], Step[54501/60000], Loss: 0.0319\n",
      "Epoch [9/10], Step[54601/60000], Loss: 0.0959\n",
      "Epoch [9/10], Step[54701/60000], Loss: 0.0566\n",
      "Epoch [9/10], Step[54801/60000], Loss: 0.0102\n",
      "Epoch [9/10], Step[54901/60000], Loss: 0.0170\n",
      "Epoch [9/10], Step[55001/60000], Loss: 0.0069\n",
      "Epoch [9/10], Step[55101/60000], Loss: 0.0127\n",
      "Epoch [9/10], Step[55201/60000], Loss: 0.0643\n",
      "Epoch [9/10], Step[55301/60000], Loss: 0.0554\n",
      "Epoch [9/10], Step[55401/60000], Loss: 0.0270\n",
      "Epoch [9/10], Step[55501/60000], Loss: 0.0126\n",
      "Epoch [9/10], Step[55601/60000], Loss: 0.0061\n",
      "Epoch [9/10], Step[55701/60000], Loss: 0.0127\n",
      "Epoch [9/10], Step[55801/60000], Loss: 0.0065\n",
      "Epoch [9/10], Step[55901/60000], Loss: 0.0149\n",
      "Epoch [9/10], Step[56001/60000], Loss: 0.0106\n",
      "Epoch [9/10], Step[56101/60000], Loss: 0.0076\n",
      "Epoch [9/10], Step[56201/60000], Loss: 0.0450\n",
      "Epoch [9/10], Step[56301/60000], Loss: 0.0166\n",
      "Epoch [9/10], Step[56401/60000], Loss: 0.0168\n",
      "Epoch [9/10], Step[56501/60000], Loss: 0.0106\n",
      "Epoch [9/10], Step[56601/60000], Loss: 0.0093\n",
      "Epoch [9/10], Step[56701/60000], Loss: 0.0136\n",
      "Epoch [9/10], Step[56801/60000], Loss: 0.0034\n",
      "Epoch [9/10], Step[56901/60000], Loss: 0.0203\n",
      "Epoch [9/10], Step[57001/60000], Loss: 0.0114\n",
      "Epoch [9/10], Step[57101/60000], Loss: 0.0020\n",
      "Epoch [9/10], Step[57201/60000], Loss: 0.0084\n",
      "Epoch [9/10], Step[57301/60000], Loss: 0.0158\n",
      "Epoch [9/10], Step[57401/60000], Loss: 0.0127\n",
      "Epoch [9/10], Step[57501/60000], Loss: 0.0094\n",
      "Epoch [9/10], Step[57601/60000], Loss: 0.0199\n",
      "Epoch [9/10], Step[57701/60000], Loss: 0.0418\n",
      "Epoch [9/10], Step[57801/60000], Loss: 0.0104\n",
      "Epoch [9/10], Step[57901/60000], Loss: 0.0027\n",
      "Epoch [9/10], Step[58001/60000], Loss: 0.0178\n",
      "Epoch [9/10], Step[58101/60000], Loss: 0.0041\n",
      "Epoch [9/10], Step[58201/60000], Loss: 0.0027\n",
      "Epoch [9/10], Step[58301/60000], Loss: 0.0076\n",
      "Epoch [9/10], Step[58401/60000], Loss: 0.0024\n",
      "Epoch [9/10], Step[58501/60000], Loss: 0.0069\n",
      "Epoch [9/10], Step[58601/60000], Loss: 0.0161\n",
      "Epoch [9/10], Step[58701/60000], Loss: 0.0018\n",
      "Epoch [9/10], Step[58801/60000], Loss: 0.0055\n",
      "Epoch [9/10], Step[58901/60000], Loss: 0.0003\n",
      "Epoch [9/10], Step[59001/60000], Loss: 0.0013\n",
      "Epoch [9/10], Step[59101/60000], Loss: 0.0004\n",
      "Epoch [9/10], Step[59201/60000], Loss: 0.0104\n",
      "Epoch [9/10], Step[59301/60000], Loss: 0.0027\n",
      "Epoch [9/10], Step[59401/60000], Loss: 0.0022\n",
      "Epoch [9/10], Step[59501/60000], Loss: 0.0003\n",
      "Epoch [9/10], Step[59601/60000], Loss: 0.0098\n",
      "Epoch [9/10], Step[59701/60000], Loss: 0.0520\n",
      "Epoch [9/10], Step[59801/60000], Loss: 0.0004\n",
      "Epoch [9/10], Step[59901/60000], Loss: 0.4410\n",
      "Epoch [10/10], Step[1/60000], Loss: 0.0055\n",
      "Epoch [10/10], Step[101/60000], Loss: 0.0703\n",
      "Epoch [10/10], Step[201/60000], Loss: 0.0082\n",
      "Epoch [10/10], Step[301/60000], Loss: 0.0024\n",
      "Epoch [10/10], Step[401/60000], Loss: 0.0354\n",
      "Epoch [10/10], Step[501/60000], Loss: 0.0816\n",
      "Epoch [10/10], Step[601/60000], Loss: 0.1097\n",
      "Epoch [10/10], Step[701/60000], Loss: 0.0111\n",
      "Epoch [10/10], Step[801/60000], Loss: 0.0083\n",
      "Epoch [10/10], Step[901/60000], Loss: 0.0061\n",
      "Epoch [10/10], Step[1001/60000], Loss: 0.0274\n",
      "Epoch [10/10], Step[1101/60000], Loss: 0.0073\n",
      "Epoch [10/10], Step[1201/60000], Loss: 0.0225\n",
      "Epoch [10/10], Step[1301/60000], Loss: 0.0134\n",
      "Epoch [10/10], Step[1401/60000], Loss: 0.0118\n",
      "Epoch [10/10], Step[1501/60000], Loss: 0.0111\n",
      "Epoch [10/10], Step[1601/60000], Loss: 0.0041\n",
      "Epoch [10/10], Step[1701/60000], Loss: 0.0046\n",
      "Epoch [10/10], Step[1801/60000], Loss: 0.0042\n",
      "Epoch [10/10], Step[1901/60000], Loss: 0.0058\n",
      "Epoch [10/10], Step[2001/60000], Loss: 0.0074\n",
      "Epoch [10/10], Step[2101/60000], Loss: 0.0978\n",
      "Epoch [10/10], Step[2201/60000], Loss: 0.0063\n",
      "Epoch [10/10], Step[2301/60000], Loss: 0.0046\n",
      "Epoch [10/10], Step[2401/60000], Loss: 0.0056\n",
      "Epoch [10/10], Step[2501/60000], Loss: 0.0037\n",
      "Epoch [10/10], Step[2601/60000], Loss: 0.0057\n",
      "Epoch [10/10], Step[2701/60000], Loss: 0.0239\n",
      "Epoch [10/10], Step[2801/60000], Loss: 0.0182\n",
      "Epoch [10/10], Step[2901/60000], Loss: 0.0085\n",
      "Epoch [10/10], Step[3001/60000], Loss: 0.0055\n",
      "Epoch [10/10], Step[3101/60000], Loss: 0.0010\n",
      "Epoch [10/10], Step[3201/60000], Loss: 0.5390\n",
      "Epoch [10/10], Step[3301/60000], Loss: 0.0054\n",
      "Epoch [10/10], Step[3401/60000], Loss: 0.0041\n",
      "Epoch [10/10], Step[3501/60000], Loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step[3601/60000], Loss: 0.0165\n",
      "Epoch [10/10], Step[3701/60000], Loss: 0.0028\n",
      "Epoch [10/10], Step[3801/60000], Loss: 0.0336\n",
      "Epoch [10/10], Step[3901/60000], Loss: 0.0020\n",
      "Epoch [10/10], Step[4001/60000], Loss: 0.0070\n",
      "Epoch [10/10], Step[4101/60000], Loss: 0.1523\n",
      "Epoch [10/10], Step[4201/60000], Loss: 0.0046\n",
      "Epoch [10/10], Step[4301/60000], Loss: 0.0084\n",
      "Epoch [10/10], Step[4401/60000], Loss: 0.0430\n",
      "Epoch [10/10], Step[4501/60000], Loss: 0.0032\n",
      "Epoch [10/10], Step[4601/60000], Loss: 0.0197\n",
      "Epoch [10/10], Step[4701/60000], Loss: 0.0029\n",
      "Epoch [10/10], Step[4801/60000], Loss: 0.0024\n",
      "Epoch [10/10], Step[4901/60000], Loss: 0.0147\n",
      "Epoch [10/10], Step[5001/60000], Loss: 0.0114\n",
      "Epoch [10/10], Step[5101/60000], Loss: 0.0411\n",
      "Epoch [10/10], Step[5201/60000], Loss: 0.0064\n",
      "Epoch [10/10], Step[5301/60000], Loss: 0.0145\n",
      "Epoch [10/10], Step[5401/60000], Loss: 0.0078\n",
      "Epoch [10/10], Step[5501/60000], Loss: 0.0093\n",
      "Epoch [10/10], Step[5601/60000], Loss: 0.0124\n",
      "Epoch [10/10], Step[5701/60000], Loss: 0.0187\n",
      "Epoch [10/10], Step[5801/60000], Loss: 0.0341\n",
      "Epoch [10/10], Step[5901/60000], Loss: 0.0159\n",
      "Epoch [10/10], Step[6001/60000], Loss: 0.0177\n",
      "Epoch [10/10], Step[6101/60000], Loss: 0.0080\n",
      "Epoch [10/10], Step[6201/60000], Loss: 0.0379\n",
      "Epoch [10/10], Step[6301/60000], Loss: 0.0087\n",
      "Epoch [10/10], Step[6401/60000], Loss: 0.0125\n",
      "Epoch [10/10], Step[6501/60000], Loss: 0.0006\n",
      "Epoch [10/10], Step[6601/60000], Loss: 0.0095\n",
      "Epoch [10/10], Step[6701/60000], Loss: 0.0064\n",
      "Epoch [10/10], Step[6801/60000], Loss: 0.0680\n",
      "Epoch [10/10], Step[6901/60000], Loss: 0.0122\n",
      "Epoch [10/10], Step[7001/60000], Loss: 0.0264\n",
      "Epoch [10/10], Step[7101/60000], Loss: 0.0026\n",
      "Epoch [10/10], Step[7201/60000], Loss: 0.0431\n",
      "Epoch [10/10], Step[7301/60000], Loss: 0.0295\n",
      "Epoch [10/10], Step[7401/60000], Loss: 0.0097\n",
      "Epoch [10/10], Step[7501/60000], Loss: 0.0110\n",
      "Epoch [10/10], Step[7601/60000], Loss: 0.0168\n",
      "Epoch [10/10], Step[7701/60000], Loss: 0.0121\n",
      "Epoch [10/10], Step[7801/60000], Loss: 0.0153\n",
      "Epoch [10/10], Step[7901/60000], Loss: 0.0149\n",
      "Epoch [10/10], Step[8001/60000], Loss: 0.0083\n",
      "Epoch [10/10], Step[8101/60000], Loss: 0.0405\n",
      "Epoch [10/10], Step[8201/60000], Loss: 0.0417\n",
      "Epoch [10/10], Step[8301/60000], Loss: 0.0177\n",
      "Epoch [10/10], Step[8401/60000], Loss: 0.0071\n",
      "Epoch [10/10], Step[8501/60000], Loss: 0.0033\n",
      "Epoch [10/10], Step[8601/60000], Loss: 0.0066\n",
      "Epoch [10/10], Step[8701/60000], Loss: 0.0076\n",
      "Epoch [10/10], Step[8801/60000], Loss: 0.0209\n",
      "Epoch [10/10], Step[8901/60000], Loss: 0.0112\n",
      "Epoch [10/10], Step[9001/60000], Loss: 0.0194\n",
      "Epoch [10/10], Step[9101/60000], Loss: 0.0071\n",
      "Epoch [10/10], Step[9201/60000], Loss: 0.0148\n",
      "Epoch [10/10], Step[9301/60000], Loss: 0.0052\n",
      "Epoch [10/10], Step[9401/60000], Loss: 0.0037\n",
      "Epoch [10/10], Step[9501/60000], Loss: 0.0188\n",
      "Epoch [10/10], Step[9601/60000], Loss: 0.0062\n",
      "Epoch [10/10], Step[9701/60000], Loss: 0.0048\n",
      "Epoch [10/10], Step[9801/60000], Loss: 0.0043\n",
      "Epoch [10/10], Step[9901/60000], Loss: 0.0037\n",
      "Epoch [10/10], Step[10001/60000], Loss: 0.0217\n",
      "Epoch [10/10], Step[10101/60000], Loss: 0.0086\n",
      "Epoch [10/10], Step[10201/60000], Loss: 0.0261\n",
      "Epoch [10/10], Step[10301/60000], Loss: 0.0061\n",
      "Epoch [10/10], Step[10401/60000], Loss: 0.0031\n",
      "Epoch [10/10], Step[10501/60000], Loss: 0.0037\n",
      "Epoch [10/10], Step[10601/60000], Loss: 0.0016\n",
      "Epoch [10/10], Step[10701/60000], Loss: 0.0108\n",
      "Epoch [10/10], Step[10801/60000], Loss: 0.0072\n",
      "Epoch [10/10], Step[10901/60000], Loss: 0.0547\n",
      "Epoch [10/10], Step[11001/60000], Loss: 0.0047\n",
      "Epoch [10/10], Step[11101/60000], Loss: 0.0026\n",
      "Epoch [10/10], Step[11201/60000], Loss: 0.0130\n",
      "Epoch [10/10], Step[11301/60000], Loss: 0.0044\n",
      "Epoch [10/10], Step[11401/60000], Loss: 0.0098\n",
      "Epoch [10/10], Step[11501/60000], Loss: 0.0071\n",
      "Epoch [10/10], Step[11601/60000], Loss: 0.0915\n",
      "Epoch [10/10], Step[11701/60000], Loss: 0.0107\n",
      "Epoch [10/10], Step[11801/60000], Loss: 0.0072\n",
      "Epoch [10/10], Step[11901/60000], Loss: 0.0247\n",
      "Epoch [10/10], Step[12001/60000], Loss: 0.0099\n",
      "Epoch [10/10], Step[12101/60000], Loss: 0.0035\n",
      "Epoch [10/10], Step[12201/60000], Loss: 0.0217\n",
      "Epoch [10/10], Step[12301/60000], Loss: 0.0040\n",
      "Epoch [10/10], Step[12401/60000], Loss: 0.2652\n",
      "Epoch [10/10], Step[12501/60000], Loss: 0.0176\n",
      "Epoch [10/10], Step[12601/60000], Loss: 0.0107\n",
      "Epoch [10/10], Step[12701/60000], Loss: 0.0075\n",
      "Epoch [10/10], Step[12801/60000], Loss: 0.0171\n",
      "Epoch [10/10], Step[12901/60000], Loss: 0.0109\n",
      "Epoch [10/10], Step[13001/60000], Loss: 0.0137\n",
      "Epoch [10/10], Step[13101/60000], Loss: 0.0084\n",
      "Epoch [10/10], Step[13201/60000], Loss: 0.0034\n",
      "Epoch [10/10], Step[13301/60000], Loss: 0.0111\n",
      "Epoch [10/10], Step[13401/60000], Loss: 0.0032\n",
      "Epoch [10/10], Step[13501/60000], Loss: 0.0036\n",
      "Epoch [10/10], Step[13601/60000], Loss: 0.0078\n",
      "Epoch [10/10], Step[13701/60000], Loss: 0.0135\n",
      "Epoch [10/10], Step[13801/60000], Loss: 0.0114\n",
      "Epoch [10/10], Step[13901/60000], Loss: 0.0095\n",
      "Epoch [10/10], Step[14001/60000], Loss: 0.0124\n",
      "Epoch [10/10], Step[14101/60000], Loss: 0.0162\n",
      "Epoch [10/10], Step[14201/60000], Loss: 0.0061\n",
      "Epoch [10/10], Step[14301/60000], Loss: 0.0104\n",
      "Epoch [10/10], Step[14401/60000], Loss: 0.0144\n",
      "Epoch [10/10], Step[14501/60000], Loss: 0.0066\n",
      "Epoch [10/10], Step[14601/60000], Loss: 0.0079\n",
      "Epoch [10/10], Step[14701/60000], Loss: 0.0177\n",
      "Epoch [10/10], Step[14801/60000], Loss: 0.0057\n",
      "Epoch [10/10], Step[14901/60000], Loss: 0.0023\n",
      "Epoch [10/10], Step[15001/60000], Loss: 0.0080\n",
      "Epoch [10/10], Step[15101/60000], Loss: 0.2717\n",
      "Epoch [10/10], Step[15201/60000], Loss: 0.3957\n",
      "Epoch [10/10], Step[15301/60000], Loss: 0.0071\n",
      "Epoch [10/10], Step[15401/60000], Loss: 0.0111\n",
      "Epoch [10/10], Step[15501/60000], Loss: 0.0074\n",
      "Epoch [10/10], Step[15601/60000], Loss: 0.0051\n",
      "Epoch [10/10], Step[15701/60000], Loss: 0.0376\n",
      "Epoch [10/10], Step[15801/60000], Loss: 0.0173\n",
      "Epoch [10/10], Step[15901/60000], Loss: 0.0091\n",
      "Epoch [10/10], Step[16001/60000], Loss: 0.0172\n",
      "Epoch [10/10], Step[16101/60000], Loss: 0.0149\n",
      "Epoch [10/10], Step[16201/60000], Loss: 0.0038\n",
      "Epoch [10/10], Step[16301/60000], Loss: 0.0032\n",
      "Epoch [10/10], Step[16401/60000], Loss: 0.0170\n",
      "Epoch [10/10], Step[16501/60000], Loss: 0.0072\n",
      "Epoch [10/10], Step[16601/60000], Loss: 0.0160\n",
      "Epoch [10/10], Step[16701/60000], Loss: 0.0163\n",
      "Epoch [10/10], Step[16801/60000], Loss: 0.0019\n",
      "Epoch [10/10], Step[16901/60000], Loss: 0.0118\n",
      "Epoch [10/10], Step[17001/60000], Loss: 0.0132\n",
      "Epoch [10/10], Step[17101/60000], Loss: 0.0194\n",
      "Epoch [10/10], Step[17201/60000], Loss: 0.0621\n",
      "Epoch [10/10], Step[17301/60000], Loss: 0.3381\n",
      "Epoch [10/10], Step[17401/60000], Loss: 0.0118\n",
      "Epoch [10/10], Step[17501/60000], Loss: 0.0080\n",
      "Epoch [10/10], Step[17601/60000], Loss: 0.0040\n",
      "Epoch [10/10], Step[17701/60000], Loss: 0.0263\n",
      "Epoch [10/10], Step[17801/60000], Loss: 0.0334\n",
      "Epoch [10/10], Step[17901/60000], Loss: 0.0067\n",
      "Epoch [10/10], Step[18001/60000], Loss: 0.0119\n",
      "Epoch [10/10], Step[18101/60000], Loss: 0.0140\n",
      "Epoch [10/10], Step[18201/60000], Loss: 0.0085\n",
      "Epoch [10/10], Step[18301/60000], Loss: 0.0078\n",
      "Epoch [10/10], Step[18401/60000], Loss: 0.0056\n",
      "Epoch [10/10], Step[18501/60000], Loss: 0.0083\n",
      "Epoch [10/10], Step[18601/60000], Loss: 0.0069\n",
      "Epoch [10/10], Step[18701/60000], Loss: 0.0168\n",
      "Epoch [10/10], Step[18801/60000], Loss: 0.0038\n",
      "Epoch [10/10], Step[18901/60000], Loss: 0.0022\n",
      "Epoch [10/10], Step[19001/60000], Loss: 0.0281\n",
      "Epoch [10/10], Step[19101/60000], Loss: 0.0174\n",
      "Epoch [10/10], Step[19201/60000], Loss: 0.0030\n",
      "Epoch [10/10], Step[19301/60000], Loss: 0.0081\n",
      "Epoch [10/10], Step[19401/60000], Loss: 0.0176\n",
      "Epoch [10/10], Step[19501/60000], Loss: 0.0126\n",
      "Epoch [10/10], Step[19601/60000], Loss: 0.0019\n",
      "Epoch [10/10], Step[19701/60000], Loss: 0.0062\n",
      "Epoch [10/10], Step[19801/60000], Loss: 0.0061\n",
      "Epoch [10/10], Step[19901/60000], Loss: 0.0134\n",
      "Epoch [10/10], Step[20001/60000], Loss: 0.0179\n",
      "Epoch [10/10], Step[20101/60000], Loss: 0.0219\n",
      "Epoch [10/10], Step[20201/60000], Loss: 0.0255\n",
      "Epoch [10/10], Step[20301/60000], Loss: 0.0185\n",
      "Epoch [10/10], Step[20401/60000], Loss: 0.0023\n",
      "Epoch [10/10], Step[20501/60000], Loss: 0.0160\n",
      "Epoch [10/10], Step[20601/60000], Loss: 0.0108\n",
      "Epoch [10/10], Step[20701/60000], Loss: 0.0383\n",
      "Epoch [10/10], Step[20801/60000], Loss: 0.0050\n",
      "Epoch [10/10], Step[20901/60000], Loss: 0.0117\n",
      "Epoch [10/10], Step[21001/60000], Loss: 0.0137\n",
      "Epoch [10/10], Step[21101/60000], Loss: 0.0106\n",
      "Epoch [10/10], Step[21201/60000], Loss: 0.0018\n",
      "Epoch [10/10], Step[21301/60000], Loss: 0.0076\n",
      "Epoch [10/10], Step[21401/60000], Loss: 0.0103\n",
      "Epoch [10/10], Step[21501/60000], Loss: 0.0087\n",
      "Epoch [10/10], Step[21601/60000], Loss: 0.0238\n",
      "Epoch [10/10], Step[21701/60000], Loss: 0.0063\n",
      "Epoch [10/10], Step[21801/60000], Loss: 0.0078\n",
      "Epoch [10/10], Step[21901/60000], Loss: 0.0192\n",
      "Epoch [10/10], Step[22001/60000], Loss: 0.0056\n",
      "Epoch [10/10], Step[22101/60000], Loss: 0.0079\n",
      "Epoch [10/10], Step[22201/60000], Loss: 0.0102\n",
      "Epoch [10/10], Step[22301/60000], Loss: 0.0047\n",
      "Epoch [10/10], Step[22401/60000], Loss: 0.0209\n",
      "Epoch [10/10], Step[22501/60000], Loss: 0.0243\n",
      "Epoch [10/10], Step[22601/60000], Loss: 0.0030\n",
      "Epoch [10/10], Step[22701/60000], Loss: 0.0076\n",
      "Epoch [10/10], Step[22801/60000], Loss: 0.0064\n",
      "Epoch [10/10], Step[22901/60000], Loss: 0.0029\n",
      "Epoch [10/10], Step[23001/60000], Loss: 0.0047\n",
      "Epoch [10/10], Step[23101/60000], Loss: 0.0052\n",
      "Epoch [10/10], Step[23201/60000], Loss: 0.0045\n",
      "Epoch [10/10], Step[23301/60000], Loss: 0.0036\n",
      "Epoch [10/10], Step[23401/60000], Loss: 0.0062\n",
      "Epoch [10/10], Step[23501/60000], Loss: 0.0193\n",
      "Epoch [10/10], Step[23601/60000], Loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step[23701/60000], Loss: 0.0073\n",
      "Epoch [10/10], Step[23801/60000], Loss: 0.0107\n",
      "Epoch [10/10], Step[23901/60000], Loss: 0.0087\n",
      "Epoch [10/10], Step[24001/60000], Loss: 0.0103\n",
      "Epoch [10/10], Step[24101/60000], Loss: 0.0068\n",
      "Epoch [10/10], Step[24201/60000], Loss: 0.0105\n",
      "Epoch [10/10], Step[24301/60000], Loss: 0.0053\n",
      "Epoch [10/10], Step[24401/60000], Loss: 0.0016\n",
      "Epoch [10/10], Step[24501/60000], Loss: 0.0131\n",
      "Epoch [10/10], Step[24601/60000], Loss: 0.0108\n",
      "Epoch [10/10], Step[24701/60000], Loss: 0.0085\n",
      "Epoch [10/10], Step[24801/60000], Loss: 0.0111\n",
      "Epoch [10/10], Step[24901/60000], Loss: 0.0057\n",
      "Epoch [10/10], Step[25001/60000], Loss: 0.0060\n",
      "Epoch [10/10], Step[25101/60000], Loss: 0.0110\n",
      "Epoch [10/10], Step[25201/60000], Loss: 0.0061\n",
      "Epoch [10/10], Step[25301/60000], Loss: 0.0022\n",
      "Epoch [10/10], Step[25401/60000], Loss: 0.0049\n",
      "Epoch [10/10], Step[25501/60000], Loss: 0.0251\n",
      "Epoch [10/10], Step[25601/60000], Loss: 0.0082\n",
      "Epoch [10/10], Step[25701/60000], Loss: 0.0149\n",
      "Epoch [10/10], Step[25801/60000], Loss: 0.0069\n",
      "Epoch [10/10], Step[25901/60000], Loss: 0.0044\n",
      "Epoch [10/10], Step[26001/60000], Loss: 0.0051\n",
      "Epoch [10/10], Step[26101/60000], Loss: 0.0028\n",
      "Epoch [10/10], Step[26201/60000], Loss: 0.0082\n",
      "Epoch [10/10], Step[26301/60000], Loss: 0.0127\n",
      "Epoch [10/10], Step[26401/60000], Loss: 0.0162\n",
      "Epoch [10/10], Step[26501/60000], Loss: 0.0497\n",
      "Epoch [10/10], Step[26601/60000], Loss: 0.0241\n",
      "Epoch [10/10], Step[26701/60000], Loss: 0.0224\n",
      "Epoch [10/10], Step[26801/60000], Loss: 0.0114\n",
      "Epoch [10/10], Step[26901/60000], Loss: 0.0061\n",
      "Epoch [10/10], Step[27001/60000], Loss: 0.0026\n",
      "Epoch [10/10], Step[27101/60000], Loss: 0.0121\n",
      "Epoch [10/10], Step[27201/60000], Loss: 0.0505\n",
      "Epoch [10/10], Step[27301/60000], Loss: 0.0033\n",
      "Epoch [10/10], Step[27401/60000], Loss: 0.0099\n",
      "Epoch [10/10], Step[27501/60000], Loss: 0.0184\n",
      "Epoch [10/10], Step[27601/60000], Loss: 0.0053\n",
      "Epoch [10/10], Step[27701/60000], Loss: 0.0192\n",
      "Epoch [10/10], Step[27801/60000], Loss: 0.0138\n",
      "Epoch [10/10], Step[27901/60000], Loss: 0.0035\n",
      "Epoch [10/10], Step[28001/60000], Loss: 0.0034\n",
      "Epoch [10/10], Step[28101/60000], Loss: 0.0149\n",
      "Epoch [10/10], Step[28201/60000], Loss: 0.0068\n",
      "Epoch [10/10], Step[28301/60000], Loss: 0.0301\n",
      "Epoch [10/10], Step[28401/60000], Loss: 0.0038\n",
      "Epoch [10/10], Step[28501/60000], Loss: 0.0064\n",
      "Epoch [10/10], Step[28601/60000], Loss: 0.0036\n",
      "Epoch [10/10], Step[28701/60000], Loss: 0.0114\n",
      "Epoch [10/10], Step[28801/60000], Loss: 0.0013\n",
      "Epoch [10/10], Step[28901/60000], Loss: 0.0050\n",
      "Epoch [10/10], Step[29001/60000], Loss: 0.0158\n",
      "Epoch [10/10], Step[29101/60000], Loss: 0.0036\n",
      "Epoch [10/10], Step[29201/60000], Loss: 0.0216\n",
      "Epoch [10/10], Step[29301/60000], Loss: 0.0071\n",
      "Epoch [10/10], Step[29401/60000], Loss: 0.0059\n",
      "Epoch [10/10], Step[29501/60000], Loss: 0.0075\n",
      "Epoch [10/10], Step[29601/60000], Loss: 0.0126\n",
      "Epoch [10/10], Step[29701/60000], Loss: 0.0138\n",
      "Epoch [10/10], Step[29801/60000], Loss: 0.0174\n",
      "Epoch [10/10], Step[29901/60000], Loss: 0.0077\n",
      "Epoch [10/10], Step[30001/60000], Loss: 0.0083\n",
      "Epoch [10/10], Step[30101/60000], Loss: 0.0070\n",
      "Epoch [10/10], Step[30201/60000], Loss: 0.0035\n",
      "Epoch [10/10], Step[30301/60000], Loss: 0.0052\n",
      "Epoch [10/10], Step[30401/60000], Loss: 0.0061\n",
      "Epoch [10/10], Step[30501/60000], Loss: 0.0658\n",
      "Epoch [10/10], Step[30601/60000], Loss: 0.0137\n",
      "Epoch [10/10], Step[30701/60000], Loss: 0.0091\n",
      "Epoch [10/10], Step[30801/60000], Loss: 0.0086\n",
      "Epoch [10/10], Step[30901/60000], Loss: 0.0085\n",
      "Epoch [10/10], Step[31001/60000], Loss: 0.0123\n",
      "Epoch [10/10], Step[31101/60000], Loss: 0.0319\n",
      "Epoch [10/10], Step[31201/60000], Loss: 0.0062\n",
      "Epoch [10/10], Step[31301/60000], Loss: 0.0612\n",
      "Epoch [10/10], Step[31401/60000], Loss: 0.0076\n",
      "Epoch [10/10], Step[31501/60000], Loss: 0.0215\n",
      "Epoch [10/10], Step[31601/60000], Loss: 0.3487\n",
      "Epoch [10/10], Step[31701/60000], Loss: 0.0165\n",
      "Epoch [10/10], Step[31801/60000], Loss: 0.0135\n",
      "Epoch [10/10], Step[31901/60000], Loss: 0.0069\n",
      "Epoch [10/10], Step[32001/60000], Loss: 0.0056\n",
      "Epoch [10/10], Step[32101/60000], Loss: 0.0105\n",
      "Epoch [10/10], Step[32201/60000], Loss: 0.0057\n",
      "Epoch [10/10], Step[32301/60000], Loss: 0.0041\n",
      "Epoch [10/10], Step[32401/60000], Loss: 0.0630\n",
      "Epoch [10/10], Step[32501/60000], Loss: 0.0046\n",
      "Epoch [10/10], Step[32601/60000], Loss: 0.0056\n",
      "Epoch [10/10], Step[32701/60000], Loss: 0.0059\n",
      "Epoch [10/10], Step[32801/60000], Loss: 0.0073\n",
      "Epoch [10/10], Step[32901/60000], Loss: 0.0032\n",
      "Epoch [10/10], Step[33001/60000], Loss: 0.0023\n",
      "Epoch [10/10], Step[33101/60000], Loss: 0.0021\n",
      "Epoch [10/10], Step[33201/60000], Loss: 0.0053\n",
      "Epoch [10/10], Step[33301/60000], Loss: 0.0158\n",
      "Epoch [10/10], Step[33401/60000], Loss: 0.0111\n",
      "Epoch [10/10], Step[33501/60000], Loss: 0.0117\n",
      "Epoch [10/10], Step[33601/60000], Loss: 0.0066\n",
      "Epoch [10/10], Step[33701/60000], Loss: 0.0758\n",
      "Epoch [10/10], Step[33801/60000], Loss: 0.0023\n",
      "Epoch [10/10], Step[33901/60000], Loss: 0.0032\n",
      "Epoch [10/10], Step[34001/60000], Loss: 0.0174\n",
      "Epoch [10/10], Step[34101/60000], Loss: 0.0038\n",
      "Epoch [10/10], Step[34201/60000], Loss: 0.0009\n",
      "Epoch [10/10], Step[34301/60000], Loss: 0.0045\n",
      "Epoch [10/10], Step[34401/60000], Loss: 0.0167\n",
      "Epoch [10/10], Step[34501/60000], Loss: 0.0140\n",
      "Epoch [10/10], Step[34601/60000], Loss: 0.0272\n",
      "Epoch [10/10], Step[34701/60000], Loss: 0.0151\n",
      "Epoch [10/10], Step[34801/60000], Loss: 0.0205\n",
      "Epoch [10/10], Step[34901/60000], Loss: 0.0053\n",
      "Epoch [10/10], Step[35001/60000], Loss: 0.0126\n",
      "Epoch [10/10], Step[35101/60000], Loss: 0.0013\n",
      "Epoch [10/10], Step[35201/60000], Loss: 0.0275\n",
      "Epoch [10/10], Step[35301/60000], Loss: 0.0113\n",
      "Epoch [10/10], Step[35401/60000], Loss: 0.0627\n",
      "Epoch [10/10], Step[35501/60000], Loss: 0.0052\n",
      "Epoch [10/10], Step[35601/60000], Loss: 0.0399\n",
      "Epoch [10/10], Step[35701/60000], Loss: 0.0083\n",
      "Epoch [10/10], Step[35801/60000], Loss: 0.0032\n",
      "Epoch [10/10], Step[35901/60000], Loss: 0.0074\n",
      "Epoch [10/10], Step[36001/60000], Loss: 0.0148\n",
      "Epoch [10/10], Step[36101/60000], Loss: 0.0542\n",
      "Epoch [10/10], Step[36201/60000], Loss: 0.0030\n",
      "Epoch [10/10], Step[36301/60000], Loss: 0.0046\n",
      "Epoch [10/10], Step[36401/60000], Loss: 0.0212\n",
      "Epoch [10/10], Step[36501/60000], Loss: 0.0174\n",
      "Epoch [10/10], Step[36601/60000], Loss: 0.0011\n",
      "Epoch [10/10], Step[36701/60000], Loss: 0.0104\n",
      "Epoch [10/10], Step[36801/60000], Loss: 0.0065\n",
      "Epoch [10/10], Step[36901/60000], Loss: 0.0164\n",
      "Epoch [10/10], Step[37001/60000], Loss: 0.0077\n",
      "Epoch [10/10], Step[37101/60000], Loss: 0.0122\n",
      "Epoch [10/10], Step[37201/60000], Loss: 0.0007\n",
      "Epoch [10/10], Step[37301/60000], Loss: 0.0156\n",
      "Epoch [10/10], Step[37401/60000], Loss: 0.0086\n",
      "Epoch [10/10], Step[37501/60000], Loss: 0.0139\n",
      "Epoch [10/10], Step[37601/60000], Loss: 0.0040\n",
      "Epoch [10/10], Step[37701/60000], Loss: 0.0035\n",
      "Epoch [10/10], Step[37801/60000], Loss: 0.1070\n",
      "Epoch [10/10], Step[37901/60000], Loss: 0.0033\n",
      "Epoch [10/10], Step[38001/60000], Loss: 0.0053\n",
      "Epoch [10/10], Step[38101/60000], Loss: 0.0026\n",
      "Epoch [10/10], Step[38201/60000], Loss: 0.0015\n",
      "Epoch [10/10], Step[38301/60000], Loss: 0.0230\n",
      "Epoch [10/10], Step[38401/60000], Loss: 0.0035\n",
      "Epoch [10/10], Step[38501/60000], Loss: 0.0123\n",
      "Epoch [10/10], Step[38601/60000], Loss: 0.0125\n",
      "Epoch [10/10], Step[38701/60000], Loss: 0.0342\n",
      "Epoch [10/10], Step[38801/60000], Loss: 0.0021\n",
      "Epoch [10/10], Step[38901/60000], Loss: 0.0051\n",
      "Epoch [10/10], Step[39001/60000], Loss: 0.0040\n",
      "Epoch [10/10], Step[39101/60000], Loss: 0.0050\n",
      "Epoch [10/10], Step[39201/60000], Loss: 0.1372\n",
      "Epoch [10/10], Step[39301/60000], Loss: 0.0432\n",
      "Epoch [10/10], Step[39401/60000], Loss: 0.0166\n",
      "Epoch [10/10], Step[39501/60000], Loss: 0.0065\n",
      "Epoch [10/10], Step[39601/60000], Loss: 0.0175\n",
      "Epoch [10/10], Step[39701/60000], Loss: 0.0117\n",
      "Epoch [10/10], Step[39801/60000], Loss: 0.0208\n",
      "Epoch [10/10], Step[39901/60000], Loss: 0.0021\n",
      "Epoch [10/10], Step[40001/60000], Loss: 0.0186\n",
      "Epoch [10/10], Step[40101/60000], Loss: 0.0037\n",
      "Epoch [10/10], Step[40201/60000], Loss: 0.0091\n",
      "Epoch [10/10], Step[40301/60000], Loss: 0.0017\n",
      "Epoch [10/10], Step[40401/60000], Loss: 0.0017\n",
      "Epoch [10/10], Step[40501/60000], Loss: 0.0089\n",
      "Epoch [10/10], Step[40601/60000], Loss: 0.0077\n",
      "Epoch [10/10], Step[40701/60000], Loss: 0.0059\n",
      "Epoch [10/10], Step[40801/60000], Loss: 0.0130\n",
      "Epoch [10/10], Step[40901/60000], Loss: 0.0172\n",
      "Epoch [10/10], Step[41001/60000], Loss: 0.0137\n",
      "Epoch [10/10], Step[41101/60000], Loss: 0.0059\n",
      "Epoch [10/10], Step[41201/60000], Loss: 0.0230\n",
      "Epoch [10/10], Step[41301/60000], Loss: 0.0152\n",
      "Epoch [10/10], Step[41401/60000], Loss: 0.2086\n",
      "Epoch [10/10], Step[41501/60000], Loss: 0.0272\n",
      "Epoch [10/10], Step[41601/60000], Loss: 0.0054\n",
      "Epoch [10/10], Step[41701/60000], Loss: 0.0036\n",
      "Epoch [10/10], Step[41801/60000], Loss: 0.0102\n",
      "Epoch [10/10], Step[41901/60000], Loss: 0.0378\n",
      "Epoch [10/10], Step[42001/60000], Loss: 0.0026\n",
      "Epoch [10/10], Step[42101/60000], Loss: 0.0093\n",
      "Epoch [10/10], Step[42201/60000], Loss: 0.0025\n",
      "Epoch [10/10], Step[42301/60000], Loss: 0.0050\n",
      "Epoch [10/10], Step[42401/60000], Loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step[42501/60000], Loss: 0.0151\n",
      "Epoch [10/10], Step[42601/60000], Loss: 0.0080\n",
      "Epoch [10/10], Step[42701/60000], Loss: 0.0264\n",
      "Epoch [10/10], Step[42801/60000], Loss: 0.0047\n",
      "Epoch [10/10], Step[42901/60000], Loss: 0.0071\n",
      "Epoch [10/10], Step[43001/60000], Loss: 0.0066\n",
      "Epoch [10/10], Step[43101/60000], Loss: 0.0193\n",
      "Epoch [10/10], Step[43201/60000], Loss: 0.0046\n",
      "Epoch [10/10], Step[43301/60000], Loss: 0.0023\n",
      "Epoch [10/10], Step[43401/60000], Loss: 0.0261\n",
      "Epoch [10/10], Step[43501/60000], Loss: 0.0115\n",
      "Epoch [10/10], Step[43601/60000], Loss: 0.0077\n",
      "Epoch [10/10], Step[43701/60000], Loss: 0.0038\n",
      "Epoch [10/10], Step[43801/60000], Loss: 0.0047\n",
      "Epoch [10/10], Step[43901/60000], Loss: 0.0226\n",
      "Epoch [10/10], Step[44001/60000], Loss: 0.0165\n",
      "Epoch [10/10], Step[44101/60000], Loss: 0.0058\n",
      "Epoch [10/10], Step[44201/60000], Loss: 0.0174\n",
      "Epoch [10/10], Step[44301/60000], Loss: 0.0067\n",
      "Epoch [10/10], Step[44401/60000], Loss: 0.0141\n",
      "Epoch [10/10], Step[44501/60000], Loss: 0.0029\n",
      "Epoch [10/10], Step[44601/60000], Loss: 0.0047\n",
      "Epoch [10/10], Step[44701/60000], Loss: 0.0046\n",
      "Epoch [10/10], Step[44801/60000], Loss: 0.0214\n",
      "Epoch [10/10], Step[44901/60000], Loss: 0.0040\n",
      "Epoch [10/10], Step[45001/60000], Loss: 0.0032\n",
      "Epoch [10/10], Step[45101/60000], Loss: 0.0209\n",
      "Epoch [10/10], Step[45201/60000], Loss: 0.0160\n",
      "Epoch [10/10], Step[45301/60000], Loss: 0.0303\n",
      "Epoch [10/10], Step[45401/60000], Loss: 0.0073\n",
      "Epoch [10/10], Step[45501/60000], Loss: 0.0134\n",
      "Epoch [10/10], Step[45601/60000], Loss: 0.0077\n",
      "Epoch [10/10], Step[45701/60000], Loss: 0.0038\n",
      "Epoch [10/10], Step[45801/60000], Loss: 0.0092\n",
      "Epoch [10/10], Step[45901/60000], Loss: 0.0164\n",
      "Epoch [10/10], Step[46001/60000], Loss: 0.0487\n",
      "Epoch [10/10], Step[46101/60000], Loss: 0.0060\n",
      "Epoch [10/10], Step[46201/60000], Loss: 0.0416\n",
      "Epoch [10/10], Step[46301/60000], Loss: 0.0059\n",
      "Epoch [10/10], Step[46401/60000], Loss: 0.0064\n",
      "Epoch [10/10], Step[46501/60000], Loss: 0.0066\n",
      "Epoch [10/10], Step[46601/60000], Loss: 0.0011\n",
      "Epoch [10/10], Step[46701/60000], Loss: 0.0056\n",
      "Epoch [10/10], Step[46801/60000], Loss: 0.0248\n",
      "Epoch [10/10], Step[46901/60000], Loss: 0.0066\n",
      "Epoch [10/10], Step[47001/60000], Loss: 0.0069\n",
      "Epoch [10/10], Step[47101/60000], Loss: 0.0016\n",
      "Epoch [10/10], Step[47201/60000], Loss: 0.0503\n",
      "Epoch [10/10], Step[47301/60000], Loss: 0.0123\n",
      "Epoch [10/10], Step[47401/60000], Loss: 0.0095\n",
      "Epoch [10/10], Step[47501/60000], Loss: 0.0061\n",
      "Epoch [10/10], Step[47601/60000], Loss: 0.0455\n",
      "Epoch [10/10], Step[47701/60000], Loss: 0.0023\n",
      "Epoch [10/10], Step[47801/60000], Loss: 0.0040\n",
      "Epoch [10/10], Step[47901/60000], Loss: 0.0139\n",
      "Epoch [10/10], Step[48001/60000], Loss: 0.0073\n",
      "Epoch [10/10], Step[48101/60000], Loss: 0.0053\n",
      "Epoch [10/10], Step[48201/60000], Loss: 0.0019\n",
      "Epoch [10/10], Step[48301/60000], Loss: 0.0135\n",
      "Epoch [10/10], Step[48401/60000], Loss: 0.0094\n",
      "Epoch [10/10], Step[48501/60000], Loss: 0.0305\n",
      "Epoch [10/10], Step[48601/60000], Loss: 0.0064\n",
      "Epoch [10/10], Step[48701/60000], Loss: 0.0027\n",
      "Epoch [10/10], Step[48801/60000], Loss: 0.0033\n",
      "Epoch [10/10], Step[48901/60000], Loss: 0.0302\n",
      "Epoch [10/10], Step[49001/60000], Loss: 0.3956\n",
      "Epoch [10/10], Step[49101/60000], Loss: 0.0054\n",
      "Epoch [10/10], Step[49201/60000], Loss: 0.0099\n",
      "Epoch [10/10], Step[49301/60000], Loss: 0.0032\n",
      "Epoch [10/10], Step[49401/60000], Loss: 0.0127\n",
      "Epoch [10/10], Step[49501/60000], Loss: 0.0263\n",
      "Epoch [10/10], Step[49601/60000], Loss: 0.0123\n",
      "Epoch [10/10], Step[49701/60000], Loss: 0.0110\n",
      "Epoch [10/10], Step[49801/60000], Loss: 0.0187\n",
      "Epoch [10/10], Step[49901/60000], Loss: 0.0082\n",
      "Epoch [10/10], Step[50001/60000], Loss: 0.0047\n",
      "Epoch [10/10], Step[50101/60000], Loss: 0.0054\n",
      "Epoch [10/10], Step[50201/60000], Loss: 0.0062\n",
      "Epoch [10/10], Step[50301/60000], Loss: 0.0122\n",
      "Epoch [10/10], Step[50401/60000], Loss: 0.0179\n",
      "Epoch [10/10], Step[50501/60000], Loss: 0.0339\n",
      "Epoch [10/10], Step[50601/60000], Loss: 0.0059\n",
      "Epoch [10/10], Step[50701/60000], Loss: 0.0150\n",
      "Epoch [10/10], Step[50801/60000], Loss: 0.0057\n",
      "Epoch [10/10], Step[50901/60000], Loss: 0.0058\n",
      "Epoch [10/10], Step[51001/60000], Loss: 0.0037\n",
      "Epoch [10/10], Step[51101/60000], Loss: 0.0137\n",
      "Epoch [10/10], Step[51201/60000], Loss: 0.0358\n",
      "Epoch [10/10], Step[51301/60000], Loss: 0.0100\n",
      "Epoch [10/10], Step[51401/60000], Loss: 0.0106\n",
      "Epoch [10/10], Step[51501/60000], Loss: 0.0026\n",
      "Epoch [10/10], Step[51601/60000], Loss: 0.0103\n",
      "Epoch [10/10], Step[51701/60000], Loss: 0.0043\n",
      "Epoch [10/10], Step[51801/60000], Loss: 0.0039\n",
      "Epoch [10/10], Step[51901/60000], Loss: 0.0559\n",
      "Epoch [10/10], Step[52001/60000], Loss: 0.0045\n",
      "Epoch [10/10], Step[52101/60000], Loss: 0.0392\n",
      "Epoch [10/10], Step[52201/60000], Loss: 0.0121\n",
      "Epoch [10/10], Step[52301/60000], Loss: 0.0038\n",
      "Epoch [10/10], Step[52401/60000], Loss: 0.0135\n",
      "Epoch [10/10], Step[52501/60000], Loss: 0.0010\n",
      "Epoch [10/10], Step[52601/60000], Loss: 0.0041\n",
      "Epoch [10/10], Step[52701/60000], Loss: 0.0046\n",
      "Epoch [10/10], Step[52801/60000], Loss: 0.0070\n",
      "Epoch [10/10], Step[52901/60000], Loss: 0.0051\n",
      "Epoch [10/10], Step[53001/60000], Loss: 0.0091\n",
      "Epoch [10/10], Step[53101/60000], Loss: 0.0039\n",
      "Epoch [10/10], Step[53201/60000], Loss: 0.0049\n",
      "Epoch [10/10], Step[53301/60000], Loss: 0.0031\n",
      "Epoch [10/10], Step[53401/60000], Loss: 0.0048\n",
      "Epoch [10/10], Step[53501/60000], Loss: 0.0050\n",
      "Epoch [10/10], Step[53601/60000], Loss: 0.0355\n",
      "Epoch [10/10], Step[53701/60000], Loss: 0.0074\n",
      "Epoch [10/10], Step[53801/60000], Loss: 0.0033\n",
      "Epoch [10/10], Step[53901/60000], Loss: 0.0169\n",
      "Epoch [10/10], Step[54001/60000], Loss: 0.1533\n",
      "Epoch [10/10], Step[54101/60000], Loss: 0.0034\n",
      "Epoch [10/10], Step[54201/60000], Loss: 0.0179\n",
      "Epoch [10/10], Step[54301/60000], Loss: 0.0022\n",
      "Epoch [10/10], Step[54401/60000], Loss: 0.0081\n",
      "Epoch [10/10], Step[54501/60000], Loss: 0.0186\n",
      "Epoch [10/10], Step[54601/60000], Loss: 0.0066\n",
      "Epoch [10/10], Step[54701/60000], Loss: 0.0059\n",
      "Epoch [10/10], Step[54801/60000], Loss: 0.1951\n",
      "Epoch [10/10], Step[54901/60000], Loss: 0.0088\n",
      "Epoch [10/10], Step[55001/60000], Loss: 0.0024\n",
      "Epoch [10/10], Step[55101/60000], Loss: 0.0030\n",
      "Epoch [10/10], Step[55201/60000], Loss: 0.0061\n",
      "Epoch [10/10], Step[55301/60000], Loss: 0.0387\n",
      "Epoch [10/10], Step[55401/60000], Loss: 0.0059\n",
      "Epoch [10/10], Step[55501/60000], Loss: 0.0025\n",
      "Epoch [10/10], Step[55601/60000], Loss: 0.0019\n",
      "Epoch [10/10], Step[55701/60000], Loss: 0.0049\n",
      "Epoch [10/10], Step[55801/60000], Loss: 0.0067\n",
      "Epoch [10/10], Step[55901/60000], Loss: 0.0027\n",
      "Epoch [10/10], Step[56001/60000], Loss: 0.0086\n",
      "Epoch [10/10], Step[56101/60000], Loss: 0.0028\n",
      "Epoch [10/10], Step[56201/60000], Loss: 0.0117\n",
      "Epoch [10/10], Step[56301/60000], Loss: 0.0131\n",
      "Epoch [10/10], Step[56401/60000], Loss: 0.0047\n",
      "Epoch [10/10], Step[56501/60000], Loss: 0.0168\n",
      "Epoch [10/10], Step[56601/60000], Loss: 0.0018\n",
      "Epoch [10/10], Step[56701/60000], Loss: 0.0047\n",
      "Epoch [10/10], Step[56801/60000], Loss: 0.0021\n",
      "Epoch [10/10], Step[56901/60000], Loss: 0.0030\n",
      "Epoch [10/10], Step[57001/60000], Loss: 0.0073\n",
      "Epoch [10/10], Step[57101/60000], Loss: 0.0019\n",
      "Epoch [10/10], Step[57201/60000], Loss: 0.0038\n",
      "Epoch [10/10], Step[57301/60000], Loss: 0.0125\n",
      "Epoch [10/10], Step[57401/60000], Loss: 0.0177\n",
      "Epoch [10/10], Step[57501/60000], Loss: 0.0090\n",
      "Epoch [10/10], Step[57601/60000], Loss: 0.0071\n",
      "Epoch [10/10], Step[57701/60000], Loss: 0.0087\n",
      "Epoch [10/10], Step[57801/60000], Loss: 0.0048\n",
      "Epoch [10/10], Step[57901/60000], Loss: 0.0128\n",
      "Epoch [10/10], Step[58001/60000], Loss: 0.0145\n",
      "Epoch [10/10], Step[58101/60000], Loss: 0.0033\n",
      "Epoch [10/10], Step[58201/60000], Loss: 0.0020\n",
      "Epoch [10/10], Step[58301/60000], Loss: 0.0185\n",
      "Epoch [10/10], Step[58401/60000], Loss: 0.0009\n",
      "Epoch [10/10], Step[58501/60000], Loss: 0.0048\n",
      "Epoch [10/10], Step[58601/60000], Loss: 0.0175\n",
      "Epoch [10/10], Step[58701/60000], Loss: 0.0018\n",
      "Epoch [10/10], Step[58801/60000], Loss: 0.0123\n",
      "Epoch [10/10], Step[58901/60000], Loss: 0.0007\n",
      "Epoch [10/10], Step[59001/60000], Loss: 0.0023\n",
      "Epoch [10/10], Step[59101/60000], Loss: 0.0004\n",
      "Epoch [10/10], Step[59201/60000], Loss: 0.0021\n",
      "Epoch [10/10], Step[59301/60000], Loss: 0.0033\n",
      "Epoch [10/10], Step[59401/60000], Loss: 0.0030\n",
      "Epoch [10/10], Step[59501/60000], Loss: 0.0003\n",
      "Epoch [10/10], Step[59601/60000], Loss: 0.0017\n",
      "Epoch [10/10], Step[59701/60000], Loss: 0.0355\n",
      "Epoch [10/10], Step[59801/60000], Loss: 0.0002\n",
      "Epoch [10/10], Step[59901/60000], Loss: 0.2082\n"
     ]
    }
   ],
   "source": [
    "# Your PyTorch training loop here.\n",
    "n_total_steps = len(X_trn)\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_trn), batch_size):        \n",
    "        X = X_trn_torch[i:i+batch_size]     # Slice out a mini-batch of features\n",
    "        y = y_trn_torch[i:i+batch_size] \n",
    "\n",
    "        images = X.reshape(-1, 28*28)\n",
    "        labels = y\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Step[{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the *named_parameters* method, available on all PyTorch [*Module*](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) objects, to print the name and shape of each parameter tensor in the neural network. Your output should look something like:\n",
    "```\n",
    "0.weight  torch.Size([?])\n",
    "0.bias    torch.Size([?])\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1.weight   torch.Size(([tensor([[-0.0116,  0.0281, -0.0072,  ..., -0.0173,  0.0244,  0.0215],\n",
      "        [ 0.0342,  0.0338,  0.0089,  ..., -0.0197, -0.0033, -0.0346],\n",
      "        [ 0.0040, -0.0110, -0.0260,  ..., -0.0224,  0.0230,  0.0113],\n",
      "        ...,\n",
      "        [ 0.0169,  0.0180, -0.0047,  ..., -0.0293,  0.0140,  0.0190],\n",
      "        [ 0.0117,  0.0328, -0.0209,  ...,  0.0291,  0.0136, -0.0303],\n",
      "        [-0.0073, -0.0036,  0.0039,  ...,  0.0141, -0.0278,  0.0201]])]))\n",
      "l1.bias   torch.Size(([tensor([-0.0792, -0.0229, -0.0454, -0.0327,  0.0010,  0.0199,  0.0246, -0.0631,\n",
      "        -0.0522, -0.0223, -0.0454,  0.0094, -0.0406, -0.0358, -0.0816, -0.0104,\n",
      "        -0.0323,  0.0065,  0.0005, -0.0467, -0.0250, -0.0375,  0.0251, -0.0098,\n",
      "         0.0077, -0.0372, -0.0092, -0.0034, -0.0398,  0.0269, -0.0396, -0.0043,\n",
      "        -0.0029, -0.0300,  0.0268,  0.0121,  0.0261, -0.0050, -0.0455, -0.0909,\n",
      "        -0.0368, -0.0112, -0.0152, -0.0192, -0.0098, -0.0233, -0.0031,  0.0037,\n",
      "        -0.0409, -0.0411, -0.0300, -0.0221, -0.0617, -0.0094, -0.0816, -0.0222,\n",
      "        -0.0258, -0.0260,  0.0144, -0.0083,  0.0071,  0.0024, -0.0360,  0.0078,\n",
      "         0.0170,  0.0220, -0.0602,  0.0270, -0.0513, -0.0081, -0.0060,  0.0119,\n",
      "        -0.0268,  0.0186, -0.0353,  0.0015, -0.0507, -0.0170, -0.0290, -0.0060,\n",
      "        -0.0479, -0.0276,  0.0216,  0.0032, -0.0078, -0.0035, -0.0445, -0.0339,\n",
      "        -0.0049,  0.0305, -0.0038, -0.0322,  0.0197, -0.0329, -0.0485,  0.0096,\n",
      "        -0.0059, -0.0412, -0.0189, -0.0321,  0.0031, -0.0678, -0.0041, -0.0126,\n",
      "         0.0249,  0.0107, -0.0350,  0.0108, -0.0305,  0.0116, -0.0152,  0.0061,\n",
      "        -0.0140,  0.0042, -0.0193, -0.0204,  0.0132, -0.0204,  0.0082,  0.0209,\n",
      "        -0.0344,  0.0119, -0.0205,  0.0009, -0.0361, -0.0069, -0.0022, -0.0272,\n",
      "        -0.0444, -0.0609, -0.0042, -0.0405, -0.0148, -0.0188, -0.0558,  0.0129,\n",
      "        -0.0185,  0.0019, -0.0708, -0.0246, -0.0251,  0.0394, -0.0090, -0.0537,\n",
      "         0.0113,  0.0213, -0.0304, -0.0267, -0.0315,  0.0135,  0.0185,  0.0207,\n",
      "         0.0049, -0.0379, -0.0480, -0.0329, -0.0224,  0.0078,  0.0241,  0.0249,\n",
      "        -0.0273, -0.0227, -0.0056,  0.0066,  0.0364,  0.0018,  0.0121, -0.0430,\n",
      "        -0.0603, -0.0130, -0.0236, -0.0003,  0.0072,  0.0206, -0.0439, -0.0169,\n",
      "         0.0005, -0.0055, -0.0167, -0.0356, -0.0127, -0.0301, -0.0376, -0.0511,\n",
      "        -0.0076, -0.0088, -0.0553, -0.0163, -0.0454, -0.0253, -0.0471, -0.0308,\n",
      "        -0.0417,  0.0086, -0.0636, -0.0347, -0.0361,  0.0122,  0.0122, -0.0317,\n",
      "        -0.0510,  0.0031, -0.0817, -0.0340, -0.0172, -0.0721, -0.0111,  0.0276,\n",
      "        -0.0606, -0.0283,  0.0262, -0.0012, -0.0398, -0.0056, -0.0384, -0.0100,\n",
      "        -0.0135, -0.0195,  0.0121, -0.0436, -0.0340, -0.0304, -0.0467,  0.0146,\n",
      "        -0.0081, -0.0085, -0.0568,  0.0108, -0.0196, -0.0112, -0.0037, -0.0384,\n",
      "        -0.0116, -0.0313,  0.0469,  0.0018, -0.0069, -0.0229, -0.0133,  0.0236,\n",
      "        -0.0789, -0.0050, -0.0145, -0.0024,  0.0189, -0.0275,  0.0301,  0.0015,\n",
      "        -0.0049, -0.0259, -0.0213, -0.0142, -0.0055,  0.0012, -0.0168, -0.0211,\n",
      "        -0.0097, -0.0326, -0.0040, -0.0319,  0.0065, -0.0394, -0.0781, -0.0119,\n",
      "        -0.0297, -0.0232, -0.1018, -0.0502, -0.0311,  0.0244, -0.0611, -0.0043,\n",
      "        -0.0133,  0.0062, -0.0325,  0.0199, -0.0525, -0.0266, -0.0598,  0.0071,\n",
      "         0.0004, -0.0059, -0.0773, -0.0168, -0.0308,  0.0442,  0.0024, -0.0393,\n",
      "        -0.0237,  0.0015, -0.0863, -0.0195, -0.0303, -0.0488, -0.0264,  0.0023,\n",
      "         0.0221,  0.0100,  0.0198, -0.0551, -0.0115,  0.0068, -0.0462, -0.0501,\n",
      "        -0.0358, -0.0122, -0.0947, -0.0601,  0.0053, -0.0318, -0.0465,  0.0371,\n",
      "        -0.0353, -0.0102, -0.0100,  0.0062, -0.0320,  0.0183,  0.0155, -0.0103,\n",
      "        -0.1323,  0.0085, -0.0236,  0.0207, -0.0082, -0.0089, -0.0901, -0.0368,\n",
      "        -0.0509, -0.0028,  0.0385,  0.0030, -0.0888, -0.0087, -0.0358, -0.0310,\n",
      "         0.0019, -0.0279, -0.0088, -0.0279, -0.0407, -0.0381, -0.0592, -0.0198,\n",
      "        -0.0015,  0.0124, -0.0509, -0.0050, -0.0027,  0.0345,  0.0138, -0.0528,\n",
      "        -0.0177,  0.0188, -0.0730, -0.0563,  0.0099,  0.0098, -0.0249,  0.0042,\n",
      "        -0.0213,  0.0011, -0.0319, -0.0288,  0.0025,  0.0021, -0.0257, -0.0997,\n",
      "        -0.0431,  0.0167, -0.0389, -0.0222,  0.0262, -0.0139, -0.0310, -0.0176,\n",
      "         0.0310, -0.0264, -0.0687, -0.0333, -0.0257, -0.0182, -0.0747, -0.0452,\n",
      "        -0.0434, -0.0373, -0.0342, -0.0029, -0.0074, -0.0480, -0.0386, -0.0467,\n",
      "        -0.0631,  0.0302, -0.0110, -0.0022,  0.0132, -0.0128, -0.0338, -0.0140,\n",
      "        -0.0250, -0.0374,  0.0482,  0.0044,  0.0067,  0.0236,  0.0197, -0.0364,\n",
      "        -0.0238, -0.0373, -0.0709, -0.0742, -0.0838, -0.0438, -0.0228, -0.0241,\n",
      "        -0.0293,  0.0165, -0.0338, -0.0234,  0.0038, -0.0092, -0.0146, -0.0007,\n",
      "        -0.0422, -0.0160,  0.0241, -0.0515, -0.0329, -0.0054, -0.0169, -0.0425,\n",
      "        -0.0284, -0.0206, -0.0280, -0.0462, -0.0139, -0.0225, -0.0517, -0.0457,\n",
      "        -0.0078, -0.0166, -0.0128, -0.0114, -0.0594, -0.0319, -0.0029, -0.0071,\n",
      "        -0.0259, -0.0022,  0.0297,  0.0397, -0.0738, -0.0193, -0.0134, -0.0480,\n",
      "         0.0076, -0.0587, -0.0020, -0.0187, -0.0076, -0.0184, -0.0174, -0.0356,\n",
      "        -0.0510, -0.0488, -0.0371, -0.0194, -0.0097, -0.0061, -0.0355, -0.0227,\n",
      "        -0.0039, -0.0391, -0.0570, -0.0422, -0.0229,  0.0005, -0.0245, -0.0093,\n",
      "        -0.0496, -0.0194,  0.0261, -0.0586, -0.0700, -0.0442, -0.0474,  0.0128,\n",
      "        -0.0068, -0.0707, -0.0036, -0.0821, -0.0437, -0.0454, -0.0130, -0.0551,\n",
      "        -0.0193, -0.0658, -0.0126, -0.0256])]))\n",
      "l2.weight   torch.Size(([tensor([[-0.1656, -0.0381, -0.0269,  ..., -0.1185, -0.1056, -0.1176],\n",
      "        [ 0.1467, -0.0772, -0.0395,  ..., -0.1317,  0.0582, -0.0287],\n",
      "        [-0.0892,  0.0434, -0.0416,  ...,  0.1343,  0.0544,  0.0533],\n",
      "        ...,\n",
      "        [-0.0923,  0.0004, -0.0119,  ..., -0.1429, -0.0403,  0.0184],\n",
      "        [ 0.0020, -0.0631, -0.0573,  ..., -0.0618,  0.0977,  0.0969],\n",
      "        [-0.1072,  0.1432, -0.0097,  ..., -0.0905,  0.0974,  0.1715]])]))\n",
      "l2.bias   torch.Size(([tensor([-0.0157, -0.0067,  0.2463, -0.1323,  0.0761, -0.2380,  0.0676,  0.3145,\n",
      "         0.0428,  0.0087])]))\n",
      "l3.weight   torch.Size(([tensor([[-6.7427e-01, -3.0340e-01,  7.4559e-01,  2.2091e-01,  1.7482e-01,\n",
      "          4.7046e-01,  2.3228e-01, -4.6776e-01, -1.9231e-02,  8.9520e-01],\n",
      "        [ 3.7646e-01, -2.5879e-01, -5.7313e-01,  7.2104e-01, -1.1378e-01,\n",
      "          6.0973e-01,  6.2403e-01,  2.8740e-01, -6.2451e-01,  3.5090e-01],\n",
      "        [ 4.4770e-01, -3.3660e-01, -9.1884e-02, -5.5955e-02, -1.2217e-01,\n",
      "          7.1496e-02,  4.5154e-01,  4.1134e-01,  1.1382e-02, -5.1414e-01],\n",
      "        [-4.4891e-01,  6.7241e-01,  1.4835e-01,  2.0722e-01,  4.6999e-03,\n",
      "          4.0866e-01,  2.4812e-01,  1.3336e-01, -4.3800e-01, -5.1566e-01],\n",
      "        [-6.3324e-01,  3.2653e-01,  4.1921e-02,  4.9053e-01,  4.2114e-01,\n",
      "          9.5585e-03,  7.6818e-01, -4.8692e-01,  1.0473e-01, -6.9570e-01],\n",
      "        [ 6.5984e-02,  2.7338e-01, -4.8643e-01,  4.0064e-01, -1.9916e-01,\n",
      "          6.5939e-01, -6.2228e-01, -8.2350e-01, -2.9080e-01, -2.6588e-01],\n",
      "        [ 1.8830e-01, -2.7800e-01,  9.2159e-01,  2.0522e-01,  6.4701e-01,\n",
      "          2.3243e-01, -2.0257e-02,  3.3162e-01, -7.0039e-01, -3.1877e-01],\n",
      "        [-2.4069e-01,  3.4063e-01, -2.3356e-01, -2.7567e-01, -3.1561e-01,\n",
      "          3.1056e-01,  7.1360e-01,  3.7254e-01,  5.5004e-01,  2.9339e-01],\n",
      "        [ 2.6696e-01, -8.3647e-01, -2.1612e-01, -5.1703e-01,  1.7825e-01,\n",
      "          7.0917e-02,  6.6817e-01, -5.2734e-01, -1.0219e-01,  4.8884e-04],\n",
      "        [ 7.0245e-01,  3.4307e-01,  8.8732e-03,  3.1436e-01,  7.9956e-01,\n",
      "          7.1078e-02, -1.2719e-01,  8.5723e-02,  3.1499e-01,  3.2512e-01]])]))\n",
      "l3.bias   torch.Size(([tensor([-0.1928,  0.1497,  0.0811, -0.0345, -0.0100, -0.7406,  0.1619,  0.2463,\n",
      "        -0.1712, -0.2007])]))\n",
      "l4.weight   torch.Size(([tensor([[-8.4763e-01, -2.3449e-01,  1.5603e-01, -5.5200e-01, -7.4787e-01,\n",
      "         -1.9439e-01, -1.6128e-01, -4.0256e-01, -5.3705e-01, -4.5992e-02],\n",
      "        [-1.2986e-01,  6.1208e-01,  2.3855e-01,  4.5415e-01,  9.0513e-01,\n",
      "         -1.4538e-01, -2.8215e-01,  3.8734e-01, -2.6542e-01, -5.4602e-01],\n",
      "        [-1.4218e+00,  1.4860e-02,  6.5879e-01,  3.2654e-01,  8.5357e-02,\n",
      "         -2.5177e-01,  3.0845e-01, -1.1186e-01,  1.6478e-02, -1.7750e-01],\n",
      "        [-2.4395e-01,  6.4783e-01,  8.6884e-01,  4.7186e-02,  2.4512e-01,\n",
      "         -4.8122e-01,  5.6467e-01,  1.4545e-01,  6.6508e-01, -4.0936e-01],\n",
      "        [ 2.5484e-01, -7.8295e-01, -2.0953e-01,  5.7116e-01,  5.7858e-01,\n",
      "          1.0887e-02,  6.8923e-01, -4.1125e-01, -4.8596e-01, -7.5808e-01],\n",
      "        [ 2.2980e-01,  9.0557e-02,  8.3938e-02, -3.6373e-01, -7.7883e-01,\n",
      "         -8.4576e-01,  2.7370e-01,  7.1307e-02,  4.3077e-01, -7.9695e-01],\n",
      "        [-4.8145e-01, -9.5488e-01,  3.7229e-01, -2.9954e-01,  1.2676e-01,\n",
      "         -3.3638e-01, -3.5224e-01,  4.8787e-02,  9.4068e-02, -7.9301e-01],\n",
      "        [-2.0697e-01,  6.5271e-01,  2.8067e-01,  5.3823e-01, -2.5391e-01,\n",
      "          1.7674e-01,  8.8451e-01, -4.0485e-01, -6.7374e-01, -1.4725e-01],\n",
      "        [-2.0327e-01, -1.3677e-01,  2.9391e-01,  2.4094e-01, -4.5412e-02,\n",
      "         -1.4581e+00,  2.7341e-01,  6.7334e-01, -5.6318e-01,  1.1500e-01],\n",
      "        [ 2.1165e-01, -1.7307e-02,  2.3355e-01, -1.6642e-01,  3.3812e-01,\n",
      "         -6.3779e-01,  1.2484e+00, -6.5637e-01,  1.3105e-01,  1.9096e-01],\n",
      "        [-2.7008e-01,  1.1455e-01, -3.1850e-01, -2.0885e-01, -1.1465e-01,\n",
      "          3.0456e-01,  4.3746e-02,  9.3418e-02, -9.7607e-03,  6.7460e-02],\n",
      "        [ 2.8861e-01,  1.9792e-01,  2.5505e-01,  2.6040e-02, -6.3327e-02,\n",
      "          2.9279e-01,  1.9628e-01,  1.5536e-01, -1.0842e-01, -9.9480e-02],\n",
      "        [ 1.4772e-01,  2.6477e-02,  1.1827e-01,  2.0859e-01, -8.1368e-02,\n",
      "         -9.3874e-02, -1.3470e-01,  7.9775e-03,  2.9651e-01,  3.1802e-01],\n",
      "        [ 8.4838e-02,  1.0168e-01,  2.0471e-02,  1.5527e-01, -1.4278e-01,\n",
      "         -8.7178e-02,  6.0663e-02,  7.4241e-03,  2.0351e-01,  5.3636e-02],\n",
      "        [ 2.2439e-01,  3.3800e-02, -2.5214e-01,  3.1870e-02, -7.5139e-02,\n",
      "         -1.8337e-01,  1.3044e-01,  1.6839e-01, -4.8833e-02, -2.4009e-01],\n",
      "        [ 2.5674e-01, -8.2281e-03, -8.1126e-02, -8.7042e-02, -2.3022e-01,\n",
      "         -1.0683e-02, -2.2403e-01,  6.7091e-02, -1.9495e-01, -2.4131e-01],\n",
      "        [ 2.6516e-02, -3.0348e-01, -2.6194e-01, -2.4559e-01,  1.9071e-01,\n",
      "          8.4916e-02,  9.5476e-02,  1.0155e-01, -4.8222e-02, -1.5095e-01],\n",
      "        [-5.4905e-02,  9.1744e-02, -2.4231e-01, -7.0090e-02, -2.5846e-01,\n",
      "          2.5216e-01, -1.3050e-01, -1.3656e-01,  1.6701e-01,  1.7771e-01],\n",
      "        [ 2.4933e-01, -2.4041e-03, -2.0207e-01,  3.1689e-02,  2.6379e-01,\n",
      "         -2.3773e-01, -1.8984e-01,  2.0947e-01,  2.5744e-01,  3.0499e-01],\n",
      "        [-2.0915e-01,  2.8107e-02,  8.5545e-02,  1.4994e-01, -2.7883e-01,\n",
      "         -1.0846e-01, -1.7672e-01,  2.3313e-01, -8.7768e-03,  6.9717e-02],\n",
      "        [-1.4374e-02,  1.0224e-01,  1.9354e-01,  2.1529e-01,  2.0601e-01,\n",
      "          1.9928e-01, -7.0489e-02, -2.4079e-01, -9.8304e-02, -1.3092e-01],\n",
      "        [-3.0256e-02, -2.6856e-01,  1.2182e-02, -3.0743e-01,  6.2200e-02,\n",
      "          1.7848e-01,  6.9395e-02,  8.7642e-02,  1.3313e-01, -1.8180e-01],\n",
      "        [-1.7472e-01,  7.0244e-02,  1.1786e-01, -1.1004e-01,  2.5720e-01,\n",
      "          3.5263e-01,  4.0454e-02, -2.8424e-01,  3.1717e-01, -2.5510e-01],\n",
      "        [ 2.7775e-01,  2.8341e-01,  7.1864e-02, -7.8154e-02, -5.5499e-02,\n",
      "         -2.9271e-02, -2.1825e-01, -6.3565e-02,  7.3526e-02,  1.1217e-01],\n",
      "        [-1.6976e-01,  5.8696e-02,  1.6518e-01,  1.0387e-01,  1.7511e-03,\n",
      "          1.1665e-01, -1.7237e-02,  8.9900e-02, -2.7995e-01,  4.9971e-02],\n",
      "        [-1.6229e-01, -1.9513e-01,  2.7474e-03, -2.1925e-01, -1.0415e-01,\n",
      "          1.2273e-01,  9.2839e-02,  2.6924e-01, -1.8929e-01, -1.3271e-01],\n",
      "        [-2.6161e-01, -4.2705e-02,  1.2569e-02,  2.6457e-01,  1.2883e-01,\n",
      "          9.2150e-02, -3.0045e-01, -1.1056e-01, -1.5708e-01,  2.4079e-01],\n",
      "        [ 2.6323e-01,  3.0035e-01, -3.1545e-01,  2.4139e-02,  3.0021e-01,\n",
      "         -5.1183e-02, -1.9360e-01,  1.9250e-01, -8.9627e-02,  1.0893e-01],\n",
      "        [-2.3483e-01, -2.4142e-01, -1.9135e-01,  1.9981e-01,  1.6788e-01,\n",
      "         -1.4668e-02, -3.1101e-01, -1.9757e-01,  9.4583e-02,  2.3587e-01],\n",
      "        [-4.1745e-02, -5.2525e-02, -1.6007e-01,  1.1378e-01, -1.6137e-01,\n",
      "          1.1659e-01,  1.9477e-01,  1.7827e-01,  1.5948e-01,  1.8863e-01],\n",
      "        [ 2.8690e-01,  2.2316e-01, -2.5164e-01, -2.0023e-01,  1.3909e-01,\n",
      "         -1.2334e-02, -2.2317e-01, -1.9041e-01, -1.4798e-01,  2.3637e-01],\n",
      "        [ 2.3057e-01, -9.2565e-03, -2.5880e-02,  8.9704e-02,  2.2257e-01,\n",
      "          2.9836e-01, -9.1185e-02,  1.0125e-01, -2.8899e-01, -2.9384e-02],\n",
      "        [-2.8404e-01, -2.0559e-01, -2.2847e-01, -5.0085e-02, -1.9717e-01,\n",
      "          2.7401e-01, -3.0244e-01,  2.3630e-01,  1.4257e-01, -2.5527e-01],\n",
      "        [ 9.6763e-02,  1.6954e-02,  2.1030e-01, -7.4607e-02, -1.3869e-01,\n",
      "          1.3794e-01,  4.6477e-02,  1.1705e-01, -5.8385e-02,  1.7487e-02],\n",
      "        [ 2.5456e-02, -4.9862e-02, -1.7439e-01,  2.4205e-01,  1.5847e-01,\n",
      "         -2.2540e-01, -2.4818e-01, -6.5247e-02, -6.7749e-02, -1.0689e-01],\n",
      "        [-1.9457e-01, -1.0444e-01,  2.1396e-01,  2.2030e-01, -5.9082e-02,\n",
      "          1.7890e-01,  1.1483e-01,  1.4594e-01, -1.9955e-01,  3.0279e-01],\n",
      "        [-5.8200e-02, -5.6050e-02,  7.2723e-02,  3.7182e-02, -2.2926e-01,\n",
      "          3.1588e-01, -2.3984e-01, -1.7896e-01, -2.7914e-01,  1.1948e-01],\n",
      "        [-3.1518e-02, -2.4999e-01, -2.0153e-01, -1.6975e-01,  9.2673e-02,\n",
      "         -1.0895e-01, -2.5241e-01,  2.0840e-01,  1.1059e-01, -1.5812e-01],\n",
      "        [-1.5252e-01,  2.1463e-01, -6.1564e-02,  7.8511e-02,  2.0950e-01,\n",
      "          2.0629e-01,  2.0363e-01,  3.6437e-02, -1.5638e-01,  2.7574e-02],\n",
      "        [ 2.0494e-01,  9.6450e-02, -2.5328e-01, -1.4691e-01, -5.9266e-02,\n",
      "         -1.0545e-01, -2.5164e-02, -2.7455e-01,  2.2267e-01, -2.2908e-01],\n",
      "        [-1.6718e-01, -2.2407e-01, -1.3409e-01,  1.0502e-01,  1.0513e-01,\n",
      "          2.7931e-02, -1.8922e-01, -1.1189e-01,  1.7552e-01, -2.2595e-01],\n",
      "        [-1.1429e-01, -2.4005e-01, -1.6443e-01,  1.6797e-01,  1.1216e-02,\n",
      "         -2.9850e-02,  1.8133e-01,  1.0546e-01, -2.6075e-01,  2.3596e-01],\n",
      "        [-1.3270e-01, -1.4725e-01, -6.4218e-02, -2.0783e-02, -2.7997e-01,\n",
      "         -4.4501e-03, -1.2308e-01,  2.8976e-01, -5.1704e-02, -6.1920e-02],\n",
      "        [ 1.7572e-01, -8.5554e-03, -2.2829e-02,  9.2120e-02, -2.7159e-01,\n",
      "         -1.1200e-01,  1.4405e-01,  2.3842e-01,  1.5034e-01,  1.6203e-02],\n",
      "        [ 1.1195e-01,  1.8870e-01, -2.5214e-01,  1.5441e-01, -2.2112e-01,\n",
      "          2.9538e-01,  1.5300e-01,  2.1770e-01,  2.1664e-01, -2.0023e-01],\n",
      "        [-7.0564e-02, -2.9555e-01, -2.0528e-02, -1.7428e-01, -2.0495e-01,\n",
      "          2.2192e-01, -2.7099e-01, -1.5630e-01, -2.4410e-01, -1.0856e-01],\n",
      "        [-1.1408e-01,  2.4319e-01, -2.7841e-01,  1.5590e-01, -2.4037e-01,\n",
      "          1.5689e-01, -2.4092e-01,  2.9412e-01,  2.1712e-01,  2.9745e-01],\n",
      "        [-2.6272e-02,  6.1644e-02, -1.5425e-01, -2.2965e-01,  4.9738e-02,\n",
      "         -1.1648e-01, -6.7940e-02,  2.5230e-02, -1.9668e-01,  7.9101e-02],\n",
      "        [-1.4326e-01,  2.7610e-01,  2.7320e-02,  1.8730e-01, -2.1381e-01,\n",
      "          1.3317e-01,  2.0799e-01,  7.4955e-02, -4.6051e-02,  1.3699e-01],\n",
      "        [-1.3794e-01, -1.2985e-01, -6.4439e-02, -1.3570e-01, -1.4635e-01,\n",
      "         -4.6380e-02, -1.6287e-01,  2.3814e-01,  2.2607e-01, -2.4489e-01],\n",
      "        [ 2.2339e-01, -2.6315e-01,  1.5374e-01, -1.7746e-01,  2.1769e-01,\n",
      "          2.6596e-01,  9.8849e-02, -3.0010e-01, -2.4194e-02,  7.6471e-02],\n",
      "        [-1.9709e-01, -2.4988e-01, -3.6637e-02, -1.9259e-01, -2.5792e-01,\n",
      "          3.2887e-01, -1.1619e-01, -2.1541e-01,  2.0874e-01, -7.9922e-02],\n",
      "        [ 1.4230e-01,  6.8401e-02,  2.1816e-01,  2.3198e-01,  3.0066e-02,\n",
      "          2.6795e-01, -3.2720e-01, -1.8515e-01, -1.0494e-01,  2.1089e-01],\n",
      "        [ 1.3618e-01, -1.0874e-01,  1.7144e-01, -5.6133e-02,  7.8235e-02,\n",
      "         -2.4856e-02, -3.2269e-01,  4.1765e-02,  2.6313e-01, -2.1604e-02],\n",
      "        [ 1.4824e-01,  2.6707e-01,  1.1489e-01,  1.4340e-02, -1.1220e-01,\n",
      "         -1.5541e-01,  7.1235e-02,  3.0582e-01,  2.0954e-01,  1.8619e-01],\n",
      "        [ 2.7803e-01, -2.7317e-01,  2.5823e-01, -1.7589e-01, -9.0411e-02,\n",
      "         -9.2314e-02, -1.2141e-01,  1.1234e-01, -5.7957e-02,  4.8826e-02],\n",
      "        [-2.2068e-01, -1.1977e-01, -2.6188e-01, -3.8885e-02,  2.9142e-01,\n",
      "          2.3580e-02, -1.8612e-01,  1.4333e-01, -1.4997e-01,  3.1518e-01],\n",
      "        [-2.5633e-01,  7.7668e-02, -1.4182e-01,  1.1126e-02,  2.5588e-01,\n",
      "          2.8995e-01, -2.6322e-01,  3.0596e-02, -1.4757e-01, -2.0977e-01],\n",
      "        [-2.7727e-02,  1.3541e-01, -1.3576e-01, -1.4265e-01,  3.0907e-01,\n",
      "          1.6762e-01,  1.3383e-01, -2.0462e-01,  1.8888e-01, -7.7848e-02],\n",
      "        [-6.4757e-02, -1.9010e-02,  9.9181e-02,  2.9077e-01,  2.0168e-01,\n",
      "          3.1807e-01, -2.7465e-01, -1.7092e-01,  9.9359e-02,  6.4656e-02],\n",
      "        [ 1.4304e-01, -1.5364e-01, -3.3449e-01,  2.2983e-02, -9.6376e-02,\n",
      "         -5.2338e-02,  1.7942e-01,  1.6208e-01, -1.6415e-01, -1.4072e-01],\n",
      "        [-2.2852e-01, -1.2654e-01, -1.3799e-01, -2.2867e-01, -1.7325e-01,\n",
      "          2.5292e-01, -2.8657e-01,  1.7867e-01,  1.8476e-01, -1.0348e-01],\n",
      "        [ 1.8203e-01,  1.7075e-01, -3.1880e-01,  2.0924e-01,  6.1250e-02,\n",
      "         -1.6085e-02,  7.4746e-02,  2.5157e-01,  3.1753e-01, -6.5731e-03],\n",
      "        [ 1.6421e-01,  7.6468e-02,  1.1524e-01,  9.9048e-02,  2.0857e-01,\n",
      "          1.7123e-01,  2.3248e-02,  1.9894e-01,  3.1948e-01,  1.2958e-01],\n",
      "        [ 1.2303e-01, -1.3742e-01, -2.4130e-01, -1.5187e-02,  1.9223e-01,\n",
      "          7.6612e-02, -9.0482e-02,  2.6151e-01, -1.1197e-01, -1.2578e-01],\n",
      "        [ 1.8697e-01,  2.7009e-01,  1.6008e-01,  6.4654e-02,  1.5346e-01,\n",
      "          2.9785e-03, -1.3552e-01, -2.5108e-01,  2.3480e-01, -1.4819e-01],\n",
      "        [ 1.1610e-01,  2.9040e-02, -1.4605e-01, -8.5348e-02,  1.3439e-01,\n",
      "          3.2640e-01,  1.2691e-01,  2.6828e-01, -9.4906e-02,  2.9817e-01],\n",
      "        [-1.2939e-01,  2.1709e-02, -2.2688e-01, -6.2258e-02,  2.2379e-01,\n",
      "          2.7522e-01,  2.6820e-02, -1.8920e-01, -3.4823e-02, -8.2271e-02],\n",
      "        [-1.4759e-02,  2.2283e-01,  1.4526e-01, -3.7785e-02,  5.5950e-02,\n",
      "          1.5403e-01, -2.6580e-01, -1.8319e-01,  3.2942e-03,  3.1379e-01],\n",
      "        [ 2.5418e-01,  2.1794e-01, -6.0466e-03, -3.9227e-02, -3.7502e-02,\n",
      "          1.3828e-01,  1.4936e-01,  1.4439e-01, -1.3690e-01, -8.5809e-02],\n",
      "        [ 5.6270e-02,  1.8528e-01,  4.4798e-02,  3.6050e-02,  6.6441e-02,\n",
      "          1.7378e-01,  1.3027e-01,  1.0599e-01, -8.2764e-02,  9.2605e-02],\n",
      "        [-7.9472e-02,  9.0007e-03, -1.1388e-01,  2.4946e-01,  2.5468e-01,\n",
      "          3.7045e-02,  1.7577e-01, -9.1240e-02,  1.7826e-01,  2.1736e-02],\n",
      "        [ 2.5420e-01, -2.7233e-01, -1.1383e-01,  2.5666e-01, -7.4940e-02,\n",
      "          2.2795e-01,  1.7418e-02, -1.8959e-01,  1.1319e-01, -6.4160e-02],\n",
      "        [-1.7677e-02,  1.8319e-01,  4.8933e-02,  8.1154e-02,  1.7984e-01,\n",
      "         -2.6674e-03,  7.8041e-02, -2.1343e-02,  1.6946e-01,  3.5229e-02],\n",
      "        [ 2.7278e-01, -2.7404e-02, -4.0698e-04,  3.4005e-02,  8.5909e-02,\n",
      "          1.4076e-01,  2.0173e-03, -4.9328e-02,  2.1342e-01, -1.7934e-01],\n",
      "        [-2.7233e-01,  2.8131e-01,  2.1668e-01, -3.0262e-01,  2.9540e-02,\n",
      "          1.9744e-01, -3.0653e-01,  5.4882e-02, -2.9646e-01,  2.7631e-01],\n",
      "        [-1.2933e-01, -4.0498e-03,  1.2712e-01, -2.8530e-01, -9.8405e-02,\n",
      "          2.3554e-01,  4.3794e-03, -1.1029e-01,  4.8465e-02,  2.4573e-01],\n",
      "        [ 1.4762e-01,  1.6406e-01,  2.7415e-01, -1.2667e-01,  2.5831e-01,\n",
      "          2.5683e-01, -1.9530e-01,  2.4353e-02,  6.5409e-02,  1.3509e-01],\n",
      "        [-2.4611e-01,  3.1028e-01, -2.7652e-01, -2.2064e-02, -4.0022e-02,\n",
      "          3.1670e-01,  1.1068e-01, -2.0240e-01,  8.7535e-02, -2.1847e-01],\n",
      "        [ 1.2888e-01, -1.4683e-01,  1.6433e-02, -2.2670e-01, -1.5262e-01,\n",
      "          1.2130e-01, -1.0963e-01, -2.3135e-01, -1.2130e-01, -1.0202e-01],\n",
      "        [-4.3479e-04,  1.7016e-02,  2.3622e-01, -3.1000e-01,  2.6933e-01,\n",
      "          2.0909e-01, -2.3792e-01,  2.6898e-01, -3.6494e-02,  2.9752e-01],\n",
      "        [ 1.9967e-01,  2.3717e-01, -1.5901e-01, -8.3209e-02, -1.0034e-01,\n",
      "          3.1061e-02,  2.1486e-01, -2.5919e-01,  1.2676e-01,  1.2890e-01],\n",
      "        [ 2.7070e-01, -1.8969e-01, -2.0305e-01,  2.5167e-01, -1.1830e-01,\n",
      "         -2.6612e-01, -1.9207e-01,  2.3872e-02,  4.2739e-03,  1.4513e-01],\n",
      "        [ 6.3304e-02, -6.5002e-02, -1.4250e-01,  1.4386e-01, -1.4852e-01,\n",
      "          2.0859e-03, -2.1537e-01, -1.4055e-01, -2.9786e-01,  1.5392e-01],\n",
      "        [ 1.3748e-01,  1.1996e-01, -2.3745e-01, -2.0411e-01, -1.5280e-01,\n",
      "         -1.4298e-01,  5.5652e-02, -1.7502e-01,  2.3597e-01, -1.4617e-01],\n",
      "        [-1.4277e-01, -2.1855e-01, -2.7456e-01, -7.4054e-02, -2.0812e-01,\n",
      "         -1.2819e-01, -1.0942e-01,  6.9262e-02, -5.8369e-02,  2.3046e-01],\n",
      "        [-2.2870e-01, -1.4240e-01, -3.2452e-02, -1.4153e-01, -2.0906e-02,\n",
      "          1.7423e-01, -1.4090e-01,  6.4733e-02,  2.7427e-01,  3.1245e-01],\n",
      "        [ 2.4331e-01,  3.0077e-01,  3.8448e-03, -8.2942e-02,  1.4100e-01,\n",
      "          1.7935e-01, -3.8383e-02, -2.5790e-01, -1.0330e-01, -6.4021e-02],\n",
      "        [-2.5820e-01, -1.1454e-01, -2.1900e-01, -2.7801e-01,  3.3045e-02,\n",
      "          8.2366e-02, -4.6973e-02,  4.7891e-02, -7.9996e-02, -2.4735e-01],\n",
      "        [-6.4712e-02,  9.1749e-02, -1.1145e-01, -1.5335e-01,  6.2599e-02,\n",
      "          2.7785e-01, -2.8424e-01, -1.7692e-01,  2.8088e-01,  1.1779e-01],\n",
      "        [ 1.0918e-01,  6.1944e-02,  2.3050e-01, -5.2607e-02,  1.4063e-01,\n",
      "          8.1682e-02, -1.9020e-01,  2.3645e-02,  1.0293e-01, -2.2591e-01],\n",
      "        [ 5.6801e-02, -2.9378e-01,  2.1774e-01, -1.7898e-01, -2.1707e-01,\n",
      "         -1.0554e-01,  1.6373e-01,  1.0282e-01, -2.8072e-01,  3.1872e-01],\n",
      "        [-1.0461e-01,  2.1858e-02,  2.2809e-02, -3.1964e-01, -8.7403e-02,\n",
      "          2.9023e-01,  5.8814e-02, -1.1999e-01, -5.6778e-02, -2.5359e-01],\n",
      "        [ 2.6103e-01,  1.0172e-01, -2.1132e-01,  6.7176e-02,  2.9323e-01,\n",
      "          6.8650e-02,  1.0278e-01,  3.2281e-02, -1.0907e-01,  2.1328e-01],\n",
      "        [ 1.7129e-01,  1.0184e-01, -1.9074e-01,  3.8700e-03,  8.8611e-02,\n",
      "          2.1478e-01,  1.7482e-02,  1.4788e-01,  1.1381e-01, -8.1597e-02],\n",
      "        [ 3.1848e-01, -1.3919e-01,  1.1761e-01,  1.2315e-01, -2.4132e-01,\n",
      "          6.8129e-02, -2.7633e-01, -6.1799e-02, -2.5799e-01,  1.0996e-01],\n",
      "        [-2.3641e-01, -1.3023e-01, -8.2409e-02,  9.6568e-02, -1.2559e-01,\n",
      "         -3.3656e-02, -2.6041e-01, -5.4208e-02, -1.4470e-01,  1.1534e-01],\n",
      "        [-1.4123e-01,  1.4230e-01, -1.8011e-01, -1.9338e-01,  1.6542e-02,\n",
      "         -1.6298e-01,  6.3080e-02,  1.4783e-01, -3.3332e-02,  6.3707e-02],\n",
      "        [-1.7855e-01,  7.2850e-02, -1.8794e-01, -1.9689e-01,  1.1798e-01,\n",
      "          3.0476e-01,  1.9316e-01, -4.3427e-02, -5.9395e-02,  1.7549e-01],\n",
      "        [ 1.8883e-01,  2.3398e-01, -1.2035e-01, -1.4666e-01, -2.9596e-01,\n",
      "         -2.3663e-02, -2.1400e-01,  3.0335e-02, -2.0173e-01,  8.1974e-02]])]))\n",
      "l4.bias   torch.Size(([tensor([ 0.1015,  0.4864,  0.4269, -0.0764,  0.3831,  0.2905,  0.2546,  0.2607,\n",
      "         0.6220,  0.5764,  0.2555, -0.1238,  0.1336,  0.1886, -0.2440, -0.1046,\n",
      "        -0.0811, -0.3172,  0.1696,  0.0629,  0.0069, -0.0378,  0.0022, -0.1171,\n",
      "         0.0236, -0.0709, -0.1521, -0.2344,  0.1131,  0.1138, -0.0613, -0.2340,\n",
      "        -0.3322, -0.0048,  0.1040, -0.2924,  0.1399, -0.0948,  0.1866,  0.1813,\n",
      "         0.0670, -0.2420, -0.1554,  0.0807,  0.1423,  0.1289, -0.0545, -0.0118,\n",
      "        -0.2018, -0.2746,  0.0890,  0.2503, -0.0333, -0.3019, -0.0468, -0.0106,\n",
      "         0.2148,  0.2379, -0.2733, -0.1512, -0.0031, -0.1246,  0.1675,  0.1263,\n",
      "        -0.3149, -0.0688,  0.1743, -0.2223, -0.0182,  0.0128, -0.1360, -0.1429,\n",
      "        -0.3358,  0.1471, -0.2267,  0.0429, -0.0101, -0.2281, -0.0855,  0.1891,\n",
      "         0.1071,  0.2200, -0.3056,  0.0567, -0.1091, -0.2192,  0.0362,  0.0454,\n",
      "        -0.2142, -0.1739, -0.1099, -0.1836,  0.1279,  0.1021,  0.0930,  0.1319,\n",
      "         0.1522,  0.0830, -0.0036, -0.2997])]))\n"
     ]
    }
   ],
   "source": [
    "# Your code here. Aim for 2-3 lines.\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, f\"  torch.Size(([{param.data}]))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
